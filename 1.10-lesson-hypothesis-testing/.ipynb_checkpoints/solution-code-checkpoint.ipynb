{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "## Hypothesis Testing\n",
    "\n",
    "_Authors: Tim Book (DC), Matt Brems (DC), et. al_\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "- Define the null and alternative hypotheses.\n",
    "- Perform a two-sample t-test.\n",
    "- Define the t-statistics and p-value.\n",
    "- List the steps of hypothesis testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in our libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Hypothesis Testing\n",
    "\n",
    "In the real world, we like to make **data-driven decisions$^{\\text{TM}}$**!\n",
    "- In order to make these decisions, though, we need to collect some data.\n",
    "- We take this data, put it into a \"box,\" which gives us a statistically-powered yes-or-no decision.\n",
    "- This \"box\" is hypothesis testing.\n",
    "- **Hypothesis testing is a mathematically rigorous way of making yes-or-no decisions!**\n",
    "\n",
    "Hypothesis testing is a little more complicated than that, but not much!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First: How do we interpret statsmodels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/houses-norm.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-deb5f2bdf173>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhouses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/houses-norm.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mhouses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/houses-norm.csv'"
     ]
    }
   ],
   "source": [
    "houses = pd.read_csv('../data/houses-norm.csv')\n",
    "\n",
    "houses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = houses[['sqft', 'bedrooms','age']]\n",
    "y = houses['price']\n",
    "\n",
    "X = sm.add_constant(X, prepend=True)\n",
    "results = sm.OLS(y, X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the statsmodels results\n",
    "\n",
    "![](../images/statsmodels1.png)\n",
    "\n",
    "---\n",
    "\n",
    "![](../images/statsmodels2.png)\n",
    "\n",
    "---\n",
    "\n",
    "![](../images/statsmodels3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You Try: Hypothesis Testing our OLS coefficients\n",
    "By far the most common place we'll see hypothesis testing is in the context of linear regression coefficients. Let's read in some data and use `statsmodels` to conduct a quick linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>angle</th>\n",
       "      <th>chord_len</th>\n",
       "      <th>velocity</th>\n",
       "      <th>thickness</th>\n",
       "      <th>db</th>\n",
       "      <th>junk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>126.201</td>\n",
       "      <td>0.553485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.201</td>\n",
       "      <td>-1.393035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.951</td>\n",
       "      <td>-0.007287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.591</td>\n",
       "      <td>-0.772781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.461</td>\n",
       "      <td>0.110481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   freq  angle  chord_len  velocity  thickness       db      junk\n",
       "0   800    0.0     0.3048      71.3   0.002663  126.201  0.553485\n",
       "1  1000    0.0     0.3048      71.3   0.002663  125.201 -1.393035\n",
       "2  1250    0.0     0.3048      71.3   0.002663  125.951 -0.007287\n",
       "3  1600    0.0     0.3048      71.3   0.002663  127.591 -0.772781\n",
       "4  2000    0.0     0.3048      71.3   0.002663  127.461  0.110481"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a NASA dataset of airfoils at various wind tunnel speeds and angles of attack.\n",
    "# Their goal was to minimize noise (measured in db)\n",
    "df = pd.read_csv(\n",
    "    \"../data/airfoil_self_noise.dat\",\n",
    "    sep=\"\\t\",\n",
    "    names=[\"freq\", \"angle\", \"chord_len\", \"velocity\", \"thickness\", \"db\"]\n",
    ")\n",
    "df[\"junk\"] = np.random.randn(df.shape[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"db\", axis=1)\n",
    "X = sm.add_constant(X)\n",
    "y = df[\"db\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y, X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>db</td>        <th>  R-squared:         </th> <td>   0.516</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.514</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   265.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 08 Oct 2020</td> <th>  Prob (F-statistic):</th> <td>1.99e-231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:32:39</td>     <th>  Log-Likelihood:    </th> <td> -4490.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1503</td>      <th>  AIC:               </th> <td>   8994.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1496</td>      <th>  BIC:               </th> <td>   9031.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>     <td>  132.8308</td> <td>    0.545</td> <td>  243.768</td> <td> 0.000</td> <td>  131.762</td> <td>  133.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>freq</th>      <td>   -0.0013</td> <td> 4.22e-05</td> <td>  -30.411</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>angle</th>     <td>   -0.4218</td> <td>    0.039</td> <td>  -10.841</td> <td> 0.000</td> <td>   -0.498</td> <td>   -0.345</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chord_len</th> <td>  -35.6903</td> <td>    1.631</td> <td>  -21.884</td> <td> 0.000</td> <td>  -38.889</td> <td>  -32.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>velocity</th>  <td>    0.0999</td> <td>    0.008</td> <td>   12.281</td> <td> 0.000</td> <td>    0.084</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thickness</th> <td> -147.2880</td> <td>   15.019</td> <td>   -9.807</td> <td> 0.000</td> <td> -176.748</td> <td> -117.828</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>junk</th>      <td>   -0.0497</td> <td>    0.125</td> <td>   -0.399</td> <td> 0.690</td> <td>   -0.294</td> <td>    0.195</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>12.911</td> <th>  Durbin-Watson:     </th> <td>   0.448</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.002</td> <th>  Jarque-Bera (JB):  </th> <td>  19.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.019</td> <th>  Prob(JB):          </th> <td>6.86e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.552</td> <th>  Cond. No.          </th> <td>5.18e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.18e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     db   R-squared:                       0.516\n",
       "Model:                            OLS   Adj. R-squared:                  0.514\n",
       "Method:                 Least Squares   F-statistic:                     265.6\n",
       "Date:                Thu, 08 Oct 2020   Prob (F-statistic):          1.99e-231\n",
       "Time:                        00:32:39   Log-Likelihood:                -4490.0\n",
       "No. Observations:                1503   AIC:                             8994.\n",
       "Df Residuals:                    1496   BIC:                             9031.\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        132.8308      0.545    243.768      0.000     131.762     133.900\n",
       "freq          -0.0013   4.22e-05    -30.411      0.000      -0.001      -0.001\n",
       "angle         -0.4218      0.039    -10.841      0.000      -0.498      -0.345\n",
       "chord_len    -35.6903      1.631    -21.884      0.000     -38.889     -32.491\n",
       "velocity       0.0999      0.008     12.281      0.000       0.084       0.116\n",
       "thickness   -147.2880     15.019     -9.807      0.000    -176.748    -117.828\n",
       "junk          -0.0497      0.125     -0.399      0.690      -0.294       0.195\n",
       "==============================================================================\n",
       "Omnibus:                       12.911   Durbin-Watson:                   0.448\n",
       "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               19.173\n",
       "Skew:                          -0.019   Prob(JB):                     6.86e-05\n",
       "Kurtosis:                       3.552   Cond. No.                     5.18e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.18e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypotheses\n",
    "Notice the columns marked `t` and `P>|t|`. These are the $t$-statistics and $p$-values for the hypothesis test:\n",
    "\n",
    "$$\n",
    "H_0: \\beta_i = 0 \\\\\n",
    "H_A: \\beta_i \\ne 0\n",
    "$$\n",
    "\n",
    "(THREAD) In your own words, what would it mean if $\\beta_i = 0$ for one of these coefficients?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing with Puppies\n",
    "\n",
    "[This example is pulled liberally from Cassie Kozyrkov's Medium post.](https://hackernoon.com/explaining-p-values-with-puppies-af63d68005d0)\n",
    "\n",
    "Let's say that we come home at the end of the day to find some unspooled toilet paper.\n",
    "\n",
    "<img src=\"./images/pug_toilet_paper.jpg\" alt=\"doggo\" width=\"600\"/>\n",
    "\n",
    "We need to make a **data-driven** decision: Do we yell at our dog? \n",
    "\n",
    "Our possibilities are:\n",
    "- Yes, we yell at our dog.\n",
    "- No, we don't yell at our dog.\n",
    "\n",
    "Let's assume that our dog is innocent. Being good data scientists, we want to gather data, then use this data to make a decision.\n",
    "- **Gust of wind?** We check to see if the bathroom window is open or closed.\n",
    "- **Floor vent?** We check the thermostat to see if we left the heating/air conditioning on.\n",
    "- **Another human?** We text your sibling to see if they brought our niece over.\n",
    "\n",
    "Once you're done \"gathering your data,\" you determine the probability of observing this naturally, if our dog didn't do it.\n",
    "- If the probability is low enough (<= 0.05), we blame our dog.\n",
    "- Otherwise, we can't blame our dog!\n",
    "\n",
    "We just walked through a hypothesis test! We had two potential decisions, we gathered data, and used this data to make a decision.\n",
    "\n",
    "> **Note that we only deem our dog guilty or not guilty. The dog is never pronounced innocent! Just like the U.S. court system, hypothesis testing works this way too.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing: A Drug Efficacy Example\n",
    "\n",
    "---\n",
    "\n",
    "Say we are testing the efficacy of a new drug:\n",
    "\n",
    "- We randomly select 50 people to be in the control group and 50 people to recieve the treatment.\n",
    "    - In the context of experiments, we often talk about the \"control\" group and the \"experimental\" or \"treatment\" group. In our example, the control group is the one given the old drug (the one currently on the market) and the treatment group is the one given the actual drug. \n",
    "    - In other experiments, the control group is the one that receives no treatment. There can be a placebo group as well, which is one that receives a false treatment. **Is this ethical in this scenario?**\n",
    "- We are interested in the average difference in blood pressure levels between the treatment and control groups.\n",
    "- We know our sample is selected from a broader, unknown population pool.\n",
    "- We can imagine that, in a hypothetical parallel world, we could have ended up with a different random sample of subjects from the population pool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='null-hypothesis'></a>\n",
    "\n",
    "### The \"Null\" Hypothesis\n",
    "\n",
    "---\n",
    "\n",
    "The **null hypothesis** is typically the exact opposite of what you want to test for, i.e. the \"status quo\". We typically denote the null hypothesis with $H_0$.\n",
    "- In our dog example, we assume that our dog is innocent.\n",
    "- In our drug efficacy experiment example, our null hypothesis is that there is no difference in blood pressure between a subject taking a placebo and and one taking the treatment drug.\n",
    "\n",
    "> $H_0:$ The average difference in blood pressure between treatment and control groups is zero.\n",
    "\n",
    "Or, as it's properly written:\n",
    "\n",
    "> $H_0: \\mu_\\text{trt} = \\mu_\\text{ctrl}$\n",
    "\n",
    "Or, as it's often written:\n",
    "\n",
    "> $H_0: \\mu_\\text{trt} - \\mu_\\text{ctrl} = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='alternative-hypothesis'></a>\n",
    "\n",
    "### The \"Alternative Hypothesis\"\n",
    "\n",
    "---\n",
    "\n",
    "The **alternative hypothesis** is the outcome of the experiment that we hope to show. It's the opposite of our null hypothesis!\n",
    "- In our dog example, the alternative hypothesis is that our dog is guilty of unspooling the toilet paper.\n",
    "- In our drug efficacy experiment example, the alternative hypothesis is that there is in fact an average difference in blood pressure between the treatment and control groups. \n",
    "\n",
    "> $H_A:$ The parameter of interest — our average difference between treatment and control — is not zero.\n",
    "\n",
    "Or, in math:\n",
    "\n",
    "> $H_A: \\mu_\\text{trt} \\ne \\mu_\\text{ctrl}$\n",
    "\n",
    "Again, we usually write\n",
    "\n",
    "> $H_A: \\mu_\\text{trt} - \\mu_\\text{ctrl} \\ne 0$\n",
    "\n",
    "**NOTE:** The null and alternative hypotheses are concerned with the true values, or, in other words, the **parameter of the overall population**. Through hypothesis testing, we will make an **inference** (a decision) about this population parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is it written like this? $\\mu$ vs $\\bar{x}$\n",
    "(THREAD) Can you remind me what a *population parameter* is?\n",
    "\n",
    "(THREAD) Can you remind me what a *sample statistic* is?\n",
    "\n",
    "Population parameters are often denoted with Greek letters. It would make no sense to conduct a hypothesis test with sample statistics, since they differ with each experiment, and you don't need to hypothesize about them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to the $t$-Test\n",
    "\n",
    "---\n",
    "\n",
    "In our dog example, we gathered data in a way that's different from how we'll usually gather data in order to make a decision.\n",
    "\n",
    "Say that, in our drug experiment, we measure the following results:\n",
    "\n",
    "- The 50 subjects in the control group have an average systolic blood pressure of 121.38.\n",
    "- The 50 subjects in the experimental/treatment group have an average systolic blood pressure of 111.56.\n",
    "\n",
    "The difference between experimental and control samples is -9.82 points. \n",
    "\n",
    "**But**, with only 50 subjects in each sample, how confident can we be that this measured difference is real? Do we have enough evidence to say that the population average blood pressure is different between these two groups?\n",
    "\n",
    "We can perform what is known as a **t-test** to evaluate this. (A $t$-test is one of many, many types of hypothesis tests.)\n",
    "\n",
    "Four steps to hypothesis testing:\n",
    "1. Construct a null hypothesis that you want to contradict and its complement, the alternative hypothesis.\n",
    "2. Specify a level of significance.\n",
    "3. Calculate your test statistic.\n",
    "4. Find your $p$-value and make a conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bp</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>166</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>165</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bp    group\n",
       "0  166  control\n",
       "1  165  control\n",
       "2  120  control\n",
       "3   94  control\n",
       "4  104  control"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp = pd.read_csv(\"../data/blood-pressure.csv\")\n",
    "bp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the blood pressure data into two separate vectors\n",
    "# (this is how we'll need it for a SciPy t-test)\n",
    "ctrl = bp.loc[bp[\"group\"] == \"control\", \"bp\"]\n",
    "trt = bp.loc[bp[\"group\"] == \"treatment\", \"bp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121.38\n",
      "111.56\n"
     ]
    }
   ],
   "source": [
    "# Print the average of the control and experimental groups.\n",
    "print(ctrl.mean())\n",
    "print(trt.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='likelihood-data'></a>\n",
    "\n",
    "### Step 1: Construct the null and alternative hypotheses\n",
    "\n",
    "---\n",
    "\n",
    "For our experiment, we will set up a null hypothesis and an alternative hypothesis:\n",
    "\n",
    "$H_0:$ The true mean difference in systolic blood pressure between those who receive the treatment and those who do not is 0.\n",
    "\n",
    "$H_A:$ The true mean difference in systolic blood pressure between those who receive the treatment and those who do not is NOT 0.\n",
    "\n",
    "### Formally:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "H_0: & \\mu_\\text{trt} = \\mu_\\text{ctrl} \\\\\n",
    "H_A: & \\mu_\\text{trt} \\ne \\mu_\\text{ctrl} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Recall, our measured difference is $\\bar{x}_\\text{trt} - \\bar{x}_\\text{ctrl} = -9.82$\n",
    "\n",
    "Written out using probability notation, we want to know:\n",
    "\n",
    "### $$P(\\text{data}\\;|\\;H_0 \\text{ true})$$\n",
    "\n",
    "**What is the probability that we observed this data, assuming that our null hypothesis is true?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Specify a level of significance\n",
    "\n",
    "If we assume that our null hypothesis is true, and the probability of observing the data we observed is \"small,\" then our data does not support our null hypothesis. \n",
    "\n",
    "**But how \"small\" is small enough?**\n",
    "\n",
    "This is set by our level of significance, which we call $\\alpha$.\n",
    "\n",
    "Typically (and arbitrarily) the value $\\alpha=0.05$ is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Calculating your Test Statistic\n",
    "\n",
    "---\n",
    "\n",
    "Remember that hypothesis testing is a \"box\" where the inputs are our data and the outputs allow us to make our decision? Well, in this \"box,\" we are calculating $P(\\text{data}\\;|\\;H_0 \\text{ true})$.\n",
    "\n",
    "When comparing two means, the **t-statistic** (based on the [Student's $t$-distribution](https://en.wikipedia.org/wiki/Student%27s_t-distribution)) is a classic way to quantify the difference between groups. In essence, our $t$-statistic is a standardized version of the difference between groups.\n",
    "\n",
    "Luckily, our computer will do this for us!\n",
    "\n",
    "---\n",
    "\n",
    "<details><summary>Want the mathematical details of the calculation of the t-statistic?</summary>\n",
    "When comparing the difference between groups, we can calculate the two-sample t-statistic like so:\n",
    "\n",
    "### $$t = \\frac{\\bar{x}_E - \\bar{x}_C}{\\sqrt {s^2 \\Big(\\frac{1}{n_E} + \\frac{1}{n_C}\\Big)}}$$\n",
    "\n",
    "In our example, $\\bar{x}_E$ is the mean of our experimental group's sample measurements and $\\bar{x}_C$ is the mean of our control group's sample measurements.\n",
    "\n",
    "$n_E$ and $n_C$ are the number of observations in each group. \n",
    "\n",
    "The $s^2$ denotes our *sample variance*. In this version of the t-test, we are assuming equal variances in our experimental and control groups in the overall population. There is another way to calculate the t-test where equal variance is not assumed, but, in our case, it is a reasonable assumption.\n",
    "\n",
    "The sample variance is calculated like so:\n",
    "\n",
    "### $$ s^2 = \\frac{\\sum_{i=1}^{n_E} (x_i - \\bar{x}_E)^2 + \\sum_{j=1}^{n_C} (x_j - \\bar{x}_C)^2}{ n_E + n_C -2} $$\n",
    "\n",
    "This combines the variance of the two groups' measurements into a single pooled metric. \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TL;DR What are we doing?\n",
    "\n",
    "**GOAL:** To tell whether or not our new treatment is effective. We define \"effective\" as whether or not those who get the treatment see lower systolic blood pressure, on average.\n",
    "\n",
    "To do this, we follow the following steps to carry out a **hypothesis test**:\n",
    "\n",
    "1. Set up null and alternative hypotheses. Remember, ours was this:\n",
    "\n",
    "$$ H_0: \\mu_\\text{trt} - \\mu_\\text{ctrl} = 0 $$\n",
    "$$ H_A: \\mu_\\text{trt} - \\mu_\\text{ctrl} \\ne 0 $$\n",
    "\n",
    "2. Decide on a significance level. $\\alpha = 0.05$ is a typical choice.\n",
    "3. Decide on a hypothesis test. There are a million of them. In this case, we're testing the difference between two means, which is a great time to use a **two-sample $t$-test**.\n",
    "\n",
    "> The two-sample (independent) $t$-test tests whether or not two population means differ.\n",
    "\n",
    "4. After carrying out this hypothesis test, we'll see if our data provide enough evidence to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do it!\n",
    "Uh... how? What function do I use? Help me, Google!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scipy.stats\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-1.8915462966190273, pvalue=0.06161817112302221)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conduct our t-test.\n",
    "stats.ttest_ind(trt, ctrl, equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stat, p_value = stats.ttest_ind(trt, ctrl, equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p-value'></a>\n",
    "\n",
    "### Step 4: The P-Value\n",
    "\n",
    "---\n",
    "\n",
    "Remember that our goal of doing all of this work is to make a decision? Well, using our $t$-statistic, we can generate a **p-value**.\n",
    "\n",
    "> **The p-value is the probability that, given that the null hypothesis $H_0$ is true, we could have ended up with a statistic at least as extreme as the one we got.**\n",
    "\n",
    "We have measured a difference in blood pressure of -9.82 between the experimental and control groups. We then calculated a $t$-statistic associated with this difference of -1.89. In our specific example:\n",
    "\n",
    "> The p-value is the probability that, assuming there is truly no difference in blood pressure between treatment and control conditions (i.e., no effect of the drug), we get results that yield a t-statistic more extreme than -1.89."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So how do we make the decision? *(This will show up in interviews!)*\n",
    "\n",
    "Remember that $\\alpha$ is our level of significance.\n",
    "\n",
    "- If $p\\text{-value} < \\alpha$, then there is evidence to reject the null hypothesis, so you accept that $H_0$ is incorrect and therefore $H_A$ is correct.\n",
    "    - i.e., a statisically significant difference between the two groups!\n",
    "    - This is like saying there is enough evidence to say our dog isn't innocent... so we say our dog is guilty.\n",
    "- If $p\\text{-value} \\ge \\alpha$, then there is insufficient evidence to reject the null hypothesis and you cannot accept that either $H_0$ or $H_A$ is correct.\n",
    "    - i.e., there is no statistical difference between your two groups.\n",
    "    - This is like saying there is not enough evidence to say our dog isn't innocent. We can't totally determine that our dog is innocent, but we haven't determined that our dog is guilty, either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So.... what is our decision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **DECISION:** Because our $p$-value is greater than our $\\alpha = 0.05$, we fail to reject our null hypothesis. We do not have enough evidence to conclude that the mean systolic blood pressure differs between the treatment and placebo group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just for good measure... what's the opposite opinion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **DECISION:** Because our p-value was below 0.05, we reject the null hypothesis and conclude that the mean blood pressure between the treatment and control group differs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Law of Parsimony (aka: Occam's Razor)\n",
    "This is usually paraphrased as:\n",
    "> The simplest explanation for a phenomenon is usually the correct one.\n",
    "\n",
    "We don't want to overspecify our model. In our context, that means we want to avoid any potential overfitting. While we **never accept the null hypothesis**, the truth is, _some decision must be made_. Oftentimes, we drop variables from our model that do not have significant $p$-values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Hypothesis Tests\n",
    "The goal of this lesson was to teach you, in general, how hypothesis testing works. We showed you what is probably the most common variety of hypothesis test: the $t$-test. However, there are kajillions of other ones out there. It's not worth our time to go over so many more of them, as they all have the same implementation and interpretation, just in different situations. Instead, here is a list of many of the \"big\" ones and when to use them:\n",
    "\n",
    "| Situation | Common hypothesis test | Example | Notes |\n",
    "| --- | --- | --- | --- |\n",
    "| Testing whether or not one mean is equal to a value | One-sample $t$-test | Do cars on a given road, on average, drive about 65mph? | |\n",
    "| Testing whether or not two means are equal to eachother | Two-sample $t$-test | Is the mean systolic blood pressure of people who receive Medicine A or Medicine B the same? | |\n",
    "| Testing whether or not paired observations have the same value | Paired $t$-test | Among heterosexual married couples, is the husband, on average, taller than the wife? | This is functionally the same as a one-sample $t$-test of the differences |\n",
    "| Testing whether or not three or more means are the same | One-way ANOVA test | Are base salaries upon graduation different for graduates of Penn State, Ohio State, and Michigan? | The ANOVA test has many variants |\n",
    "| Testing whether or not there is a relationship between two categorical variables | $\\chi^2$ test | Is there a relationship between home state and political affiliation? | |\n",
    "| Testing whether or not a given distribution is normally distributed | Kolmogorov-Smirnov Test | Testing whether or not model residuals are normally distributed. Useful for testing linear regression assumptions! | |\n",
    "| Testing whether or not one proportion is equal to a number | One-sample $z$-test | Testing whether or not a coin is fair (ie, testing $P(Heads) = 0.5$) | |\n",
    "| Testing whether or not two proportions are euqal | Two-sample $z$-test | Who is going to win an election? | Testing two or more proportions can be done better with a $\\chi^2$ test |\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "Four steps to hypothesis testing:\n",
    "1. Construct a null hypothesis that you want to contradict and its complement, the alternative hypothesis.\n",
    "2. Specify a level of significance.\n",
    "3. Calculate your test statistic.\n",
    "4. Find your $p$-value and make a conclusion."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
