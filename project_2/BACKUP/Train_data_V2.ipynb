{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6992f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.linear_model import (\n",
    "    Ridge,RidgeCV,\n",
    "    Lasso,LassoCV,\n",
    "    ElasticNet, ElasticNetCV,\n",
    "    LinearRegression\n",
    ")\n",
    "from sklearn.model_selection import(\n",
    "    cross_val_score,\n",
    "    train_test_split\n",
    ")\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    PolynomialFeatures\n",
    ")\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "pd.set_option('display.max_rows', 1000)  # or 1000\n",
    "pd.set_option('display.max_columns', 1000)  # or 1000\n",
    "\n",
    "from itertools import combinations\n",
    "from itertools import permutations\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d780865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be78a10b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5514391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column names \n",
    "\n",
    "new_columns = {\n",
    "    'Id': 'id',\n",
    "    'PID':'pid',\n",
    "    'MS SubClass': 'ms_subclass',\n",
    "    'MS Zoning': 'ms_zoning',\n",
    "    'Lot Frontage': 'lot_front',\n",
    "    'Lot Area': 'lot_area',\n",
    "    'Street': 'street',\n",
    "    'Alley':'alley',\n",
    "    'Lot Shape': 'lot_shape',\n",
    "    'Land Contour':'land_contour',\n",
    "    'Utilities': 'util',\n",
    "    'Lot Config': 'lot_config',\n",
    "    'Land Slope': 'land_slope',\n",
    "    'Neighborhood': 'neighborhood',\n",
    "    'Condition 1': 'cond_1',    \n",
    "    'Condition 2': 'cond_2',\n",
    "    'Bldg Type': 'bldg_type',\n",
    "    'House Style': 'house_style',\n",
    "    'Overall Qual': 'overall_qual',\n",
    "    'Overall Cond': 'overall_cond',\n",
    "    'Year Built': 'year_built',\n",
    "    'Year Remod/Add': 'year_remod_add',\n",
    "    'Roof Style': 'roof_style',\n",
    "    'Roof Matl': 'roof_matl',\n",
    "    'Exterior 1st': 'ext_1st',\n",
    "    'Exterior 2nd': 'ext_2nd',\n",
    "    'Mas Vnr Type': 'mas_vnr_type',\n",
    "    'Mas Vnr Area': 'mas_vnr_area',\n",
    "    'Exter Qual': 'exter_qual',\n",
    "    'Exter Cond': 'exter_cond',\n",
    "    'Foundation': 'foundation',\n",
    "    'Bsmt Qual': 'bsmt_qual',\n",
    "    'Bsmt Cond': 'bsmt_cond',\n",
    "    'Bsmt Exposure': 'bsmt_exposure',\n",
    "    'BsmtFin Type 1': 'bsmtfin_type1',\n",
    "    'BsmtFin SF 1': 'bsmtfin_sf1',\n",
    "    'BsmtFin Type 2': 'bsmt_type2',\n",
    "    'BsmtFin SF 2': 'bsmt_sf2',\n",
    "    'Bsmt Unf SF': 'bsmt_unf_sf',\n",
    "    'Total Bsmt SF': 'total_bsmt_sf',\n",
    "    'Heating': 'heating',\n",
    "    'Heating QC': 'heating_qc',\n",
    "    'Central Air': 'central_air',\n",
    "    'Electrical': 'electrical',\n",
    "    '1st Flr SF': '1st_flr_sf',\n",
    "    '2nd Flr SF': '2nd_flr_sf',\n",
    "    'Low Qual Fin SF': 'low_qual_fin_sf',\n",
    "    'Gr Liv Area': 'gr_liv_area',\n",
    "    'Bsmt Full Bath': 'bsmt_full_bath',    \n",
    "    'Bsmt Half Bath': 'bsmt_half_bath',\n",
    "    'Full Bath': 'full_bath',\n",
    "    'Half Bath': 'half_bath',\n",
    "    'Bedroom AbvGr': 'bedroom_abv_gr',\n",
    "    'Kitchen AbvGr': 'kitchen_abv_gr',\n",
    "    'Kitchen Qual': 'kitchen_qual',\n",
    "    'TotRms AbvGrd': 'tot_rms_abv_grd',\n",
    "    'Functional': 'functional',\n",
    "    'Fireplaces': 'fireplace',\n",
    "    'Fireplace Qu': 'fireplace_qu',\n",
    "    'Garage Type': 'garage_type',\n",
    "    'Garage Yr Blt': 'garage_yr_blt',\n",
    "    'Garage Finish': 'garage_finish',\n",
    "    'Garage Cars': 'garag_cars',\n",
    "    'Garage Area': 'garage_area',\n",
    "    'Garage Qual': 'garage_qual',\n",
    "    'Garage Cond': 'garage_cond',\n",
    "    'Paved Drive': 'paved_drive',\n",
    "    'Wood Deck SF': 'wood_deck_sf',\n",
    "    'Open Porch SF': 'open_porch_sf',\n",
    "    'Enclosed Porch': 'enclosed_porch',\n",
    "    '3Ssn Porch': '3ssn_porch',\n",
    "    'Screen Porch': 'screen_porch',\n",
    "    'Pool Area': 'pool_area',\n",
    "    'Pool QC': 'pool_qc',\n",
    "    'Fence': 'fence',\n",
    "    'Misc Feature': 'misc_feature',\n",
    "    'Misc Val': 'misc_val',\n",
    "    'Mo Sold': 'mo_sold',\n",
    "    'Yr Sold': 'yr_sold',\n",
    "    'Sale Type': 'sale_type',\n",
    "    'SalePrice':'sale_price',\n",
    "}\n",
    "\n",
    "df.rename(columns=new_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037214c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef4d9e7",
   "metadata": {},
   "source": [
    "## EDA\n",
    "- **Read the data dictionary.**\n",
    "- Determine _what_ missing values mean.\n",
    "- Figure out what each categorical value represents.\n",
    "- Identify outliers.\n",
    "- Consider whether discrete values are better represented as categorical or continuous. (Are relationships to the target linear?)\n",
    "\n",
    "## Data Cleaning\n",
    "- Decide how to impute null values.\n",
    "- Decide how to handle outliers.\n",
    "- Do you want to combine any features?\n",
    "- Do you want to have interaction terms?\n",
    "- Do you want to manually drop collinear features?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a378a58e",
   "metadata": {},
   "source": [
    "**Clean missing values**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5ea01f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88975dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b413b50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fba701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build list of features with na \n",
    "\n",
    "feature_nan = [feature for feature in df.columns if df[feature].isnull().sum()]\n",
    "for feat in feature_nan:\n",
    "    print(feat, f'has {round((df[feat].isnull().mean())*100,2)}% missing values')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a427cb64",
   "metadata": {},
   "source": [
    "**Some missing values are bigger percentage than the other** \n",
    "\n",
    "- we need to find the correlation between the missing values and the sales price to judge if its good to remove or to keep\n",
    "\n",
    "**Approach**\n",
    "\n",
    "1) Larger values - might remove\n",
    "\n",
    "2) Smaller values - need to conduct EDA and decide later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc174e01",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lot_font has normal distrubtion centered across mean of 69\n",
    "\n",
    "sns.histplot(x = 'lot_front', data =df)\n",
    "print(df['lot_front'].mean())\n",
    "print(df['lot_front'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d55f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean and fill into NA\n",
    "# why mean -->> because normally distributed centered at mean 69. \n",
    "df['lot_front'].fillna(df['lot_front'].mean(),inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665ba645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lot_font has normal distrubtion centered across mean of 69\n",
    "\n",
    "sns.histplot(x = 'lot_front', data =df)\n",
    "print(df['lot_front'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d0cb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change 'nan' to NoAlleyAccess\n",
    "df['alley'] = df['alley'].map(lambda x: 'NoAlley' if pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc08359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# no meaning to the sales \n",
    "# drop alley\n",
    "\n",
    "sns.boxplot(\n",
    "    data = df,\n",
    "    x = 'alley',\n",
    "    y = 'sale_price'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00e423f",
   "metadata": {},
   "source": [
    "Boxplot shows strong outliers in NoAlley, hence if need to use this data, has to clear outliers first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47e2548",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mas_vnr_type -->> categorical, insert most common type \n",
    "df.groupby(by='mas_vnr_type').count()['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525d5421",
   "metadata": {},
   "source": [
    "mas_vnr_type already has a None column. Will need to classify nan into the mode of the types for minimal impact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc1e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values with mode of mas_vnr_type\n",
    "df['mas_vnr_type'].fillna(df['mas_vnr_type'].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b846c987",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checked categories for mas_vnr_area\n",
    "# found if mas vnr area == 0, then belongs to none\n",
    "sns.histplot(x = 'mas_vnr_area', hue = 'mas_vnr_type', data =df)\n",
    "plt.xlim(0,600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a738592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking nominal category: mas_vnr_type against sale price\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.boxplot(\n",
    "    x = 'mas_vnr_type',\n",
    "    y = 'sale_price',\n",
    "    data = df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcd5418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary that stores mean of\n",
    "mas_dict_mean = {key:val for key, val in df.groupby(['mas_vnr_type'])['mas_vnr_area'].mean().iteritems()}\n",
    "\n",
    "mas_dict_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96617690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function that returns mean based on mas_dict_mean if column has null values \n",
    "def enter_area(col):\n",
    "    area = col[0]\n",
    "    mas_type = col[1]\n",
    "    if pd.isnull(area):\n",
    "        return mas_dict_mean[mas_type]\n",
    "    else:\n",
    "        return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8c0760",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fill in null values for -->> mas_vnr_area\n",
    "df['mas_vnr_area'] = df[['mas_vnr_area', 'mas_vnr_type']].apply(enter_area, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f65adcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# missing values seems common across about bsmt columns \n",
    "df[df['bsmt_exposure'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef25ca63",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create pairplot to check relationship between all bsmt parameters against sale_price\n",
    "# noticed only total_basement_sf area has high correlation with sale_price\n",
    "# checked only 58 out of 2051 data has NAN -->> meaning no basement \n",
    "# will want to change all null to 'NoBsmt'\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "sub_bsmt = ['bsmt_qual', 'bsmt_cond', 'bsmt_exposure',\n",
    "       'bsmtfin_type1', 'bsmtfin_sf1', 'bsmt_type2', 'bsmt_sf2', 'bsmt_unf_sf',\n",
    "       'total_bsmt_sf', 'sale_price']\n",
    "\n",
    "sns.pairplot(\n",
    "    df,\n",
    "    x_vars = sub_bsmt,\n",
    "    y_vars = ['sale_price'],\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c160163",
   "metadata": {},
   "source": [
    "**EDA on basement null values**\n",
    "\n",
    "bsmt_qual            55 null values\n",
    "\n",
    "bsmt_cond            55 null values\n",
    "\n",
    "bsmt_exposure        58 null values\n",
    "\n",
    "bsmtfin_type1        55 null values\n",
    "\n",
    "bsmtfin_sf1           1 null values\n",
    "\n",
    "bsmt_type2           56 null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf314b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Checked most of the categories have null values as there is no basement. \n",
    "\n",
    "df.loc[df['bsmt_exposure'].isnull(), ['bsmt_qual', 'bsmt_cond', 'bsmt_exposure',\n",
    "       'bsmtfin_type1', 'bsmtfin_sf1', 'bsmt_type2', 'bsmt_sf2', 'bsmt_unf_sf',\n",
    "       'total_bsmt_sf']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10882ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create none category for those without basement\n",
    "df['bsmt_cond'].fillna('NoBsmt',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7dc994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross check category, makes sense that those without basement will have lowest mean sale price \n",
    "sns.boxplot(\n",
    "    x = 'bsmt_cond',\n",
    "    y = 'sale_price',\n",
    "    data = df,\n",
    "    order = ['Ex','Gd', 'TA', 'Fa', 'Po', 'NoBsmt']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195e3b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create none category for those without basement\n",
    "df['bsmt_type2'].fillna('NoBsmt',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25765414",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# notice higher prices are under unfinised. \n",
    "# no basement is the lowest mean score, which fits the ordinal flow. \n",
    "\n",
    "sns.boxplot(\n",
    "    x = 'bsmt_type2',\n",
    "    y = 'sale_price',\n",
    "    data = df,\n",
    "    order = ['GLQ', 'ALQ','BLQ','Rec','LwQ','Unf','NoBsmt']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24f82ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# since it is numerical cat, need to take a look at mean. \n",
    "# found those with null, average sale price is lower than all the other cats \n",
    "# hence safe to create another cat for None. \n",
    "\n",
    "bsmt_mean_null = df.loc[df['bsmt_exposure'].isnull(), 'sale_price'].mean()\n",
    "bsmt_mean = df.groupby('bsmt_exposure').mean()['sale_price']\n",
    "print(f'mean of null values: {bsmt_mean_null}')\n",
    "print('\\n')\n",
    "print(f'Mean values of basement exposure: {bsmt_mean}')\n",
    "df['bsmt_exposure'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecd10af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create none category for those without basement\n",
    "df['bsmt_exposure'].fillna('NoBsmt',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fd3f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross checked ordinally correct for No basement cat\n",
    "sns.boxplot(\n",
    "    x = 'bsmt_exposure',\n",
    "    y = 'sale_price',\n",
    "    data = df,\n",
    "    order = ['Gd','Av','Mn','No','NoBsmt']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2529dc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill up null values with NoBsmt\n",
    "df['bsmt_qual'].fillna('NoBsmt', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a5e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross checked ordinally correct for No basement cat\n",
    "sns.boxplot(\n",
    "    x = 'bsmt_qual',\n",
    "    y = 'sale_price',\n",
    "    data = df,\n",
    "    order = ['Ex','Gd', 'TA', 'Fa', 'Po', 'NoBsmt']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fac2c71",
   "metadata": {},
   "source": [
    "**Seeing small points for Po** \n",
    "- might need to remove it if want to use this variable as it might skew predicted data inaccurately. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b721c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill up null values with NoBsmt\n",
    "df['bsmtfin_type1'].fillna('NoBsmt', inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf651a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross checked ordinally correct for No basement cat\n",
    "\n",
    "sns.boxplot(\n",
    "    x = 'bsmtfin_type1',\n",
    "    y = 'sale_price',\n",
    "    data = df,\n",
    "    order = ['GLQ', 'ALQ','BLQ','Rec','LwQ','Unf','NoBsmt']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfaf069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checked row has no basement\n",
    "df[df['total_bsmt_sf'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783cf585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace na with 0 feet square\n",
    "\n",
    "df['bsmtfin_sf1'].fillna(0, inplace = True) \n",
    "df['bsmt_sf2'].fillna(0, inplace = True) \n",
    "df['total_bsmt_sf'].fillna(0, inplace = True) \n",
    "df['bsmt_unf_sf'].fillna(0, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a6c37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(\n",
    "    x = 'fireplace_qu',\n",
    "    y = 'sale_price',\n",
    "    data = df,\n",
    "    order = ['Ex', 'Gd', 'TA', 'Fa', 'Po'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c12340",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Establish size of figure.\n",
    "plt.figure(figsize = (10,5))\n",
    "\n",
    "\n",
    "sns.boxplot(\n",
    "    x = 'fireplace',\n",
    "    y = 'sale_price',\n",
    "    data = df,\n",
    "#     hue = 'fireplace_qu',\n",
    "#     hue_order = ['Ex', 'Gd', 'TA', 'Fa', 'Po'],\n",
    "    width = 0.6\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffa08c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby('fireplace')['fireplace'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5921073",
   "metadata": {},
   "source": [
    "**Observed rating 4 having only one point, might need to remove this variable if need to use as results might be skewed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b243b2c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# null values contain sale price mean close to 144000\n",
    "df[df['fireplace_qu'].isnull()].agg(['mean', 'median'])['sale_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e411f28e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# found that cat Po suites best for null values to be included without affecting much mean \n",
    "df.groupby(['fireplace_qu']).agg(['mean', 'median', 'count'])['sale_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bf914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill na with NoFireplace\n",
    "df['fireplace_qu'] = df['fireplace_qu'].fillna('NoFireplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb838d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross checked ordinally correct for nofireplace\n",
    "sns.boxplot(\n",
    "    x = 'fireplace_qu',\n",
    "    y = 'sale_price',\n",
    "    data = df,\n",
    "    order = ['Ex', 'Gd', 'TA', 'Fa', 'Po','NoFireplace'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e51eec",
   "metadata": {},
   "source": [
    "**Can see alot of outliers in Gd, TA, and Po (after adding NAN) inside. Hence, this might not be good to insert into our model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6d3466",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(\n",
    "    y_vars = 'sale_price',\n",
    "    x_vars = ['garage_type',\n",
    "    'garage_yr_blt', 'garage_finish', 'garag_cars', 'garage_area',\n",
    "    'garage_qual', 'garage_cond','sale_price'],\n",
    "    data = df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a90f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in None for now, might drop categorical columns if need to refine model\n",
    "\n",
    "df['garage_type'] = df['garage_type'].fillna('NoGarage')\n",
    "df['garage_finish'] = df['garage_finish'].fillna('NoGarage')\n",
    "df['garage_qual'] = df['garage_qual'].fillna('NoGarage')\n",
    "df['garage_cond'] = df['garage_cond'].fillna('NoGarage')\n",
    "\n",
    "df['garage_area'].fillna(df['garage_area'].mean(),inplace = True)\n",
    "df['garag_cars'].fillna(df['garag_cars'].mode()[0],inplace = True)\n",
    "# drop garage year built as null values cannot be replaced, it cannot be replaced by any random values or mean too. \n",
    "\n",
    "df.drop(columns = ['garage_yr_blt'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89485c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# noticed when pool area ==0, other categories also null \n",
    "\n",
    "df[df['pool_area'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e07f99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# too little points to do correlation for pool area \n",
    "\n",
    "sns.pairplot(\n",
    "    x_vars = ['pool_area', 'pool_qc', 'fence', 'misc_feature', 'sale_price'],\n",
    "    y_vars = 'sale_price',\n",
    "    data = df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cef8bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all pool columns \n",
    "\n",
    "drop_pool_list = ['pool_qc', 'fence', 'misc_feature']\n",
    "\n",
    "df = df.drop(columns = drop_pool_list, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915ffc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeing decreasing trend, and exceptionally high cost built recently \n",
    "sns.scatterplot(\n",
    "    x = 'year_built',\n",
    "    y = 'sale_price',\n",
    "    data = df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879d937c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.histplot(x = 'sale_price', data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411f80c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sale_price_classified'] = df['sale_price'].apply(lambda x: 2 if x > 450000 else 1 if ((x < 450000) & (x > 300000)) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725b6b2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e3a1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in df.columns:\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    fig = sns.histplot(x = var, data = df, hue = 'sale_price_classified', color = 'tab10')\n",
    "    fig.set_title('')\n",
    "    fig.set_xlabel(var)\n",
    "    fig.set_ylabel('Counts')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db98238",
   "metadata": {},
   "outputs": [],
   "source": [
    "['exter_qual',\n",
    " 'kitchen_qual',\n",
    " 'bsmt_qual',\n",
    " 'garage_finish',\n",
    " 'fireplace_qu',\n",
    " 'bsmtfin_type1',\n",
    " 'heating_qc',\n",
    " 'bsmt_exposure',\n",
    " 'overall_cond',\n",
    " 'lot_shape']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e95f960",
   "metadata": {},
   "source": [
    "**Variables not to use/may not use*\n",
    "\n",
    "id, pid --> no relevance \n",
    "\n",
    "ms_subclass, ms_zoning, cond1, cond2, bldg_type,house_style, overall_cond, ext_1st, ext_2nd, mas_vnr_type,mas_vnr_area\n",
    "bsmt_cond, bsmt_exposure, bsmt_unf_sf, 2nd_Flor_sf, low_qual_fin_sf, bsmt_full_bath,  bsmt_half_bath, full_bath, half_bath, \n",
    "bedroom_abv_grd, kitchen_abv_grd , open_porch_sf, wood_deck_sf, \n",
    "\n",
    "--> overlaps with higher sale price, nt in order, hence not good \n",
    "\n",
    "pave, no alley, lot shape, land_cotour,util, lot_config, land_slope,roof_style, roof_matl,exter_cond,foundation, \n",
    "bsmtfin_type1, bsmt_type2, bsmt_sf2, heating, central_air, electrical, paved_drive, \n",
    "->> majority classified under low sale price, which may skew predicted price lower \n",
    "\n",
    "bsmtfin_sf1 --> good distribution against sale price clsuter, but having cluster even at near zero with high sale price\n",
    "year_sold --> not much \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e866d5c",
   "metadata": {},
   "source": [
    "**Variables to use**\n",
    "\n",
    "1) lot_front -> distribution is clear against sale price\n",
    "\n",
    "2) lot_area -> distribution is clear against sale price, but need to take care of above 20000\n",
    "\n",
    "3) Neighbourhood --> can see clusters of higher cost housing in certain areas\n",
    "\n",
    "4) Overall_qual --> positively correlated to ordinal cat against sale price\n",
    "\n",
    "5) year_built --> the latest it was built in, the higher the price, need to watch for cluster after year 2000\n",
    "\n",
    "6) year_removd_add --> the latest it was built in, the higher the price, need to watch for cluster after year 2000\n",
    "\n",
    "7) exter_qual --> positively correlated to ordinal cat against sale price, cluster in EX\n",
    "\n",
    "8) bsmt_qual --> positively correlated to ordinal cat against sale price, cluster in EX\n",
    "\n",
    "9) heating_qc --> most high end sale price are in ex, need watch for cluster at ex with normal sale price. \n",
    "              --> can consider interaction terms with other quals to be more accurate for higher selling price\n",
    "              \n",
    "              \n",
    "10) total_bsmt_sf --> distribution is clear against sale price, need to create categorical separate by 3 sale groups for interactions \n",
    "\n",
    "11) 1st_flor_sf -->  distribution is clear against sale price, need to create categorical separate by 3 sale groups for interactions \n",
    "\n",
    "12) gv_liv_area-->  distribution is clear against sale price, need to create categorical separate by 3 sale groups for interactions \n",
    "\n",
    "13) kitchen_qual -->  distribution is clear against sale price, need to create categorical separate by 3 sale groups for interactions \n",
    "\n",
    "14) garage_finish --> ordinal cat matches with sales prices. \n",
    "\n",
    "15) fireplace_qu -> ordinal cat matches with sales prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cf76a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.histplot(x = 'lot_area', data = df, hue = 'sale_price_classified', bins =500)\n",
    "\n",
    "plt.xlim(1000,60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7040fc96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby('sale_price_classified')['lot_area'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6382de17",
   "metadata": {},
   "source": [
    "**Will need to do iteraction term with lot area classified into 3 main cat and interact with lot area it self**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dbebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.histplot(x = 'total_bsmt_sf', data = df, hue = 'sale_price_classified', bins =200)\n",
    "\n",
    "plt.xlim(1000,3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a34c92",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.groupby('sale_price_classified')['total_bsmt_sf'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20ed26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "sns.histplot(x = 'neighborhood', data = df, hue = 'sale_price_classified')\n",
    "\n",
    "# plt.xlim(1000,3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58007f17",
   "metadata": {},
   "source": [
    "**comments**\n",
    "1) Northridge Heights, Stone Brook and Northridge has majority high sale price housing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeabb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd35be9",
   "metadata": {},
   "source": [
    "### Filter out numerical, and categorical (Ordinal) features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6cfa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [col for col in df.columns if df[col].dtype == 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accf738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [col for col in df.columns if df[col].dtype != 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3ad6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_cat = ['lot_shape','util','land_slope','exter_qual','exter_cond','bsmt_qual','bsmt_cond','bsmt_exposure',\n",
    "               'bsmtfin_type1','bsmt_type2','electrical','kitchen_qual','functional','fireplace_qu','garage_finish',\n",
    "               'garage_qual','garage_cond','paved_drive','overall_cond','heating_qc'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c6f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in ordinal_cat:\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    fig = sns.boxplot(x = var, y = 'sale_price', data = df)\n",
    "    fig.set_title('')\n",
    "    fig.set_xlabel(var)\n",
    "    fig.set_ylabel('Sale_price')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afae75de",
   "metadata": {},
   "source": [
    "## Pre - processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b62b96",
   "metadata": {},
   "source": [
    "**Converting categorical variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc294e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "alist = []\n",
    "ordinal_score_list = []\n",
    "for col in ordinal_cat:\n",
    "    # instantiate \n",
    "    alist = []\n",
    "    # append column \n",
    "    alist.append(col)\n",
    "    # applying OneHotCode\n",
    "    df_to_OHE = df[[col]]\n",
    "    # define one hot encoding\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    # transform data\n",
    "    feature_arr = encoder.fit_transform(df_to_OHE)\n",
    "    \n",
    "    feature_labels = encoder.categories_\n",
    "    feature_labels = np.array(feature_labels).ravel()\n",
    "    \n",
    "    feature_encoded = pd.DataFrame(feature_arr, columns = feature_labels )\n",
    "\n",
    "    # assign X and y\n",
    "\n",
    "    X = feature_encoded\n",
    "    y = df['sale_price']\n",
    "\n",
    "    # Create train/test splits.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.2,\n",
    "        random_state = 123\n",
    "    )\n",
    "\n",
    "    # Scale our data.\n",
    "    # Relabeling scaled data as \"Z\" is common.\n",
    "    sc = StandardScaler()\n",
    "    # Z_train = sc.fit_transform(X_train)\n",
    "    sc.fit(X_train) # fit should only see train data, \n",
    "                    #else if put in test, will have leak from the train data \n",
    "    X_train = sc.transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    lr = LinearRegression()\n",
    "\n",
    "    # cross val mse\n",
    "    cross_score = - cross_val_score(\n",
    "        lr,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv = 3,\n",
    "        scoring = 'neg_mean_squared_error'\n",
    "    ).mean()\n",
    "    # append cross score\n",
    "    alist.append(cross_score)\n",
    "    \n",
    "    ordinal_score_list.append(alist)\n",
    "\n",
    "\n",
    "ordinal_score_list = pd.DataFrame(ordinal_score_list)                   \n",
    "ordinal_score_list = ordinal_score_list.rename(columns = {0: 'Column', 1: 'Score'})\n",
    "ordinal_score_list = ordinal_score_list.sort_values(by = 'Score', ascending = True)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6a5529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# picking top 5 ordinal categorical columns for model fitting\n",
    "\n",
    "ordinal_score_list.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37497bd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['bsmt_full_bath'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaa6442",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# assign 0 to bsmt_full_bath since no basement \n",
    "df.loc[df['bsmt_full_bath'].isnull(), 'bsmt_full_bath'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86c5b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign 0 to bsmt_full_bath since no basement \n",
    "df.loc[df['bsmt_half_bath'].isnull(), 'bsmt_half_bath'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478d27a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copy of main df as Backup\n",
    "\n",
    "main_df = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a6e185",
   "metadata": {},
   "source": [
    "**numerical feature selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68568009",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['overall_qual', 'gr_liv_area', 'garage_area',\n",
    "       'garag_cars', '1st_flr_sf', 'total_bsmt_sf', 'year_built', 'full_bath',\n",
    "       'year_remod_add', 'tot_rms_abv_grd', 'mas_vnr_area', 'fireplace',\n",
    "       'bsmtfin_sf1', 'lot_front', 'open_porch_sf', 'wood_deck_sf', 'lot_area']\n",
    "\n",
    "variables_1 = ['overall_qual', 'gr_liv_area', 'garage_area',\n",
    "       'garag_cars', '1st_flr_sf', 'total_bsmt_sf', 'year_built', 'full_bath',\n",
    "       'year_remod_add', 'tot_rms_abv_grd', 'mas_vnr_area', 'fireplace',\n",
    "       'bsmtfin_sf1', 'lot_front', 'open_porch_sf', 'wood_deck_sf', 'lot_area',\n",
    "       'half_bath', 'bsmt_full_bath', '2nd_flr_sf', 'bsmt_unf_sf',\n",
    "       'screen_porch', 'bedroom_abv_gr', '3ssn_porch', 'mo_sold', 'pool_area',\n",
    "       'bsmt_sf2', 'misc_val', 'yr_sold', 'low_qual_fin_sf','bsmt_half_bath', 'ms_subclass', 'kitchen_abv_gr', 'overall_cond',\n",
    "       'enclosed_porch']\n",
    "\n",
    "variables_2 = ['overall_qual','gr_liv_area', 'garage_area',\n",
    "       'garag_cars', '1st_flr_sf', 'total_bsmt_sf', 'full_bath',\n",
    "        'tot_rms_abv_grd', 'mas_vnr_area', 'fireplace',\n",
    "       'bsmtfin_sf1','year_remod_add','year_built', 'lot_front']\n",
    "\n",
    "variables_3 = ['overall_qual', 'gr_liv_area', 'garage_area',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adf0ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cat = df[variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9052e4c6",
   "metadata": {},
   "source": [
    "**Ordinal Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e07e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose categorical columns \n",
    "\n",
    "columns = list(ordinal_score_list.head(10)['Column'].values)\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b505a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_cat = 0\n",
    "#increment by one for every field, used to differentiate between first iteration vs the rest\n",
    "i = 0\n",
    "\n",
    "for field in columns:\n",
    "    # assign df1 as temp df -->> and dummify it, drop first column too \n",
    " \n",
    "    df1 = pd.get_dummies(data = df[field], drop_first = True, columns = field, prefix = field)\n",
    "    \n",
    "    # if first iter, assign df final to copied of df1\n",
    "    if i == 0:\n",
    "        ord_cat = df1.copy()\n",
    "    # not first iter, concat with df_final to stack with dummified df1\n",
    "    else:\n",
    "         ord_cat = pd.concat([ord_cat, df1], axis = 1) \n",
    "            \n",
    "    i += 1\n",
    "\n",
    "ord_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240f742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat for model variables \n",
    "\n",
    "model_feat = pd.concat([num_cat,ord_cat], axis =1 )\n",
    "model_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd07faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_feat = pd.concat([model_feat,df['sale_price']], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280f4eba",
   "metadata": {},
   "source": [
    "### Polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02d90e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_feat = ['overall_qual','gr_liv_area', 'garage_area',\n",
    "       'garag_cars', '1st_flr_sf', 'total_bsmt_sf', 'full_bath',\n",
    "        'tot_rms_abv_grd', 'mas_vnr_area', 'fireplace',\n",
    "       'bsmtfin_sf1','year_remod_add','year_built', 'lot_front']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66a8ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_feat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4f37f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "empty_list = []\n",
    "df_combi_mse = []\n",
    "for val in list(combinations(model_feat.columns.drop(['sale_price','above300K_1']), 3)):\n",
    "    # instantiate empty list \n",
    "    empty_list = []\n",
    "\n",
    "    # append in combination\n",
    "    empty_list.append(list(val))\n",
    "\n",
    "    X = model_feat[list(val)]\n",
    "    y = model_feat['sale_price']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= np.random.seed(123))\n",
    "\n",
    "    # instantiate lr\n",
    "    lr = LinearRegression()\n",
    "\n",
    "    #append in cross score\n",
    "    empty_list.append(-cross_val_score(lr, X_train, y_train, cv=3, scoring ='neg_mean_squared_error').mean())   \n",
    "\n",
    "\n",
    "    df_combi_mse.append(empty_list)\n",
    "        \n",
    "df_combi_mse = pd.DataFrame(df_combi_mse)\n",
    "df_combi_mse = df_combi_mse.rename(columns = {0: 'Combinations', 1: 'Score'})\n",
    "df_combi_mse = df_combi_mse.sort_values(by = 'Score', ascending = True)\n",
    "df_combi_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb110b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_best_combi = list(df_combi_mse['Combinations'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef44e946",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_best_combi = [' '.join(level) for level in filter_best_combi] \n",
    "filter_best_combi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d685ed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[poly_feat]\n",
    "poly = PolynomialFeatures(include_bias=False, degree = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4a2f98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "poly.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48a06db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly = poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34ddb97",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5999fa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "poly_concat = pd.DataFrame(X_poly, columns=poly.get_feature_names(poly_feat))[filter_best_combi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c98379",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94de013d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_feat = pd.concat([model_feat,poly_concat], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce491de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd16542d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9e061d",
   "metadata": {},
   "source": [
    "**Log value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf3d225",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(\n",
    "    x_vars = variables,\n",
    "    y_vars = 'sale_price',\n",
    "    data = df\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4617ed9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_variables = ['year_built', 'year_remod_add', 'gr_liv_area', 'garage_area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8023604e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in log_variables:\n",
    "    data = model_feat.copy()\n",
    "    if 0 in data[feat].unique():\n",
    "        pass\n",
    "    else:\n",
    "        plt.figure(figsize=(15,6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        data[feat] = np.log(data[feat])\n",
    "        data['sale_price'] = np.log(data['sale_price'])\n",
    "        fig = sns.regplot(x = feat, y = 'sale_price', data = data)\n",
    "        fig.set_xlabel(feat)\n",
    "        fig.set_ylabel('Sale price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9870c9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(\n",
    "     x = 'sale_price',\n",
    "    data = data\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9357dad",
   "metadata": {},
   "source": [
    "**Apply Standard Scaler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2d61f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign X and y\n",
    "\n",
    "X = df[variables_1]\n",
    "y = df['sale_price']\n",
    "\n",
    "\n",
    "# Create train/test splits.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state = 123\n",
    ")\n",
    "\n",
    "# Scale our data.\n",
    "# Relabeling scaled data as \"Z\" is common.\n",
    "sc = StandardScaler()\n",
    "# Z_train = sc.fit_transform(X_train)\n",
    "sc.fit(X_train) # fit should only see train data, \n",
    "                #else if put in test, will have leak from the train data \n",
    "X_train = sc.transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd422562",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8420a634",
   "metadata": {},
   "source": [
    "**Linear Regression - First pass**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dd70a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "# cross val mse\n",
    "cross_score = - cross_val_score(\n",
    "    lr,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv = 3,\n",
    "    scoring = 'neg_mean_squared_error'\n",
    ").mean()\n",
    "\n",
    "# test mse\n",
    "mse_test = mean_squared_error(\n",
    "    y_test,\n",
    "    lr.predict(X_test)\n",
    ")\n",
    "# cross - test \n",
    "mse_train_minus_test = cross_score - mse_test\n",
    "\n",
    "if mse_train_minus_test > 0:\n",
    "    print(f'MSE for train: {cross_score}')\n",
    "    print(f'MSE for test: {mse_test}')\n",
    "    print(f'Underfited by: {mse_train_minus_test}')\n",
    "else:\n",
    "    print(f'MSE for train: {cross_score}')\n",
    "    print(f'MSE for test: {mse_test}')\n",
    "    print(f'Overfitted by: {mse_train_minus_test}')\n",
    "print(f'RMSE: {mse_test**0.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609c1b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noticed at higher ends of the sale_price,\n",
    "# model is calculating below real sales_price\n",
    "\n",
    "ax = sns.jointplot(\n",
    "    x = lr.predict(X_test),\n",
    "    y = y_test,\n",
    "    kind = 'reg'\n",
    ")\n",
    "ax.ax_joint.set_xlabel('Predicted Sale Price')\n",
    "ax.ax_joint.set_ylabel('Actual Sale Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb8f538",
   "metadata": {},
   "source": [
    "**Lasso Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5647ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate \n",
    "lasso = LassoCV(\n",
    "    cv=5,\n",
    "    max_iter=50000,\n",
    "    n_alphas=200,\n",
    ")\n",
    "\n",
    "# Fit model using best ridge alpha!\n",
    "lasso.fit(X_train, y_train);\n",
    "\n",
    "\n",
    "lasso.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb9e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_best = Lasso(alpha = lasso.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99396ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit lasso best \n",
    "\n",
    "lasso_best.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea81454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross val mse\n",
    "cross_score = - cross_val_score(\n",
    "    lasso_best,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv = 3,\n",
    "    scoring = 'neg_mean_squared_error'\n",
    ").mean()\n",
    "\n",
    "# test mse\n",
    "mse_test = mean_squared_error(\n",
    "    y_test,\n",
    "    lasso_best.predict(X_test)\n",
    ")\n",
    "# cross - test \n",
    "mse_train_minus_test = cross_score - mse_test\n",
    "\n",
    "if mse_train_minus_test > 0:\n",
    "    print(f'MSE for train: {cross_score}')\n",
    "    print(f'MSE for test: {mse_test}')\n",
    "    print(f'Underfited by: {mse_train_minus_test}')\n",
    "else:\n",
    "    print(f'MSE for train: {cross_score}')\n",
    "    print(f'MSE for test: {mse_test}')\n",
    "    print(f'Overfitted by: {mse_train_minus_test}')\n",
    "print(f'RMSE: {mse_test**0.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2016be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE for test: 1498556570.0823781\n",
    "# MSE for test: 1292841509.1969898\n",
    "# Underfited by: 205715060.88538837\n",
    "# RMSE: 14342.770335098738"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130c8e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noticed at higher ends of the sale_price,\n",
    "# model is calculating below real sales_price\n",
    "\n",
    "ax = sns.jointplot(\n",
    "    x = lasso_best.predict(X_test),\n",
    "    y = y_test,\n",
    "    kind = 'reg'\n",
    ")\n",
    "ax.ax_joint.set_xlabel('Predicted Sale Price')\n",
    "ax.ax_joint.set_ylabel('Actual Sale Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb3955a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lasso_best.predict(X_test).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300c8936",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find out index 339 having anomaly \n",
    "anomaly = {num: val for num,val in enumerate (lasso_best.predict(X_test)>638000) if val == True}\n",
    "anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c110a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.values[339]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c949df7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out other similar prices with 160000\n",
    "{num: val for num,val in enumerate (y_test == y_test.values[339]) if val == True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd34b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ab_val= pd.DataFrame(X_test[339])\n",
    "val1= pd.DataFrame(X_test[31])\n",
    "val2= pd.DataFrame(X_test[286])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a4a069",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ab_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b974c907",
   "metadata": {},
   "outputs": [],
   "source": [
    "val1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0684efcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "val2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc07bceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.concat([Ab_val,val1,val2], axis = 1)\n",
    "sample.columns = ['Ab', 'norm1', 'norm2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738d7c39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# True outlier compared to two other rows with similar coefficients against sale price\n",
    "\n",
    "sample.sort_values(by = 'Ab', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08caa1d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229fdc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index = 960, inplace = True)\n",
    "df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892df288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign X and y\n",
    "\n",
    "X = df[variables_1]\n",
    "y = df['sale_price']\n",
    "\n",
    "\n",
    "# Create train/test splits.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state = 123\n",
    ")\n",
    "\n",
    "# Scale our data.\n",
    "# Relabeling scaled data as \"Z\" is common.\n",
    "sc = StandardScaler()\n",
    "# Z_train = sc.fit_transform(X_train)\n",
    "sc.fit(X_train) # fit should only see train data, \n",
    "                #else if put in test, will have leak from the train data \n",
    "X_train = sc.transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1af68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate \n",
    "\n",
    "lasso = LassoCV(\n",
    "    cv=5,\n",
    "    max_iter=50000,\n",
    "    n_alphas=200,\n",
    ")\n",
    "# Fit model using best ridge alpha!\n",
    "lasso.fit(X_train, y_train)\n",
    "lasso_best = Lasso(alpha = lasso.alpha_)\n",
    "\n",
    "\n",
    "# fit lasso best with variables \n",
    "lasso_best.fit(X_train, y_train)\n",
    "\n",
    "# cross val mse\n",
    "cross_score = - cross_val_score(\n",
    "    lasso_best,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv = 3,\n",
    "    scoring = 'neg_mean_squared_error'\n",
    ").mean()\n",
    "\n",
    "# test mse\n",
    "mse_test = mean_squared_error(\n",
    "    y_test,\n",
    "    lasso_best.predict(X_test)\n",
    ")\n",
    "# cross - test \n",
    "mse_train_minus_test = cross_score - mse_test\n",
    "\n",
    "if mse_train_minus_test > 0:\n",
    "    print(f'MSE for train: {cross_score}')\n",
    "    print(f'MSE for test: {mse_test}')\n",
    "    print(f'Underfited by: {mse_train_minus_test}')\n",
    "else:\n",
    "    print(f'MSE for train: {cross_score}')\n",
    "    print(f'MSE for test: {mse_test}')\n",
    "    print(f'Overfitted by: {mse_train_minus_test}')\n",
    "print(f'RMSE: {mse_test**0.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d8e761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noticed at higher ends of the sale_price,\n",
    "# model is calculating below real sales_price\n",
    "\n",
    "ax2 = sns.jointplot(\n",
    "    x = lasso_best.predict(X_test),\n",
    "    y = y_test,\n",
    "    kind = 'reg'\n",
    ")\n",
    "ax2.ax_joint.set_xlabel('Predicted Sale Price - No log')\n",
    "ax2.ax_joint.set_ylabel('Actual Sale Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaeb448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hwo to plot the series \n",
    "plt.figure(figsize=(10,10))\n",
    "pd.Series(lasso_best.coef_, index = df[variables_1].columns).sort_values(ascending = False).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fac3da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.columns.drop(['sale_price', 'above300K_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6cde1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hwo to plot the series \n",
    "plt.figure(figsize=(10,10))\n",
    "pd.Series(lasso_best.coef_, index = data.columns.drop(['sale_price', 'above300K_1'])).sort_values(ascending = False).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f48b929",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby('neighborhood')['sale_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f12e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_model = SelectFromModel(lasso_best)\n",
    "feature_set_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80406670",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f527009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9c8311",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_set_model.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df465b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#refined model \n",
    "refined = X.columns[feature_set_model.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d904ef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_feat[refined]\n",
    "y = model_feat['sale_price']\n",
    "\n",
    "# Create train/test splits.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state = 123\n",
    ")\n",
    "\n",
    "# Scale our data.\n",
    "# Relabeling scaled data as \"Z\" is common.\n",
    "sc = StandardScaler()\n",
    "# Z_train = sc.fit_transform(X_train)\n",
    "sc.fit(X_train) # fit should only see train data, \n",
    "                #else if put in test, will have leak from the train data \n",
    "X_train = sc.transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13268b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit \n",
    "\n",
    "lasso.fit(X_train,y_train)\n",
    "\n",
    "lasso.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eced73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lasso best 2 \n",
    "\n",
    "lasso_best_2 = Lasso(alpha=lasso.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293e9c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_best_2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3280b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross val mse\n",
    "cross_score = - cross_val_score(\n",
    "    lasso_best_2,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv = 3,\n",
    "    scoring = 'neg_mean_squared_error'\n",
    ").mean()\n",
    "\n",
    "# test mse\n",
    "mse_test = mean_squared_error(\n",
    "    y_test,\n",
    "    lasso_best_2.predict(X_test)\n",
    ")\n",
    "# cross - test \n",
    "mse_train_minus_test = cross_score - mse_test\n",
    "\n",
    "if mse_train_minus_test > 0:\n",
    "    print(f'MSE for train: {cross_score}')\n",
    "    print(f'MSE for test: {mse_test}')\n",
    "    print(f'Underfited by: {mse_train_minus_test}')\n",
    "else:\n",
    "    print(f'MSE for train: {cross_score}')\n",
    "    print(f'MSE for test: {mse_test}')\n",
    "    print(f'Overfitted by: {mse_train_minus_test}')\n",
    "print(f'RMSE: {mse_test**0.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb74bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noticed at higher ends of the sale_price,\n",
    "# model is calculating below real sales_price\n",
    "\n",
    "ax2 = sns.jointplot(\n",
    "    x = lasso_best_2.predict(X_test),\n",
    "    y = y_test,\n",
    "    kind = 'reg'\n",
    ")\n",
    "ax2.ax_joint.set_xlabel('Predicted Sale Price - No log')\n",
    "ax2.ax_joint.set_ylabel('Actual Sale Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851be63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b35df42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noticed at higher ends of the sale_price,\n",
    "# model is calculating below real sales_price\n",
    "\n",
    "ax2 = sns.jointplot(\n",
    "    x = lasso_best_2.predict(X_test),\n",
    "    y = y_test,\n",
    "    kind = 'reg'\n",
    ")\n",
    "ax2.ax_joint.set_xlabel('Predicted Sale Price - No log')\n",
    "ax2.ax_joint.set_ylabel('Actual Sale Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97571c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add3cc58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50c1027",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
