{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# EDA Walkthrough\n",
    "\n",
    "_Authors: Kiefer Katovich (SF), David Yerrington (SF), Riley Dallas (AUS)_\n",
    "\n",
    "---\n",
    "\n",
    "The dataset for today's lesson (`Heart.csv`) comes from the book, [An Introduction to Statistical Learning (ISLR)](http://faculty.marshall.usc.edu/gareth-james/ISL/). It's comprised of diagnostic measurements for 303 patients to determine whether or not they have heart disease (the `AHD` column).\n",
    "\n",
    "Though in many if not most cases the EDA procedure will be considerably more involved, this should give you an idea of the basic workflow a data scientist would use when working with a new dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objectives\n",
    "\n",
    "- Quickly describe a dataset, including data types, missing values and basic descriptive statistics\n",
    "- Rename columns (series) in a DataFrame\n",
    "- Visualize data distributions with box plots\n",
    "- Calculate and visualize correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "---\n",
    "\n",
    "Import the CSV into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './datasets/Heart.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/Heart.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe the basic format of the data and the columns\n",
    "\n",
    "---\n",
    "\n",
    "Use the `.head()` method (and optionally pass in an integer for the number of rows you want to see) to get a glimpse of your dataset. This is a good initial step to get a feel for what is in the CSV and what problems may be present.\n",
    "\n",
    "The `.dtypes` attribute tells you the data type for each of your columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPain</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Fbs</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExAng</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Thal</th>\n",
       "      <th>AHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>typical</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>nontypical</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Age  Sex     ChestPain  RestBP  Chol  Fbs  RestECG  MaxHR  \\\n",
       "0           1  63    1       typical     145   233    1        2    150   \n",
       "1           2  67    1  asymptomatic     160   286    0        2    108   \n",
       "2           3  67    1  asymptomatic     120   229    0        2    129   \n",
       "3           4  37    1    nonanginal     130   250    0        0    187   \n",
       "4           5  41    0    nontypical     130   204    0        2    172   \n",
       "\n",
       "   ExAng  Oldpeak  Slope   Ca        Thal  AHD  \n",
       "0      0      2.3      3  0.0       fixed    0  \n",
       "1      1      1.5      2  3.0      normal    1  \n",
       "2      1      2.6      2  2.0  reversable    1  \n",
       "3      0      3.5      3  0.0      normal    0  \n",
       "4      0      1.4      1  0.0      normal    0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the first 8 rows:\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      int64\n",
       "Age            object\n",
       "Sex             int64\n",
       "ChestPain      object\n",
       "RestBP          int64\n",
       "Chol            int64\n",
       "Fbs             int64\n",
       "RestECG         int64\n",
       "MaxHR           int64\n",
       "ExAng           int64\n",
       "Oldpeak       float64\n",
       "Slope           int64\n",
       "Ca            float64\n",
       "Thal           object\n",
       "AHD             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the dtypes of the columns:\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop unwanted columns\n",
    "\n",
    "---\n",
    "\n",
    "It looks like `Unnamed: 0` is an index. This is redundant, since `pandas` automatically creates an index for us (the bold numbers to the left of the DataFrame).\n",
    "\n",
    "The `.drop()` method can be used to get rid of a column like so:\n",
    "\n",
    "```python\n",
    "df.drop(columns=['list', 'columns', 'to', 'drop'], inplace=True)\n",
    "```\n",
    "\n",
    "The `inplace=True` parameter makes our change permanent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Sex', 'ChestPain', 'RestBP', 'Chol', 'Fbs', 'RestECG', 'MaxHR',\n",
       "       'ExAng', 'Oldpeak', 'Slope', 'Ca', 'Thal', 'AHD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out the index object and the first 20 items in the DataFrame's index \n",
    "# to see that we have these row numbers already:\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the unneccesary column:\n",
    "df.drop(columns= 'Unnamed: 0', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age          0\n",
       "Sex          0\n",
       "ChestPain    0\n",
       "RestBP       0\n",
       "Chol         0\n",
       "Fbs          0\n",
       "RestECG      0\n",
       "MaxHR        0\n",
       "ExAng        0\n",
       "Oldpeak      0\n",
       "Slope        0\n",
       "Ca           4\n",
       "Thal         2\n",
       "AHD          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean corrupted column\n",
    "\n",
    "---\n",
    "\n",
    "From the previous step, we noticed the `Age` column was interpreted as a string, even though the values are integers.\n",
    "\n",
    "It is pretty common to have numeric columns represented as strings in your data if some of the observations are corrupted. It is important to always check the data types of your columns.\n",
    "\n",
    "**What is causing the `Age` column to be encoded as a string?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['63', '67', '67', '37', '41', '56', '62', '57', '63', '53', '57',\n",
       "       '56', '56', '44', '52', '57', '48', '54', '48', '49', '64', '58',\n",
       "       '58', '58', '60', '50', '?', '66', '43', '40', '69', '60', '64',\n",
       "       '59', '44', '42', '43', '57', '55', '61', '65', '40', '71', '59',\n",
       "       '61', '58', '51', '50', '65', '53', '41', '65', '44', '44', '60',\n",
       "       '54', '50', '41', '54', '51', '51', '46', '?', '54', '54', '60',\n",
       "       '60', '54', '59', '46', '65', '67', '62', '65', '44', '65', '60',\n",
       "       '51', '48', '58', '45', '53', '39', '68', '52', '44', '47', '53',\n",
       "       '53', '51', '66', '62', '?', '44', '63', '52', '59', '60', '52',\n",
       "       '48', '45', '34', '57', '71', '49', '54', '59', '57', '61', '39',\n",
       "       '61', '56', '52', '43', '62', '41', '58', '35', '63', '65', '48',\n",
       "       '?', '51', '55', '65', '45', '56', '54', '44', '62', '54', '51',\n",
       "       '29', '51', '43', '55', '70', '62', '35', '51', '59', '59', '52',\n",
       "       '64', '58', '47', '57', '41', '45', '60', '52', '42', '67', '55',\n",
       "       '64', '70', '51', '58', '60', '68', '46', '77', '54', '58', '48',\n",
       "       '57', '52', '54', '35', '45', '70', '53', '59', '62', '64', '57',\n",
       "       '52', '56', '43', '53', '48', '56', '42', '59', '60', '63', '42',\n",
       "       '66', '54', '69', '50', '51', '43', '62', '68', '67', '69', '45',\n",
       "       '?', '59', '50', '64', '57', '64', '43', '45', '58', '?', '55',\n",
       "       '62', '37', '38', '41', '66', '?', '56', '46', '46', '64', '59',\n",
       "       '41', '54', '39', '53', '63', '34', '47', '67', '54', '66', '52',\n",
       "       '55', '49', '74', '54', '54', '56', '46', '49', '42', '41', '41',\n",
       "       '49', '61', '60', '67', '58', '47', '52', '?', '57', '58', '64',\n",
       "       '51', '43', '42', '67', '76', '70', '57', '44', '58', '60', '44',\n",
       "       '61', '42', '52', '59', '40', '42', '61', '66', '46', '71', '?',\n",
       "       '64', '66', '39', '57', '58', '57', '47', '55', '35', '61', '58',\n",
       "       '58', '58', '56', '56', '67', '55', '44', '63', '63', '41', '59',\n",
       "       '57', '45', '68', '57', '57', '38'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Age contains question marks\n",
    "\n",
    "df['Age'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, replace all \"?\" cells with `np.nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = df['Age'].map(lambda x: np.nan if x == '?' else int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Age        294 non-null    float64\n",
      " 1   Sex        303 non-null    int64  \n",
      " 2   ChestPain  303 non-null    object \n",
      " 3   RestBP     303 non-null    int64  \n",
      " 4   Chol       303 non-null    int64  \n",
      " 5   Fbs        303 non-null    int64  \n",
      " 6   RestECG    303 non-null    int64  \n",
      " 7   MaxHR      303 non-null    int64  \n",
      " 8   ExAng      303 non-null    int64  \n",
      " 9   Oldpeak    303 non-null    float64\n",
      " 10  Slope      303 non-null    int64  \n",
      " 11  Ca         299 non-null    float64\n",
      " 12  Thal       301 non-null    object \n",
      " 13  AHD        303 non-null    int64  \n",
      "dtypes: float64(3), int64(9), object(2)\n",
      "memory usage: 33.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine how many observations are missing\n",
    "\n",
    "---\n",
    "\n",
    "Having replaced the question marks with `np.nan` values, we know that there are some missing observations for the `Age` column. \n",
    "\n",
    "When we start to build models with data, null values in observations are (almost) never allowed. It is important to always see how many observations are missing for each column.\n",
    "\n",
    "We can count the null values for each column like so:\n",
    "\n",
    "```python\n",
    "df.isnull().sum()\n",
    "```\n",
    "\n",
    "The `.isnull()` method will convert the columns to `True` and `False` values.\n",
    "\n",
    "The `.sum()` method will then sum these boolean columns, and the total number of null values per column will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age          9\n",
       "Sex          0\n",
       "ChestPain    0\n",
       "RestBP       0\n",
       "Chol         0\n",
       "Fbs          0\n",
       "RestECG      0\n",
       "MaxHR        0\n",
       "ExAng        0\n",
       "Oldpeak      0\n",
       "Slope        0\n",
       "Ca           4\n",
       "Thal         2\n",
       "AHD          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop the null values.** \n",
    "\n",
    "In this case, lets keep it simple and just drop the rows from the dataset that contain null values. If a column has a ton of null values it often makes more sense to drop the column entirely instead of the rows with null values.\n",
    "\n",
    "The `.dropna()` function will drop any rows that have _**ANY**_ null values for you.  Use this carefully as you could drop many more rows than expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age          0\n",
       "Sex          0\n",
       "ChestPain    0\n",
       "RestBP       0\n",
       "Chol         0\n",
       "Fbs          0\n",
       "RestECG      0\n",
       "MaxHR        0\n",
       "ExAng        0\n",
       "Oldpeak      0\n",
       "Slope        0\n",
       "Ca           0\n",
       "Thal         0\n",
       "AHD          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the column names more descriptive\n",
    "---\n",
    "\n",
    "One minor annoyance is that our column names are not at all intuitive. \n",
    "\n",
    "Let's rename them! \n",
    "\n",
    "To rename columns, use _dictionary substitution_ with `.rename()`. This is very useful if you only want to rename a few columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary Method\n",
    "new_columns_dict = {\n",
    "    'Age': 'age',\n",
    "    'Sex': 'sex_male',\n",
    "    'ChestPain': 'chest_pain',\n",
    "    'RestBP': 'resting_blood_pressure',\n",
    "    'Chol': 'cholesterol',\n",
    "    'Fbs': 'fasting_blood_sugar',\n",
    "    'RestECG': 'resting_ecg',\n",
    "    'MaxHR': 'max_heart_rate',\n",
    "    'ExAng': 'exercise_induced_angina',\n",
    "    'Oldpeak': 'old_peak',\n",
    "    'Slope': 'slope',\n",
    "    'Ca': 'ca',\n",
    "    'Thal': 'thallium_stress_test',\n",
    "    'AHD': 'has_heart_disease',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe the summary statistics for the columns\n",
    "---\n",
    "\n",
    "<img src=\"https://snag.gy/07JFa5.jpg\" width=\"350\">\n",
    "\n",
    "---\n",
    "\n",
    "The `.describe()` function gives summary statistics for each of your columns. What are some, if any, oddities you notice about the columns based on this output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use `.groupby()` + `.describe()` for cohort analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot variables with potential outliers using boxplots.\n",
    "\n",
    "---\n",
    "\n",
    "Here we will use the seaborn package to plot boxplots of the variables we have identified as potentially having outliers.\n",
    "\n",
    "Some notes on seaborn's boxplot keyword argument options:\n",
    "\n",
    "    orient: can be 'v' or 'h' for vertical and horizontal, respectively\n",
    "    fliersize: the size of the outlier points (pixels I think)\n",
    "    linewidth: the width of line outlining the boxplot\n",
    "    notch: show the confidence interval for the median (calculated by seaborn/plt.boxplot)\n",
    "    saturation: saturate the colors to an extent\n",
    "\n",
    "There are more keyword arguments available but those are most relevant for now.\n",
    "\n",
    "_If you want to check out more, place your cursor in the `boxplot` argument bracket and press `shift+tab` (Press four times repeatedly to bring up detailed documentation)._\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max heart rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation matrices\n",
    "\n",
    "---\n",
    "\n",
    "A great way to easily get a feel for linear relationships between your variables is with a correlation matrix.\n",
    "\n",
    "Below is the formula for the correlation between two variables $X$ and $Y$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation\n",
    "\n",
    "### $$ \\text{pearson correlation}\\;r = cor(X, Y) =\\frac{cov(X, Y)}{std(X)std(Y)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The correlation matrix\n",
    "\n",
    "We can see the correlation between all the numeric variables in our dataset by using the `.corr()` method.\n",
    "\n",
    "It's useful to get a feel for which columns are correlated. The `.corr() method` can help you decide what is worth investigating further (though with a lot of variables, the matrix can be a bit overwhelming...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be difficult to spot any outliers simply by staring at our correlation matrix. To help get around this issue, let's use Seaborn's `.heatmap()` to give our correlation matrix some color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
