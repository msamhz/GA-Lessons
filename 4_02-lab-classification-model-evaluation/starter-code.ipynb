{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 4, Lab 2: Predicting Chronic Kidney Disease in Patients\n",
    "> Author: Matt Brems\n",
    "\n",
    "We can sketch out the data science process as follows:\n",
    "1. Define the problem.\n",
    "2. Obtain the data.\n",
    "3. Explore the data.\n",
    "4. Model the data.\n",
    "5. Evaluate the model.\n",
    "6. Answer the problem.\n",
    "\n",
    "In this lab, we're going to focus on steps exploring data, building models and evaluating the models we build.\n",
    "\n",
    "There are three links you may find important:\n",
    "- [A set of chronic kidney disease (CKD) data and other biological factors](./chronic_kidney_disease_full.csv).\n",
    "- [The CKD data dictionary](./chronic_kidney_disease_header.txt).\n",
    "- [An article comparing the use of k-nearest neighbors and support vector machines on predicting CKD](./chronic_kidney_disease.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define the problem.\n",
    "\n",
    "Suppose you're working for Mayo Clinic, widely recognized to be the top hospital in the United States. In your work, you've overheard nurses and doctors discuss test results, then arrive at a conclusion as to whether or not someone has developed a particular disease or condition. For example, you might overhear something like:\n",
    "\n",
    "> **Nurse**: Male 57 year-old patient presents with severe chest pain. FDP _(short for fibrin degradation product)_ was elevated at 13. We did an echo _(echocardiogram)_ and it was inconclusive.\n",
    "\n",
    "> **Doctor**: What was his interarm BP? _(blood pressure)_\n",
    "\n",
    "> **Nurse**: Systolic was 140 on the right; 110 on the left.\n",
    "\n",
    "> **Doctor**: Dammit, it's an aortic dissection! Get to the OR _(operating room)_ now!\n",
    "\n",
    "> _(intense music playing)_\n",
    "\n",
    "In this fictitious but [Shonda Rhimes-esque](https://en.wikipedia.org/wiki/Shonda_Rhimes#Grey's_Anatomy,_Private_Practice,_Scandal_and_other_projects_with_ABC) scenario, you might imagine the doctor going through a series of steps like a [flowchart](https://en.wikipedia.org/wiki/Flowchart), or a series of if-this-then-that steps to diagnose a patient. The first steps made the doctor ask what the interarm blood pressure was. Because interarm blood pressure took on the values it took on, the doctor diagnosed the patient with an aortic dissection.\n",
    "\n",
    "Your goal, as a research biostatistical data scientist at the nation's top hospital, is to develop a medical test that can improve upon our current diagnosis system for [chronic kidney disease (CKD)](https://www.mayoclinic.org/diseases-conditions/chronic-kidney-disease/symptoms-causes/syc-20354521).\n",
    "\n",
    "**Real-world problem**: Develop a medical diagnosis test that is better than our current diagnosis system for CKD.\n",
    "\n",
    "**Data science problem**: Develop a medical diagnosis test that reduces both the number of false positives and the number of false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is important --> interarm blood\n",
    "\n",
    "**Data science problem**: Develop a medical diagnosis test that reduces both the number of false positives and the number of false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import train_test_split.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import Logistic Regression model.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Import metrics.\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score, plot_roc_curve, roc_auc_score, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Obtain the data.\n",
    "\n",
    "### 1. Read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('chronic_kidney_disease_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Check out the data dictionary. What are a few features or relationships you might be interested in checking out?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "1) BP\n",
    "2) Age\n",
    "3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'bp', 'sg', 'al', 'su', 'rbc', 'pc', 'pcc', 'ba', 'bgr', 'bu',\n",
       "       'sc', 'sod', 'pot', 'hemo', 'pcv', 'wbcc', 'rbcc', 'htn', 'dm', 'cad',\n",
       "       'appet', 'pe', 'ane', 'class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Explore the data.\n",
    "\n",
    "### 3. How much of the data is missing from each column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age        9\n",
       "bp        12\n",
       "sg        47\n",
       "al        46\n",
       "su        49\n",
       "rbc      152\n",
       "pc        65\n",
       "pcc        4\n",
       "ba         4\n",
       "bgr       44\n",
       "bu        19\n",
       "sc        17\n",
       "sod       87\n",
       "pot       88\n",
       "hemo      52\n",
       "pcv       71\n",
       "wbcc     106\n",
       "rbcc     131\n",
       "htn        2\n",
       "dm         2\n",
       "cad        2\n",
       "appet      1\n",
       "pe         1\n",
       "ane        1\n",
       "class      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Suppose that I dropped every row that contained at least one missing value. (In the context of analysis with missing data, we call this a \"complete case analysis,\" because we keep only the complete cases!) How many rows would remain in our dataframe? What are at least two downsides to doing this?\n",
    "\n",
    "> There's a good visual on slide 15 of [this deck](https://liberalarts.utexas.edu/prc/_files/cs/Missing-Data.pdf) that shows what a complete case analysis looks like if you're interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 25)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ckd       0.625\n",
       "notckd    0.375\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "    test = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'bp', 'sg', 'al', 'su', 'rbc', 'pc', 'pcc', 'ba', 'bgr', 'bu',\n",
       "       'sc', 'sod', 'pot', 'hemo', 'pcv', 'wbcc', 'rbcc', 'htn', 'dm', 'cad',\n",
       "       'appet', 'pe', 'ane', 'class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "notckd    0.727848\n",
       "ckd       0.272152\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['class'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "1) Rows are left with 158 from 400 -->> there is a huge reduction, and we might not get good data of either results \n",
    "- df has good percentage of 60 over 30% while test has only 72 against 27%. Abit skewed but we can tank\n",
    "\n",
    "\n",
    "2) Not best quality "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Thinking critically about how our data were gathered, it's likely that these records were gathered by doctors and nurses. Brainstorm three potential areas (in addition to the missing data we've already discussed) where this data might be inaccurate or imprecise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "1) Different doctors and nurses might have different practise in the way they want to collect the results thus, might have some bias in terms of taking down notes. \n",
    "\n",
    "2) Patients might not want to disclose some of their information as they might be worried. \n",
    "\n",
    "3) They might not be trained, hence having inaccurate data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4: Model the data.\n",
    "\n",
    "### 6. Suppose that I want to construct a model where no person who has CKD will ever be told that they do not have CKD. What (very simple, no machine learning needed) model can I create that will never tell a person with CKD that they do not have CKD?\n",
    "\n",
    "> Hint: Don't think about `statsmodels` or `scikit-learn` here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Stratified sampling \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. In problem 6, what common classification metric did we optimize for? Did we minimize false positives or negatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Accuracy \n",
    "\n",
    "\n",
    "we did not minimize false positives and negatives "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Thinking ethically, what is at least one disadvantage to the model you described in problem 6?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "People who wont know will not like it when doctors dont tell them. It will make them all feel as if they have something wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Suppose that I want to construct a model where a person who does not have CKD will ever be told that they do have CKD. What (very simple, no machine learning needed) model can I create that will accomplish this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Random sampling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. In problem 9, what common classification metric did we optimize for? Did we minimize false positives or negatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Thinking ethically, what is at least one disadvantage to the model you described in problem 9?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Construct a logistic regression model in `sklearn` predicting class from the other variables. You may scale, select/drop, and engineer features as you wish - build a good model! Make sure, however, that you include at least one categorical/dummy feature and at least one quantitative feature.\n",
    "\n",
    "> Hint: Remember to do a train/test split!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop off all NA\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rbc', 'pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declare columns to get_dummies \n",
    "dummy_columns = [col for col in df.columns if (df[col].dtypes == 'O') & (col != 'class')]\n",
    "dummy_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cat for dummies only \n",
    "\n",
    "df_cat = df[dummy_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df drop all objects \n",
    "\n",
    "df.drop(columns = dummy_columns, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df cat convert to get_dummies \n",
    "\n",
    "df_cat = pd.get_dummies(df_cat, drop_first= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat both\n",
    "\n",
    "df= pd.concat([df,df_cat], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 158 entries, 3 to 399\n",
      "Data columns (total 25 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          158 non-null    float64\n",
      " 1   bp           158 non-null    float64\n",
      " 2   sg           158 non-null    float64\n",
      " 3   al           158 non-null    float64\n",
      " 4   su           158 non-null    float64\n",
      " 5   bgr          158 non-null    float64\n",
      " 6   bu           158 non-null    float64\n",
      " 7   sc           158 non-null    float64\n",
      " 8   sod          158 non-null    float64\n",
      " 9   pot          158 non-null    float64\n",
      " 10  hemo         158 non-null    float64\n",
      " 11  pcv          158 non-null    float64\n",
      " 12  wbcc         158 non-null    float64\n",
      " 13  rbcc         158 non-null    float64\n",
      " 14  class        158 non-null    object \n",
      " 15  rbc_normal   158 non-null    uint8  \n",
      " 16  pc_normal    158 non-null    uint8  \n",
      " 17  pcc_present  158 non-null    uint8  \n",
      " 18  ba_present   158 non-null    uint8  \n",
      " 19  htn_yes      158 non-null    uint8  \n",
      " 20  dm_yes       158 non-null    uint8  \n",
      " 21  cad_yes      158 non-null    uint8  \n",
      " 22  appet_poor   158 non-null    uint8  \n",
      " 23  pe_yes       158 non-null    uint8  \n",
      " 24  ane_yes      158 non-null    uint8  \n",
      "dtypes: float64(14), object(1), uint8(10)\n",
      "memory usage: 21.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# checked all ok \n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'bp', 'sg', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo',\n",
       "       'pcv', 'wbcc', 'rbcc', 'class', 'rbc_normal', 'pc_normal',\n",
       "       'pcc_present', 'ba_present', 'htn_yes', 'dm_yes', 'cad_yes',\n",
       "       'appet_poor', 'pe_yes', 'ane_yes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ckd', 'notckd'], dtype=object)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'] = df['class'].apply(lambda x:  1 if x == 'ckd' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop(columns = 'class')\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 158 entries, 3 to 399\n",
      "Data columns (total 25 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          158 non-null    float64\n",
      " 1   bp           158 non-null    float64\n",
      " 2   sg           158 non-null    float64\n",
      " 3   al           158 non-null    float64\n",
      " 4   su           158 non-null    float64\n",
      " 5   bgr          158 non-null    float64\n",
      " 6   bu           158 non-null    float64\n",
      " 7   sc           158 non-null    float64\n",
      " 8   sod          158 non-null    float64\n",
      " 9   pot          158 non-null    float64\n",
      " 10  hemo         158 non-null    float64\n",
      " 11  pcv          158 non-null    float64\n",
      " 12  wbcc         158 non-null    float64\n",
      " 13  rbcc         158 non-null    float64\n",
      " 14  class        158 non-null    int64  \n",
      " 15  rbc_normal   158 non-null    uint8  \n",
      " 16  pc_normal    158 non-null    uint8  \n",
      " 17  pcc_present  158 non-null    uint8  \n",
      " 18  ba_present   158 non-null    uint8  \n",
      " 19  htn_yes      158 non-null    uint8  \n",
      " 20  dm_yes       158 non-null    uint8  \n",
      " 21  cad_yes      158 non-null    uint8  \n",
      " 22  appet_poor   158 non-null    uint8  \n",
      " 23  pe_yes       158 non-null    uint8  \n",
      " 24  ane_yes      158 non-null    uint8  \n",
      "dtypes: float64(14), int64(1), uint8(10)\n",
      "memory usage: 21.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify= y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 5: Evaluate the model.\n",
    "\n",
    "### 13. Based on your logistic regression model constructed in problem 12, interpret the coefficient of one of your quantitative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "logreg.fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Intercept: [0.02472258]\n",
      "Logistic Regression Coefficient: [[1.20196938 0.94587887 1.01188072 1.77359403 1.00098619 1.17593273\n",
      "  1.1835543  1.16619202 0.89416574 1.12145289 0.68370252 0.58320018\n",
      "  1.00080039 0.79266409 0.98483712 0.84849477 1.00067202 1.01050786\n",
      "  1.18018454 1.1794909  1.00009559 1.01106726 1.00065341 1.00064357]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Logistic Regression Intercept: {logreg.intercept_}')\n",
    "print(f'Logistic Regression Coefficient: {np.exp(logreg.coef_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age            1.201969\n",
       "bp             0.945879\n",
       "sg             1.011881\n",
       "al             1.773594\n",
       "su             1.000986\n",
       "bgr            1.175933\n",
       "bu             1.183554\n",
       "sc             1.166192\n",
       "sod            0.894166\n",
       "pot            1.121453\n",
       "hemo           0.683703\n",
       "pcv            0.583200\n",
       "wbcc           1.000800\n",
       "rbcc           0.792664\n",
       "rbc_normal     0.984837\n",
       "pc_normal      0.848495\n",
       "pcc_present    1.000672\n",
       "ba_present     1.010508\n",
       "htn_yes        1.180185\n",
       "dm_yes         1.179491\n",
       "cad_yes        1.000096\n",
       "appet_poor     1.011067\n",
       "pe_yes         1.000653\n",
       "ane_yes        1.000644\n",
       "dtype: float64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(np.exp(logreg.coef_[0]), index = X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: They represent the change in log-odds caused by the input variables.\n",
    "\n",
    "\n",
    "For the Age: For 1 unit of age increase, suggests that it is 1.2 times as likely to get CKD, holding all else constant\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Based on your logistic regression model constructed in problem 12, interpret the coefficient of one of your categorical/dummy features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The goal of logistic regression is to find the best-fitting model to describe the relationship between a binary outcome and a set of independent variables.\n",
    "\n",
    "Logistic regression generates the coefficientsÂ of a formula to predict a logit transformation of the probability that the characteristic of interest is present.\n",
    "\n",
    "The log of the odds make things symmetrical easier to interpret \n",
    "- as previously odds of not getting CKD is 0 - 1 while getting CKD can be 1 to infinity. \n",
    "\n",
    "dm - diabetes mellitus \n",
    "--> seems to have for every person who has diabetes, he has 1.17 likely to to get CKD, holding all else constant. \n",
    "\n",
    "Hypertension as well \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Despite being a relatively simple model, logistic regression is very widely used in the real world. Why do you think that's the case? Name at least two advantages to using logistic regression as a modeling technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "The coefficients can be ranked and be interpreted very easily by putting whatever X variable we want. \n",
    "\n",
    "Regression model can cater for any X variable due to its logit function that can help convert any value and predict probability of zero to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Does it make sense to generate a confusion matrix on our training data or our test data? Why? Generate it on the proper data.\n",
    "\n",
    "> Hint: Once you've generated your predicted $y$ values and you have your observed $y$ values, then it will be easy to [generate a confusion matrix using sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp\n",
    "\n",
    "# to check if CKD is 14 or 39 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([num for num in logreg.predict(X_test) if num != 1])\n",
    "\n",
    "# can do this too if need to check which label  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39,  0],\n",
       "       [ 0, 14]], dtype=int64)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(logreg, X_test, y_test, cmap='Blues', \n",
    "                      values_format='d', display_labels=['NO CKD', 'CKD']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. In this hospital case, we want to predict CKD. Do we want to optimize for sensitivity, specificity, or something else? Why? (If you don't think there's one clear answer, that's okay! There rarely is. Be sure to defend your conclusion!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "We will want to minimise our type 2 errors, hence improve on specifity. because will not want people to be diagnosed to not have CKD when they actually have,which may lead to many issues . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18 (BONUS). Write a function that will create an ROC curve for you, then plot the ROC curve.\n",
    "\n",
    "Here's a strategy you might consider:\n",
    "1. In order to even begin, you'll need some fit model. Use your logistic regression model from problem 12.\n",
    "2. We want to look at all values of your \"threshold\" - that is, anything where .predict() gives you above your threshold falls in the \"positive class,\" and anything that is below your threshold falls in the \"negative class.\" Start the threshold at 0.\n",
    "3. At this value of your threshold, calculate the sensitivity and specificity. Store these values.\n",
    "4. Increment your threshold by some \"step.\" Maybe set your step to be 0.01, or even smaller.\n",
    "5. At this value of your threshold, calculate the sensitivity and specificity. Store these values.\n",
    "6. Repeat steps 3 and 4 until you get to the threshold of 1.\n",
    "7. Plot the values of sensitivity and 1 - specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(logreg, X_test, y_test)\n",
    "plt.plot([0, 1], [0, 1],\n",
    "         label='baseline', linestyle='--')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, logreg.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Suppose you're speaking with the biostatistics lead at Mayo Clinic, who asks you \"Why are unbalanced classes generally a problem? Are they a problem in this particular CKD analysis?\" How would you respond?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "yes because if we do not have balanced class, what might potentially be a true CKD patient might end up being classified as not having CKD if we have a unbalanced class of having majority NONE CKD patients. \n",
    "\n",
    "hence we need to have sample of actual CKD patients to give this kind of assessment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. Suppose you're speaking with a doctor at Mayo Clinic who, despite being very smart, doesn't know much about data science or statistics. How would you explain why unbalanced classes are generally a problem to this doctor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "We do not want to  classify wrongly of patients having CKD, hence we need more accurate data especially for those with CKD or potential CKD. \n",
    "\n",
    "\n",
    "with more samples of patients with CKD, we will have much more accuracy and can predict better in order to help you to step in and decide what courses of action to do next for potential CKD patients "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. Let's create very unbalanced classes just for the sake of this example! Generate very unbalanced classes by [bootstrapping](http://stattrek.com/statistics/dictionary.aspx?definition=sampling_with_replacement) (a.k.a. random sampling with replacement) the majority class.\n",
    "\n",
    "1. The majority class are those individuals with CKD.\n",
    "2. Generate a random sample of size 200,000 of individuals who have CKD **with replacement**. (Consider setting a random seed for this part!)\n",
    "3. Create a new dataframe with the original data plus this random sample of data.\n",
    "4. Now we should have a dataset with around 200,000 observations, of which only about 0.00075% are non-CKD individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "np.random.seed(123)\n",
    "unb_ckd = np.random.randint(2,size =200000, dtype = int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unb_ckd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    115\n",
       "1     43\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_samples = []\n",
    "for _ in range(5000):\n",
    "    x = np.random.choice(2, size=10, replace=True)\n",
    "    my_samples.append(x.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150.0"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "200000*0.00075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5,\n",
       " 0.6,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.2,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.8,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.7,\n",
       " 0.7,\n",
       " 0.4,\n",
       " 0.2,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.8,\n",
       " 0.8,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.8,\n",
       " 0.6,\n",
       " 0.2,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.8,\n",
       " 0.2,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.8,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.7,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.3,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.8,\n",
       " 0.7,\n",
       " 0.7,\n",
       " 0.6,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.2,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.2,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.2,\n",
       " 0.6,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.6,\n",
       " 0.9,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.7,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.4,\n",
       " 0.2,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.8,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.9,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.8,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.9,\n",
       " 0.7,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.8,\n",
       " 0.3,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.7,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.2,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.1,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.2,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.8,\n",
       " 0.9,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.7,\n",
       " 0.7,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.7,\n",
       " 0.7,\n",
       " 0.2,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.2,\n",
       " 0.6,\n",
       " 0.8,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.7,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.8,\n",
       " 0.8,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.2,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.2,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.3,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.3,\n",
       " 0.6,\n",
       " 0.3,\n",
       " 0.1,\n",
       " 0.7,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.2,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.2,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.8,\n",
       " 0.8,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.6,\n",
       " 0.3,\n",
       " 0.2,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.8,\n",
       " 0.2,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.2,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.7,\n",
       " 0.4,\n",
       " 0.7,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.3,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.2,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.1,\n",
       " 0.8,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.2,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.2,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.8,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.2,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.4,\n",
       " 0.7,\n",
       " 0.8,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 1.0,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.2,\n",
       " 0.5,\n",
       " 0.8,\n",
       " 0.4,\n",
       " 0.7,\n",
       " 0.8,\n",
       " 0.8,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.9,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.8,\n",
       " 0.7,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.3,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.4,\n",
       " 0.2,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.1,\n",
       " 0.6,\n",
       " 0.9,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.2,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.7,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.6,\n",
       " 0.3,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.7,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.2,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.7,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.3,\n",
       " 0.7,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.2,\n",
       " 0.8,\n",
       " 0.3,\n",
       " 0.7,\n",
       " 0.6,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.7,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.7,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.9,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.3,\n",
       " 0.2,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.8,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.7,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.2,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.3,\n",
       " 0.7,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.9,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.8,\n",
       " 0.6,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.2,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.3,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.7,\n",
       " 0.6,\n",
       " 0.3,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 0.8,\n",
       " 0.9,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.9,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.3,\n",
       " 0.7,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.7,\n",
       " 0.3,\n",
       " 0.6,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.7,\n",
       " 0.3,\n",
       " 0.6,\n",
       " 0.3,\n",
       " 0.6,\n",
       " 0.3,\n",
       " 0.7,\n",
       " 0.2,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.9,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.6,\n",
       " 0.7,\n",
       " 0.2,\n",
       " 0.4,\n",
       " 0.7,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.2,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.2,\n",
       " 0.4,\n",
       " 0.7,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.2,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.2,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.2,\n",
       " 0.2,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.2,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.1,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.2,\n",
       " 0.8,\n",
       " 0.3,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.6,\n",
       " 0.8,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.6,\n",
       " 0.4,\n",
       " 0.8,\n",
       " 0.8,\n",
       " 0.7,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.3,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.3,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.4,\n",
       " 0.7,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.6,\n",
       " 0.5,\n",
       " 0.4,\n",
       " ...]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. Build a logistic regression model on the unbalanced class data and evaluate its performance using whatever method(s) you see fit. How would you describe the impact of unbalanced classes on logistic regression as a classifier?\n",
    "> Be sure to look at how well it performs on non-CKD data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: Answer the problem.\n",
    "\n",
    "At this step, you would generally answer the problem! In this situation, you would likely present your model to doctors or administrators at the hospital and show how your model results in reduced false positives/false negatives. Next steps would be to find a way to roll this model and its conclusions out across the hospital so that the outcomes of patients with CKD (and without CKD!) can be improved!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
