{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 1: Standardized Test Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# Part 1\n",
    "\n",
    "Part 1 requires knowledge of basic Python.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This project seeks to identify relationship between GPA and SATs and seek to support colleges move towards test-optional policy temporarily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents:\n",
    "- [Background](#Background)\n",
    "- [Data Import & Cleaning](#Data-Import-and-Cleaning)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [Data Visualization](#Visualize-the-Data)\n",
    "- [Conclusions and Recommendations](#Conclusions-and-Recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background: \n",
    "\n",
    "The SAT and ACT are standardized tests that may serve as entry examinations into many universities in the United States. These test requirement may vary across different states in US, and they are used along with other materials such as grade point average (GPA) and essay responses to determine whether or not a potential student will be accepted to the university.\n",
    "\n",
    "Due to the Covid impact, many students could not take the test due mass cancellations and postponement. On March 16, College board announced the cancellation for the SAT amid COVID. ([*source*]( https://edition.cnn.com/2020/03/16/us/sat-exam-coronavirus-trnd/index.html)). This has caused many unsettling concerns which may affect students further education. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [`SATOptOut`](data\\SATOptOut.csv) : Colleges in California Opt out from SAT test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [`satgpa`](\\data\\satgpa.csv) : SAT and GPA results, sampled 1000 students from unamed colleges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [`SAT_Scores_Ca_2021`](../Data/SAT_Scores_Ca_2021.csv): 2021 SAT mean scores for Math and ERW, and number of test takers for California"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [`SAT_Scores_Ca_2020`](../Data/SAT_Scores_Ca_2020.csv): 2021 SAT mean scores for Math and ERW, and number of test takers for California"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [`SAT_Scores_Ca_2019`](../Data/SAT_Scores_Ca_2019.csv): 2021 SAT mean scores for Math and ERW, and number of test takers for California"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [`Income_CA`](../Data/income_ca_sats.csv): 2021 SAT mean scores for Math and ERW, and number of test takers for California"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outside Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your problem statement and your chosen datasets, spend some time doing outside research on state policies or additional information that might be relevant. Summarize your findings below. If you bring in any outside tables or charts, make sure you are explicit about having borrowed them. If you quote any text, make sure that it renders as being quoted. **Make sure that you cite your sources.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the day, the College Board is a business, and businesses need to generate profit. Recently, the College Board has been generating significantly less revenue given that fewer students are taking the SAT compared to years past because of the shift to test-optional college admissions. \n",
    "\n",
    "https://www.forbes.com/sites/kristenmoon/2022/01/28/three-reasons-why-you-should-pay-attention-to-the-sat-redesign/?sh=2c9a28e67971"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wealthy kids might do sat more than the lower income kids \n",
    "\n",
    "participation rates might decrease \n",
    "\n",
    "https://www.bloomberg.com/news/articles/2022-01-24/wealthy-teens-tout-test-results-colleges-no-longer-require"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Participation rate, defined as the percentage of a state's high school seniors taking the SAT represented by the z-score mean of a truncated normal distribution, was the most important single predictor of state mean SAT score, accounting for 77% of the total variance in mean scores.\n",
    "\n",
    "The inclusion of significant educational and demographic variables raised the proportion of variance explained to 94%. The fallacy of comparing the mean standardized test scores of different locations or time periods without taking participation rate into account is discussed.\n",
    "\n",
    "\n",
    "Howard Wainer, Samuel Palmer, Eric T. Bradlow. (1998) A Selection of Selection Anomalies. CHANCE 11:2, pages 3-7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Participation Rates Skew State Averages on SAT & ACT\n",
    "\n",
    "https://medium.com/@james.dargan/participation-skews-state-averages-f68969371a01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://yhpf.medium.com/participation-rate-act-and-sat-short-version-4c09f4e20bdd\n",
    "\n",
    "showing negative correlation with results vs participation rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.benjamindornel.com/sat-act.html\n",
    "    \n",
    "    \n",
    "which state should the College Board target to further raise SAT participation rates? \n",
    "also has function to change column \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://shorelight.com/student-stories/the-us-higher-education-system-explained/\n",
    "    \n",
    "standard education system in US"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.openintro.org/data/index.php?data=satgpa\n",
    "    \n",
    "    \n",
    "Data on sat vs gpa\n",
    "Format\n",
    "A data frame with 1000 observations on the following 6 variables.\n",
    "\n",
    "sex\n",
    "Gender of the student.\n",
    "\n",
    "sat_v\n",
    "Verbal SAT percentile.\n",
    "\n",
    "sat_m\n",
    "Math SAT percentile.\n",
    "\n",
    "sat_sum\n",
    "Total of verbal and math SAT percentiles.\n",
    "\n",
    "hs_gpa\n",
    "High school grade point average.\n",
    "\n",
    "fy_gpa\n",
    "First year (college) grade point average.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://reports.collegeboard.org/sat-suite-program-results\n",
    "    \n",
    "SAT SCores for California "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://magoosh.com/hs/sat/states-that-require-the-act-or-sat/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the larger picture, academicians and sociologists have argued for years that the tests themselves are both culturally biased and form a barrier to entry for many students, particularly low-income and first-generation students who can’t afford the test-prep courses that have come to form a lucrative subindustry within the college admissions game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### College and Career Readiness Benchmarks\n",
    "\n",
    "\n",
    "· The SAT Math benchmark is the section score associated\n",
    "with a 75% chance of earning at least a C in first-semester,\n",
    "credit-bearing, college-level courses in algebra, statistics,\n",
    "precalculus, or calculus.\n",
    "\n",
    "· The SAT Evidence-Based Reading and Writing (ERW)\n",
    "benchmark is associated with a 75% chance of earning at\n",
    "least a C in first-semester, credit-bearing, college-level\n",
    "courses in history, literature, social science, or writing.\n",
    "\n",
    "While SAT benchmarks\n",
    "indicate likelihood of success in college, grade-level\n",
    "benchmarks indicate whether a student is on track for college\n",
    "and career readiness for their grade. The benchmarks are set\n",
    "to reflect typical annual growth from year to year from 8th\n",
    "through 12th grades.\n",
    "\n",
    "\n",
    "Met Benchmark - metric benchmark\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.prepscholar.com/test-optional-colleges-list\n",
    "    \n",
    "##### test optional definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding Challenges\n",
    "\n",
    "1. Manually calculate mean:\n",
    "\n",
    "    Write a function that takes in values and returns the mean of the values. Create a list of numbers that you test on your function to check to make sure your function works!\n",
    "    \n",
    "    *Note*: Do not use any mean methods built-in to any Python libraries to do this! This should be done without importing any additional libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating list \n",
    "\n",
    "sample = [_ for _ in range(5)]\n",
    "print(sample)  \n",
    "\n",
    "# definining mean function \n",
    "\n",
    "def getmean(sample):\n",
    "    number = 0 \n",
    "    for num in sample:\n",
    "        number = num + number\n",
    "        \n",
    "    return int(number/len(sample))\n",
    "\n",
    "getmean(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Manually calculate standard deviation:\n",
    "\n",
    "    The formula for standard deviation is below:\n",
    "\n",
    "    $$\\sigma = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu)^2}$$\n",
    "\n",
    "    Where $x_i$ represents each value in the dataset, $\\mu$ represents the mean of all values in the dataset and $n$ represents the number of values in the dataset.\n",
    "\n",
    "    Write a function that takes in values and returns the standard deviation of the values using the formula above. Hint: use the function you wrote above to calculate the mean! Use the list of numbers you created above to test on your function.\n",
    "    \n",
    "    *Note*: Do not use any standard deviation methods built-in to any Python libraries to do this! This should be done without importing any additional libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.414"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# definining stdev function \n",
    "\n",
    "def getstdev(sample):\n",
    "    number = 0\n",
    "    for num in sample:\n",
    "        number = number + ((num-getmean(sample))**2)\n",
    "    return ((number)/len(sample))**0.5\n",
    "\n",
    "\n",
    "round(getstdev(sample),3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Data cleaning function:\n",
    "    \n",
    "    Write a function that takes in a string that is a number and a percent symbol (ex. '50%', '30.5%', etc.) and converts this to a float that is the decimal approximation of the percent. For example, inputting '50%' in your function should return 0.5, '30.5%' should return 0.305, etc. Make sure to test your function to make sure it works!\n",
    "\n",
    "You will use these functions later on in the project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_percent(string):\n",
    "    return float(string.replace('%',''))/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def convert_percent_commas(df):\n",
    "    for col in df.columns:\n",
    "        if '% of score senders' in col.lower():\n",
    "            df[col] = df[col].replace('%','', regex=True).astype('float')\n",
    "        elif 'number of students' in col.lower():\n",
    "            df[col] = df[col].replace(',','', regex=True).astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "participation - how many of the state do the SAT during high school "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# Part 2\n",
    "\n",
    "Part 2 requires knowledge of Pandas, EDA, data cleaning, and data visualization.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*All libraries used should be added here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import & Cleaning\n",
    "\n",
    "Import the datasets that you selected for this project and go through the following steps at a minimum. You are welcome to do further cleaning as you feel necessary:\n",
    "1. Display the data: print the first 5 rows of each dataframe to your Jupyter notebook.\n",
    "2. Check for missing values.\n",
    "3. Check for any obvious issues with the observations (keep in mind the minimum & maximum possible values for each test/subtest).\n",
    "4. Fix any errors you identified in steps 2-3.\n",
    "5. Display the data types of each feature.\n",
    "6. Fix any incorrect data types found in step 5.\n",
    "    - Fix any individual values preventing other columns from being the appropriate type.\n",
    "    - If your dataset has a column of percents (ex. '50%', '30.5%', etc.), use the function you wrote in Part 1 (coding challenges, number 3) to convert this to floats! *Hint*: use `.map()` or `.apply()`.\n",
    "7. Rename Columns.\n",
    "    - Column names should be all lowercase.\n",
    "    - Column names should not contain spaces (underscores will suffice--this allows for using the `df.column_name` method to access columns in addition to `df['column_name']`).\n",
    "    - Column names should be unique and informative.\n",
    "8. Drop unnecessary rows (if needed).\n",
    "9. Merge dataframes that can be merged.\n",
    "10. Perform any additional cleaning that you feel is necessary.\n",
    "11. Save your cleaned and merged dataframes as csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2017/18/19/20/21 SATS Data import and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data importing \n",
    "act_2017 = pd.read_csv('Data/act_2017.csv')\n",
    "act_2018 = pd.read_csv('Data/act_2018.csv')\n",
    "sat_2017 = pd.read_csv('Data/sat_2017.csv')\n",
    "sat_2018 = pd.read_csv('Data/sat_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act_2017\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52 entries, 0 to 51\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   State          52 non-null     object \n",
      " 1   Participation  52 non-null     object \n",
      " 2   English        52 non-null     float64\n",
      " 3   Math           52 non-null     float64\n",
      " 4   Reading        52 non-null     float64\n",
      " 5   Science        52 non-null     float64\n",
      " 6   Composite      52 non-null     object \n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 3.0+ KB\n",
      "\n",
      "\n",
      "act_2018\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52 entries, 0 to 51\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   State          52 non-null     object \n",
      " 1   Participation  52 non-null     object \n",
      " 2   Composite      52 non-null     float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 1.3+ KB\n",
      "\n",
      "\n",
      "sat_2017\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51 entries, 0 to 50\n",
      "Data columns (total 5 columns):\n",
      " #   Column                              Non-Null Count  Dtype \n",
      "---  ------                              --------------  ----- \n",
      " 0   State                               51 non-null     object\n",
      " 1   Participation                       51 non-null     object\n",
      " 2   Evidence-Based Reading and Writing  51 non-null     int64 \n",
      " 3   Math                                51 non-null     int64 \n",
      " 4   Total                               51 non-null     int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 2.1+ KB\n",
      "\n",
      "\n",
      "sat_2018\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51 entries, 0 to 50\n",
      "Data columns (total 5 columns):\n",
      " #   Column                              Non-Null Count  Dtype \n",
      "---  ------                              --------------  ----- \n",
      " 0   State                               51 non-null     object\n",
      " 1   Participation                       51 non-null     object\n",
      " 2   Evidence-Based Reading and Writing  51 non-null     int64 \n",
      " 3   Math                                51 non-null     int64 \n",
      " 4   Total                               51 non-null     int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 2.1+ KB\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking Sat_Opt_Out\n",
    "print('act_2017')\n",
    "act_2017.info()\n",
    "print('\\n')\n",
    "\n",
    "print('act_2018')\n",
    "act_2018.info()\n",
    "print('\\n')\n",
    "\n",
    "print('sat_2017')\n",
    "sat_2017.info()\n",
    "print('\\n')\n",
    "\n",
    "print('sat_2018')\n",
    "sat_2018.info()\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# convert percentage to float\n",
    "filelist = [sat_2018,act_2018,sat_2017,act_2017]\n",
    "\n",
    "for file in filelist:\n",
    "    file['Participation'] = file['Participation'].apply(lambda x: remove_percent(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>0.06</td>\n",
       "      <td>595</td>\n",
       "      <td>571</td>\n",
       "      <td>1166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.43</td>\n",
       "      <td>562</td>\n",
       "      <td>544</td>\n",
       "      <td>1106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.29</td>\n",
       "      <td>577</td>\n",
       "      <td>572</td>\n",
       "      <td>1149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>0.05</td>\n",
       "      <td>592</td>\n",
       "      <td>576</td>\n",
       "      <td>1169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>0.60</td>\n",
       "      <td>540</td>\n",
       "      <td>536</td>\n",
       "      <td>1076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State  Participation  Evidence-Based Reading and Writing  Math  Total\n",
       "0     Alabama           0.06                                 595   571   1166\n",
       "1      Alaska           0.43                                 562   544   1106\n",
       "2     Arizona           0.29                                 577   572   1149\n",
       "3    Arkansas           0.05                                 592   576   1169\n",
       "4  California           0.60                                 540   536   1076"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2018.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>0.05</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.38</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.30</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>0.03</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>0.53</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        State  Participation  Evidence-Based Reading and Writing  Math  Total\n",
       "0     Alabama           0.05                                 593   572   1165\n",
       "1      Alaska           0.38                                 547   533   1080\n",
       "2     Arizona           0.30                                 563   553   1116\n",
       "3    Arkansas           0.03                                 614   594   1208\n",
       "4  California           0.53                                 531   524   1055"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation_x</th>\n",
       "      <th>Evidence-Based Reading and Writing_x</th>\n",
       "      <th>Math_x</th>\n",
       "      <th>Total_x</th>\n",
       "      <th>Participation_y</th>\n",
       "      <th>Evidence-Based Reading and Writing_y</th>\n",
       "      <th>Math_y</th>\n",
       "      <th>Total_y</th>\n",
       "      <th>Exist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [State, Participation_x, Evidence-Based Reading and Writing_x, Math_x, Total_x, Participation_y, Evidence-Based Reading and Writing_y, Math_y, Total_y, Exist]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to identify different column names based on 'college'\n",
    "\n",
    "diff_df = pd.merge(sat_2018, sat_2017, how='outer', indicator='Exist', on = 'State')\n",
    "\n",
    "diff_df = diff_df.loc[diff_df['Exist'] != 'both']\n",
    "\n",
    "diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace top columns and sync all \n",
    "set_column = ['state','participation','erwb','math','total']\n",
    "filelist = [sat_2018,sat_2017]\n",
    "\n",
    "for file in filelist:\n",
    "    file.columns = set_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>participation</th>\n",
       "      <th>erwb</th>\n",
       "      <th>math</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>0.05</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.38</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.30</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>0.03</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>0.53</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state  participation  erwb  math  total\n",
       "0     Alabama           0.05   593   572   1165\n",
       "1      Alaska           0.38   547   533   1080\n",
       "2     Arizona           0.30   563   553   1116\n",
       "3    Arkansas           0.03   614   594   1208\n",
       "4  California           0.53   531   524   1055"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column for year\n",
    "\n",
    "sat_2017['year'] = str('2017')\n",
    "sat_2018['year'] = str('2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>participation</th>\n",
       "      <th>erwb</th>\n",
       "      <th>math</th>\n",
       "      <th>total</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>0.05</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.38</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.30</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>0.03</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>0.53</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state  participation  erwb  math  total  year\n",
       "0     Alabama           0.05   593   572   1165  2017\n",
       "1      Alaska           0.38   547   533   1080  2017\n",
       "2     Arizona           0.30   563   553   1116  2017\n",
       "3    Arkansas           0.03   614   594   1208  2017\n",
       "4  California           0.53   531   524   1055  2017"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>participation</th>\n",
       "      <th>erwb</th>\n",
       "      <th>math</th>\n",
       "      <th>total</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>0.06</td>\n",
       "      <td>595</td>\n",
       "      <td>571</td>\n",
       "      <td>1166</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>0.43</td>\n",
       "      <td>562</td>\n",
       "      <td>544</td>\n",
       "      <td>1106</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>0.29</td>\n",
       "      <td>577</td>\n",
       "      <td>572</td>\n",
       "      <td>1149</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>0.05</td>\n",
       "      <td>592</td>\n",
       "      <td>576</td>\n",
       "      <td>1169</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>0.60</td>\n",
       "      <td>540</td>\n",
       "      <td>536</td>\n",
       "      <td>1076</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state  participation  erwb  math  total  year\n",
       "0     Alabama           0.06   595   571   1166  2018\n",
       "1      Alaska           0.43   562   544   1106  2018\n",
       "2     Arizona           0.29   577   572   1149  2018\n",
       "3    Arkansas           0.05   592   576   1169  2018\n",
       "4  California           0.60   540   536   1076  2018"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_combine = pd.concat([sat_2018,sat_2017])\n",
    "sat_combine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combining Act data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52 entries, 0 to 51\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   State          52 non-null     object \n",
      " 1   Participation  52 non-null     float64\n",
      " 2   Composite      52 non-null     float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 1.3+ KB\n"
     ]
    }
   ],
   "source": [
    "act_2018.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52 entries, 0 to 51\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   State          52 non-null     object \n",
      " 1   Participation  52 non-null     float64\n",
      " 2   English        52 non-null     float64\n",
      " 3   Math           52 non-null     float64\n",
      " 4   Reading        52 non-null     float64\n",
      " 5   Science        52 non-null     float64\n",
      " 6   Composite      52 non-null     object \n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 3.0+ KB\n"
     ]
    }
   ],
   "source": [
    "## noticed there was an object in Composite  \n",
    "\n",
    "act_2017.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52 entries, 0 to 51\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   State          52 non-null     object \n",
      " 1   Participation  52 non-null     float64\n",
      " 2   English        52 non-null     float64\n",
      " 3   Math           52 non-null     float64\n",
      " 4   Reading        52 non-null     float64\n",
      " 5   Science        52 non-null     float64\n",
      " 6   Composite      52 non-null     float64\n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 3.0+ KB\n"
     ]
    }
   ],
   "source": [
    "def remove_letters_return_num(string):\n",
    "    return float(''.join([x for x in string if (x =='.') or (x.isdigit())]))\n",
    "\n",
    "act_2017['Composite'] = act_2017['Composite'].apply(lambda x: remove_letters_return_num(x))\n",
    "\n",
    "act_2017.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52 entries, 0 to 51\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   State          52 non-null     object \n",
      " 1   Participation  52 non-null     float64\n",
      " 2   Composite      52 non-null     float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 1.3+ KB\n"
     ]
    }
   ],
   "source": [
    "act_2018.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation_x</th>\n",
       "      <th>Composite_x</th>\n",
       "      <th>Participation_y</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite_y</th>\n",
       "      <th>Exist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>District of columbia</td>\n",
       "      <td>0.32</td>\n",
       "      <td>23.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>National</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.60</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.32</td>\n",
       "      <td>24.4</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.9</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.2</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   State  Participation_x  Composite_x  Participation_y  \\\n",
       "8   District of columbia             0.32         23.6              NaN   \n",
       "52              National              NaN          NaN             0.60   \n",
       "53  District of Columbia              NaN          NaN             0.32   \n",
       "\n",
       "    English  Math  Reading  Science  Composite_y       Exist  \n",
       "8       NaN   NaN      NaN      NaN          NaN   left_only  \n",
       "52     20.3  20.7     21.4     21.0         21.0  right_only  \n",
       "53     24.4  23.5     24.9     23.5         24.2  right_only  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to identify different column names based on 'college'\n",
    "\n",
    "diff_df = pd.merge(act_2018, act_2017, how='outer', indicator='Exist', on = 'State')\n",
    "\n",
    "diff_df = diff_df.loc[diff_df['Exist'] != 'both']\n",
    "\n",
    "diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get index from act_2018 data \n",
    "\n",
    "set_index = act_2018[sat_major_2019['State'] == 'District of columbia'].index\n",
    "set_index2 = act_2018[sat_major_2019['State'] == 'District of Columbia'].index\n",
    "\n",
    "# drop from sat_major_2019\n",
    "\n",
    "act_2018.drop(set_index, inplace = True)\n",
    "sat_major_2019.drop(set_index2, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sat_major_2021' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-cda9f272c7b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# to identify different column names based on 'college'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdiff_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msat_major_2021\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msat_major_2020\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'outer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Exist'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'college'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdiff_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiff_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdiff_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Exist'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'both'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sat_major_2021' is not defined"
     ]
    }
   ],
   "source": [
    "# to identify different column names based on 'college'\n",
    "\n",
    "diff_df = pd.merge(sat_major_2021, sat_major_2020, how='outer', indicator='Exist', on = 'college')\n",
    "\n",
    "diff_df = diff_df.loc[diff_df['Exist'] != 'both']\n",
    "\n",
    "diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace with CAPS\n",
    "sat_major_2021.loc[25,'college'] = diff_df.loc[36,'college']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#check edited \n",
    "\n",
    "sat_major_2021[sat_major_2021['college'] == \"Personal And Culinary Services, General\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#found two rows not used for data in 2021,2020\n",
    "\n",
    "diff_df = pd.merge(sat_major_2021, sat_major_2019, how='outer', indicator='Exist', on = 'college')\n",
    "\n",
    "diff_df = diff_df.loc[diff_df['Exist'] != 'both']\n",
    "\n",
    "diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get index from 2019 data \n",
    "\n",
    "set_index = sat_major_2019[sat_major_2019['college'] == 'Precision Production'].index\n",
    "set_index2 = sat_major_2019[sat_major_2019['college'] == 'Transportation and Materials Moving'].index\n",
    "\n",
    "# drop from sat_major_2019\n",
    "\n",
    "sat_major_2019.drop(set_index, inplace = True)\n",
    "sat_major_2019.drop(set_index2, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reset and remove old index\n",
    "\n",
    "sat_major_2019.reset_index(inplace = True)\n",
    "sat_major_2019.drop('index',axis = 1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_major_2019.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate year on each data set \n",
    "\n",
    "sat_major_2019['Year'] = 2019\n",
    "sat_major_2020['Year'] = 2020\n",
    "sat_major_2021['Year'] = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sat_major_2021.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAT_MAJOR = pd.concat([sat_major_2019,sat_major_2020,sat_major_2021])\n",
    "SAT_MAJOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAT_MAJOR.drop('index', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Column (Total) between ERW and Math \n",
    "\n",
    "SAT_MAJOR['Total'] = SAT_MAJOR['ERW'] + SAT_MAJOR['Math']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'Year', y = 'test_taker', data = SAT_MAJOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Family income object \n",
    "\n",
    "income_ca.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect income_ca \n",
    "\n",
    "income_ca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to help remove punctuations \n",
    "\n",
    "def remove_punc_convertnum(alist):\n",
    "    return ''.join([i for i in alist if i not in ['$',',']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_ca['income_range'] = income_ca['Family Income'].apply(lambda x: remove_punc_convertnum(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "income_ca['income_range']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# defining function that collects the mean between values in a string\n",
    "\n",
    "def getmean(sample):\n",
    "    number = 0 \n",
    "    for num in sample:\n",
    "        number = num + number\n",
    "        \n",
    "    return int(number/len(sample))\n",
    "\n",
    "def get_number_from_string(string):\n",
    "    count = 0\n",
    "    splitlist = string.split()\n",
    "    emptylist = []\n",
    "    for num, word in enumerate (splitlist):\n",
    "        if word.isdigit():\n",
    "            count += 1\n",
    "            emptylist.append(int(word))\n",
    "            \n",
    "    if count == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return getmean(emptylist)\n",
    "\n",
    "income_ca['income_range'] = income_ca['income_range'].apply(lambda x: get_number_from_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "income_ca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_ca['total'] = income_ca['Math Mean']  + income_ca['Writing Mean'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_ca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x = 'total', y = 'income_range', data=income_ca);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing SAT Vs GPA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satgpa= pd.read_csv('Data/satgpa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "satgpa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satgpa.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satgpa.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask to prevent duplication of variables\n",
    "mask = np.zeros(satgpa.corr().shape, dtype=bool)\n",
    "mask[np.triu_indices(len(mask))] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "plt.title('Heatmap between GPA vs SATS', fontsize=14)\n",
    "sns.heatmap(satgpa.corr(), cmap='RdBu', annot=True, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## comments \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satgpa.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"hs_gpa\", y=\"fy_gpa\", data=satgpa, hue='sex');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"sat_sum\", y=\"fy_gpa\", data=satgpa, hue='sex');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"hs_gpa\", y=\"fy_gpa\", data=satgpa, kind=\"reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satgpa['sat_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.histplot(data=satgpa, x=\"sat_sum\", hue=\"sex\", multiple=\"stack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=satgpa, x=\"sat_sum\", col=\"sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(satgpa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.PairGrid(satgpa)\n",
    "g.map_upper(sns.histplot)\n",
    "g.map_lower(sns.kdeplot, fill=True)\n",
    "g.map_diag(sns.histplot, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SATs_Combined3['Institution'].values\n",
    "\n",
    "Master_list[Master_list['Institution']] == 'California State University Mentor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Master_list = pd.concat([Sat_2017,Sat_2018,Sat_2019,Sat_2020,Sat_2021])\n",
    "Master_list.groupby('Year').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describes students from California applying for colleges \n",
    "\n",
    "sns.boxplot(x = 'Year', y = 'Number of Students' , data = Master_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAT% drop in enrollment \n",
    "\n",
    "mean_2020, pct_score, year = Master_list[Master_list['Year'] == 2020].mean()\n",
    "mean_2021, pct_score, year = Master_list[Master_list['Year'] == 2021].mean()\n",
    "\n",
    "\n",
    "percent_drop = round(((mean_2021-mean_2020)/mean_2020)*100,ndigits = 4)\n",
    "\n",
    "percent_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(SATs_Combined3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate year on each data set \n",
    "sat_major_2017['Year'] = 2017\n",
    "sat_major_2018['Year'] = 2018\n",
    "sat_major_2019['Year'] = 2019\n",
    "sat_major_2020['Year'] = 2020\n",
    "sat_major_2021['Year'] = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_major_2021.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAT_MAJOR = pd.concat([sat_major_2017,sat_major_2018,sat_major_2019,sat_major_2020,sat_major_2021])\n",
    "SAT_MAJOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAT_MAJOR.drop(SAT_MAJOR.columns(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SAT_MAJOR.groupby('Year').sum()['Test Takers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAT_MAJOR.groupby('Year').mean()['Test Takers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'Year', y = 'Test Takers' , data = SAT_MAJOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAT_MAJOR.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "\n",
    "Now that we've fixed our data, and given it appropriate names, let's create a [data dictionary](http://library.ucmerced.edu/node/10249). \n",
    "\n",
    "A data dictionary provides a quick overview of features/variables/columns, alongside data types and descriptions. The more descriptive you can be, the more useful this document is.\n",
    "\n",
    "Example of a Fictional Data Dictionary Entry: \n",
    "\n",
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|**county_pop**|*integer*|2010 census|The population of the county (units in thousands, where 2.5 represents 2500 people).| \n",
    "|**per_poverty**|*float*|2010 census|The percent of the county over the age of 18 living below the 200% of official US poverty rate (units percent to two decimal places 98.10 means 98.1%)|\n",
    "\n",
    "[Here's a quick link to a short guide for formatting markdown in Jupyter notebooks](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html).\n",
    "\n",
    "Provided is the skeleton for formatting a markdown table, with columns headers that will help you create a data dictionary to quickly summarize your data, as well as some examples. **This would be a great thing to copy and paste into your custom README for this project.**\n",
    "\n",
    "*Note*: if you are unsure of what a feature is, check the source of the data! This can be found in the README."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-Do:** *Edit the table below to create your own data dictionary for the datasets you chose.*\n",
    "\n",
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|column name|int/float/object|ACT/SAT|This is an example| \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Complete the following steps to explore your data. You are welcome to do more EDA than the steps outlined here as you feel necessary:\n",
    "1. Summary Statistics.\n",
    "2. Use a **dictionary comprehension** to apply the standard deviation function you create in part 1 to each numeric column in the dataframe.  **No loops**.\n",
    "    - Assign the output to variable `sd` as a dictionary where: \n",
    "        - Each column name is now a key \n",
    "        - That standard deviation of the column is the value \n",
    "        - *Example Output :* `{'ACT_Math': 120, 'ACT_Reading': 120, ...}`\n",
    "3. Investigate trends in the data.\n",
    "    - Using sorting and/or masking (along with the `.head()` method to avoid printing our entire dataframe), consider questions relevant to your problem statement. Some examples are provided below (but feel free to change these questions for your specific problem):\n",
    "        - Which states have the highest and lowest participation rates for the 2017, 2019, or 2019 SAT and ACT?\n",
    "        - Which states have the highest and lowest mean total/composite scores for the 2017, 2019, or 2019 SAT and ACT?\n",
    "        - Do any states with 100% participation on a given test have a rate change year-to-year?\n",
    "        - Do any states show have >50% participation on *both* tests each year?\n",
    "        - Which colleges have the highest median SAT and ACT scores for admittance?\n",
    "        - Which California school districts have the highest and lowest mean test scores?\n",
    "    - **You should comment on your findings at each step in a markdown cell below your code block**. Make sure you include at least one example of sorting your dataframe by a column, and one example of using boolean filtering (i.e., masking) to select a subset of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-Do:** *Edit this cell with your findings on trends in the data (step 3 above).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Data\n",
    "\n",
    "There's not a magic bullet recommendation for the right number of plots to understand a given dataset, but visualizing your data is *always* a good idea. Not only does it allow you to quickly convey your findings (even if you have a non-technical audience), it will often reveal trends in your data that escaped you when you were looking only at numbers. It is important to not only create visualizations, but to **interpret your visualizations** as well.\n",
    "\n",
    "**Every plot should**:\n",
    "- Have a title\n",
    "- Have axis labels\n",
    "- Have appropriate tick labels\n",
    "- Text is legible in a plot\n",
    "- Plots demonstrate meaningful and valid relationships\n",
    "- Have an interpretation to aid understanding\n",
    "\n",
    "Here is an example of what your plots should look like following the above guidelines. Note that while the content of this example is unrelated, the principles of visualization hold:\n",
    "\n",
    "![](https://snag.gy/hCBR1U.jpg)\n",
    "*Interpretation: The above image shows that as we increase our spending on advertising, our sales numbers also tend to increase. There is a positive correlation between advertising spending and sales.*\n",
    "\n",
    "---\n",
    "\n",
    "Here are some prompts to get you started with visualizations. Feel free to add additional visualizations as you see fit:\n",
    "1. Use Seaborn's heatmap with pandas `.corr()` to visualize correlations between all numeric features.\n",
    "    - Heatmaps are generally not appropriate for presentations, and should often be excluded from reports as they can be visually overwhelming. **However**, they can be extremely useful in identify relationships of potential interest (as well as identifying potential collinearity before modeling).\n",
    "    - Please take time to format your output, adding a title. Look through some of the additional arguments and options. (Axis labels aren't really necessary, as long as the title is informative).\n",
    "2. Visualize distributions using histograms. If you have a lot, consider writing a custom function and use subplots.\n",
    "    - *OPTIONAL*: Summarize the underlying distributions of your features (in words & statistics)\n",
    "         - Be thorough in your verbal description of these distributions.\n",
    "         - Be sure to back up these summaries with statistics.\n",
    "         - We generally assume that data we sample from a population will be normally distributed. Do we observe this trend? Explain your answers for each distribution and how you think this will affect estimates made from these data.\n",
    "3. Plot and interpret boxplots. \n",
    "    - Boxplots demonstrate central tendency and spread in variables. In a certain sense, these are somewhat redundant with histograms, but you may be better able to identify clear outliers or differences in IQR, etc.\n",
    "    - Multiple values can be plotted to a single boxplot as long as they are of the same relative scale (meaning they have similar min/max values).\n",
    "    - Each boxplot should:\n",
    "        - Only include variables of a similar scale\n",
    "        - Have clear labels for each variable\n",
    "        - Have appropriate titles and labels\n",
    "4. Plot and interpret scatter plots to view relationships between features. Feel free to write a custom function, and subplot if you'd like. Functions save both time and space.\n",
    "    - Your plots should have:\n",
    "        - Two clearly labeled axes\n",
    "        - A proper title\n",
    "        - Colors and symbols that are clear and unmistakable\n",
    "5. Additional plots of your choosing.\n",
    "    - Are there any additional trends or relationships you haven't explored? Was there something interesting you saw that you'd like to dive further into? It's likely that there are a few more plots you might want to generate to support your narrative and recommendations that you are building toward. **As always, make sure you're interpreting your plots as you go**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your exploration of the data, what are you key takeaways and recommendations? Make sure to answer your question of interest or address your problem statement here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-Do:** *Edit this cell with your conclusions and recommendations.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to create your README!\n",
    "\n",
    "**To-Do:** *If you combine your problem statement, data dictionary, brief summary of your analysis, and conclusions/recommendations, you have an amazing README.md file that quickly aligns your audience to the contents of your project.* Don't forget to cite your data sources!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
