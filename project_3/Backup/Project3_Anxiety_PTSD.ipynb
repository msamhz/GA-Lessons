{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import string\n",
    "string.punctuation\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk import word_tokenize   \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import(\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    "    GridSearchCV\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    PolynomialFeatures\n",
    ")\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anxiety = pd.read_csv('Anxiety.csv')\n",
    "df_ptsd = pd.read_csv('PTSD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anxiety = df_anxiety.drop(columns = 'Unnamed: 0')\n",
    "df_ptsd.drop(columns = 'Unnamed: 0', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_ptsd,df_anxiety])\n",
    "df.reset_index(inplace = True)\n",
    "df.drop(columns = 'index', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20298, 5)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to remove punctuation and remove \\n\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    punctuationfree = ' '.join([sentence for sentence in punctuationfree.split('\\n') if sentence != ''])\n",
    "    return punctuationfree\n",
    "\n",
    "columns = ['selftext', 'title']\n",
    "\n",
    "for col in columns:\n",
    "    new_col = str('clean_' + col)\n",
    "    df[new_col] = df[col].apply(lambda x: remove_punctuation(x))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>datetime</th>\n",
       "      <th>clean_selftext</th>\n",
       "      <th>clean_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>So, I was on tick-tock and a therapist was talking about healing PTSD and I don't know if it's my night shift brain but I thought I kinda had PTSD forever now? Like.yeah.i can learn to love with it but I wouldn't class that as healing it? Idek I'm confused and sleepy sorry for the ramble!</td>\n",
       "      <td>Can PTSD be healed?</td>\n",
       "      <td>1647751986</td>\n",
       "      <td>2022-03-20 04:53:06</td>\n",
       "      <td>So I was on ticktock and a therapist was talking about healing PTSD and I dont know if its my night shift brain but I thought I kinda had PTSD forever now Likeyeahi can learn to love with it but I wouldnt class that as healing it Idek Im confused and sleepy sorry for the ramble</td>\n",
       "      <td>Can PTSD be healed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>I just need to share this and my feelings about it somewhere. It's too personal for my regular social media but I have to put it into writing in some way.\\n\\nI've been avoiding googling my abusive ex boyfriend for ten years. Just thinking about him made me sick. Two years ago I finally got trauma therapy to deal with what he did to me. Constant humiliation, degradation, sexual abuse and rape. \\n\\nTonight I randomly felt curious about where he would be in life now, so I googled him. Turns out he died two years ago, about the same time as my trauma therapy started. I found this webpage where his friends and family had written how much they missed him. How they'd never forget his smile, the same smile that makes my skin crawl just thinking about it. \\n\\nI've never felt happy about anyone's death before but I actually feel like celebrating. It's not relief because he was already out of my life and I was never scared of him showing up or hurting me again. It's just.. triumph. I still suffer the consequences of what he did to me. I still can't make relationships work and I still flinch when men get close to touching me because of him. I'm not ashamed to say that I hope he suffered before he died.\\n\\nThere's not much to discuss here I guess, I just didn't know where else to share this honestly.</td>\n",
       "      <td>Just found out my abuser is dead</td>\n",
       "      <td>1647747979</td>\n",
       "      <td>2022-03-20 03:46:19</td>\n",
       "      <td>I just need to share this and my feelings about it somewhere Its too personal for my regular social media but I have to put it into writing in some way Ive been avoiding googling my abusive ex boyfriend for ten years Just thinking about him made me sick Two years ago I finally got trauma therapy to deal with what he did to me Constant humiliation degradation sexual abuse and rape  Tonight I randomly felt curious about where he would be in life now so I googled him Turns out he died two years ago about the same time as my trauma therapy started I found this webpage where his friends and family had written how much they missed him How theyd never forget his smile the same smile that makes my skin crawl just thinking about it  Ive never felt happy about anyones death before but I actually feel like celebrating Its not relief because he was already out of my life and I was never scared of him showing up or hurting me again Its just triumph I still suffer the consequences of what he did to me I still cant make relationships work and I still flinch when men get close to touching me because of him Im not ashamed to say that I hope he suffered before he died Theres not much to discuss here I guess I just didnt know where else to share this honestly</td>\n",
       "      <td>Just found out my abuser is dead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>I was kidnapped at the age of 22 by a psychotic maniac on the run from the law and held against my will for 11 months\\nIt was hell.  Everyday was hell.  Of course I now have complex PTSD.  I'm 64 now and am still traumatized.  My whole life was ruined by the time I was 23.  I never got married, never had kids.  I've been a loner ever since. I still get intrusive memories of horrific child abuse.  I don't know why I'm even posting this.  But I know people here understand.</td>\n",
       "      <td>PTSD never goes away... I'm tired of it</td>\n",
       "      <td>1647747031</td>\n",
       "      <td>2022-03-20 03:30:31</td>\n",
       "      <td>I was kidnapped at the age of 22 by a psychotic maniac on the run from the law and held against my will for 11 months It was hell  Everyday was hell  Of course I now have complex PTSD  Im 64 now and am still traumatized  My whole life was ruined by the time I was 23  I never got married never had kids  Ive been a loner ever since I still get intrusive memories of horrific child abuse  I dont know why Im even posting this  But I know people here understand</td>\n",
       "      <td>PTSD never goes away Im tired of it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit  \\\n",
       "0      ptsd   \n",
       "1      ptsd   \n",
       "2      ptsd   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       selftext  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             So, I was on tick-tock and a therapist was talking about healing PTSD and I don't know if it's my night shift brain but I thought I kinda had PTSD forever now? Like.yeah.i can learn to love with it but I wouldn't class that as healing it? Idek I'm confused and sleepy sorry for the ramble!   \n",
       "1  I just need to share this and my feelings about it somewhere. It's too personal for my regular social media but I have to put it into writing in some way.\\n\\nI've been avoiding googling my abusive ex boyfriend for ten years. Just thinking about him made me sick. Two years ago I finally got trauma therapy to deal with what he did to me. Constant humiliation, degradation, sexual abuse and rape. \\n\\nTonight I randomly felt curious about where he would be in life now, so I googled him. Turns out he died two years ago, about the same time as my trauma therapy started. I found this webpage where his friends and family had written how much they missed him. How they'd never forget his smile, the same smile that makes my skin crawl just thinking about it. \\n\\nI've never felt happy about anyone's death before but I actually feel like celebrating. It's not relief because he was already out of my life and I was never scared of him showing up or hurting me again. It's just.. triumph. I still suffer the consequences of what he did to me. I still can't make relationships work and I still flinch when men get close to touching me because of him. I'm not ashamed to say that I hope he suffered before he died.\\n\\nThere's not much to discuss here I guess, I just didn't know where else to share this honestly.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   I was kidnapped at the age of 22 by a psychotic maniac on the run from the law and held against my will for 11 months\\nIt was hell.  Everyday was hell.  Of course I now have complex PTSD.  I'm 64 now and am still traumatized.  My whole life was ruined by the time I was 23.  I never got married, never had kids.  I've been a loner ever since. I still get intrusive memories of horrific child abuse.  I don't know why I'm even posting this.  But I know people here understand.   \n",
       "\n",
       "                                     title  created_utc             datetime  \\\n",
       "0                      Can PTSD be healed?   1647751986  2022-03-20 04:53:06   \n",
       "1         Just found out my abuser is dead   1647747979  2022-03-20 03:46:19   \n",
       "2  PTSD never goes away... I'm tired of it   1647747031  2022-03-20 03:30:31   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 clean_selftext  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        So I was on ticktock and a therapist was talking about healing PTSD and I dont know if its my night shift brain but I thought I kinda had PTSD forever now Likeyeahi can learn to love with it but I wouldnt class that as healing it Idek Im confused and sleepy sorry for the ramble   \n",
       "1  I just need to share this and my feelings about it somewhere Its too personal for my regular social media but I have to put it into writing in some way Ive been avoiding googling my abusive ex boyfriend for ten years Just thinking about him made me sick Two years ago I finally got trauma therapy to deal with what he did to me Constant humiliation degradation sexual abuse and rape  Tonight I randomly felt curious about where he would be in life now so I googled him Turns out he died two years ago about the same time as my trauma therapy started I found this webpage where his friends and family had written how much they missed him How theyd never forget his smile the same smile that makes my skin crawl just thinking about it  Ive never felt happy about anyones death before but I actually feel like celebrating Its not relief because he was already out of my life and I was never scared of him showing up or hurting me again Its just triumph I still suffer the consequences of what he did to me I still cant make relationships work and I still flinch when men get close to touching me because of him Im not ashamed to say that I hope he suffered before he died Theres not much to discuss here I guess I just didnt know where else to share this honestly   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   I was kidnapped at the age of 22 by a psychotic maniac on the run from the law and held against my will for 11 months It was hell  Everyday was hell  Of course I now have complex PTSD  Im 64 now and am still traumatized  My whole life was ruined by the time I was 23  I never got married never had kids  Ive been a loner ever since I still get intrusive memories of horrific child abuse  I dont know why Im even posting this  But I know people here understand   \n",
       "\n",
       "                           clean_title  \n",
       "0                   Can PTSD be healed  \n",
       "1     Just found out my abuser is dead  \n",
       "2  PTSD never goes away Im tired of it  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing all to lower caps \n",
    "\n",
    "columns = ['clean_selftext', 'clean_title']\n",
    "\n",
    "for col in columns:\n",
    "    new_col = str('lower_' + col.split('_')[1])\n",
    "    df[new_col] = df[col].apply(lambda x: x.lower())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ptsd       10188\n",
       "Anxiety    10110\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>datetime</th>\n",
       "      <th>clean_selftext</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>lower_selftext</th>\n",
       "      <th>lower_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>So, I was on tick-tock and a therapist was talking about healing PTSD and I don't know if it's my night shift brain but I thought I kinda had PTSD forever now? Like.yeah.i can learn to love with it but I wouldn't class that as healing it? Idek I'm confused and sleepy sorry for the ramble!</td>\n",
       "      <td>Can PTSD be healed?</td>\n",
       "      <td>1647751986</td>\n",
       "      <td>2022-03-20 04:53:06</td>\n",
       "      <td>So I was on ticktock and a therapist was talking about healing PTSD and I dont know if its my night shift brain but I thought I kinda had PTSD forever now Likeyeahi can learn to love with it but I wouldnt class that as healing it Idek Im confused and sleepy sorry for the ramble</td>\n",
       "      <td>Can PTSD be healed</td>\n",
       "      <td>so i was on ticktock and a therapist was talking about healing ptsd and i dont know if its my night shift brain but i thought i kinda had ptsd forever now likeyeahi can learn to love with it but i wouldnt class that as healing it idek im confused and sleepy sorry for the ramble</td>\n",
       "      <td>can ptsd be healed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>I just need to share this and my feelings about it somewhere. It's too personal for my regular social media but I have to put it into writing in some way.\\n\\nI've been avoiding googling my abusive ex boyfriend for ten years. Just thinking about him made me sick. Two years ago I finally got trauma therapy to deal with what he did to me. Constant humiliation, degradation, sexual abuse and rape. \\n\\nTonight I randomly felt curious about where he would be in life now, so I googled him. Turns out he died two years ago, about the same time as my trauma therapy started. I found this webpage where his friends and family had written how much they missed him. How they'd never forget his smile, the same smile that makes my skin crawl just thinking about it. \\n\\nI've never felt happy about anyone's death before but I actually feel like celebrating. It's not relief because he was already out of my life and I was never scared of him showing up or hurting me again. It's just.. triumph. I still suffer the consequences of what he did to me. I still can't make relationships work and I still flinch when men get close to touching me because of him. I'm not ashamed to say that I hope he suffered before he died.\\n\\nThere's not much to discuss here I guess, I just didn't know where else to share this honestly.</td>\n",
       "      <td>Just found out my abuser is dead</td>\n",
       "      <td>1647747979</td>\n",
       "      <td>2022-03-20 03:46:19</td>\n",
       "      <td>I just need to share this and my feelings about it somewhere Its too personal for my regular social media but I have to put it into writing in some way Ive been avoiding googling my abusive ex boyfriend for ten years Just thinking about him made me sick Two years ago I finally got trauma therapy to deal with what he did to me Constant humiliation degradation sexual abuse and rape  Tonight I randomly felt curious about where he would be in life now so I googled him Turns out he died two years ago about the same time as my trauma therapy started I found this webpage where his friends and family had written how much they missed him How theyd never forget his smile the same smile that makes my skin crawl just thinking about it  Ive never felt happy about anyones death before but I actually feel like celebrating Its not relief because he was already out of my life and I was never scared of him showing up or hurting me again Its just triumph I still suffer the consequences of what he did to me I still cant make relationships work and I still flinch when men get close to touching me because of him Im not ashamed to say that I hope he suffered before he died Theres not much to discuss here I guess I just didnt know where else to share this honestly</td>\n",
       "      <td>Just found out my abuser is dead</td>\n",
       "      <td>i just need to share this and my feelings about it somewhere its too personal for my regular social media but i have to put it into writing in some way ive been avoiding googling my abusive ex boyfriend for ten years just thinking about him made me sick two years ago i finally got trauma therapy to deal with what he did to me constant humiliation degradation sexual abuse and rape  tonight i randomly felt curious about where he would be in life now so i googled him turns out he died two years ago about the same time as my trauma therapy started i found this webpage where his friends and family had written how much they missed him how theyd never forget his smile the same smile that makes my skin crawl just thinking about it  ive never felt happy about anyones death before but i actually feel like celebrating its not relief because he was already out of my life and i was never scared of him showing up or hurting me again its just triumph i still suffer the consequences of what he did to me i still cant make relationships work and i still flinch when men get close to touching me because of him im not ashamed to say that i hope he suffered before he died theres not much to discuss here i guess i just didnt know where else to share this honestly</td>\n",
       "      <td>just found out my abuser is dead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>I was kidnapped at the age of 22 by a psychotic maniac on the run from the law and held against my will for 11 months\\nIt was hell.  Everyday was hell.  Of course I now have complex PTSD.  I'm 64 now and am still traumatized.  My whole life was ruined by the time I was 23.  I never got married, never had kids.  I've been a loner ever since. I still get intrusive memories of horrific child abuse.  I don't know why I'm even posting this.  But I know people here understand.</td>\n",
       "      <td>PTSD never goes away... I'm tired of it</td>\n",
       "      <td>1647747031</td>\n",
       "      <td>2022-03-20 03:30:31</td>\n",
       "      <td>I was kidnapped at the age of 22 by a psychotic maniac on the run from the law and held against my will for 11 months It was hell  Everyday was hell  Of course I now have complex PTSD  Im 64 now and am still traumatized  My whole life was ruined by the time I was 23  I never got married never had kids  Ive been a loner ever since I still get intrusive memories of horrific child abuse  I dont know why Im even posting this  But I know people here understand</td>\n",
       "      <td>PTSD never goes away Im tired of it</td>\n",
       "      <td>i was kidnapped at the age of 22 by a psychotic maniac on the run from the law and held against my will for 11 months it was hell  everyday was hell  of course i now have complex ptsd  im 64 now and am still traumatized  my whole life was ruined by the time i was 23  i never got married never had kids  ive been a loner ever since i still get intrusive memories of horrific child abuse  i dont know why im even posting this  but i know people here understand</td>\n",
       "      <td>ptsd never goes away im tired of it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit  \\\n",
       "0      ptsd   \n",
       "1      ptsd   \n",
       "2      ptsd   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       selftext  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             So, I was on tick-tock and a therapist was talking about healing PTSD and I don't know if it's my night shift brain but I thought I kinda had PTSD forever now? Like.yeah.i can learn to love with it but I wouldn't class that as healing it? Idek I'm confused and sleepy sorry for the ramble!   \n",
       "1  I just need to share this and my feelings about it somewhere. It's too personal for my regular social media but I have to put it into writing in some way.\\n\\nI've been avoiding googling my abusive ex boyfriend for ten years. Just thinking about him made me sick. Two years ago I finally got trauma therapy to deal with what he did to me. Constant humiliation, degradation, sexual abuse and rape. \\n\\nTonight I randomly felt curious about where he would be in life now, so I googled him. Turns out he died two years ago, about the same time as my trauma therapy started. I found this webpage where his friends and family had written how much they missed him. How they'd never forget his smile, the same smile that makes my skin crawl just thinking about it. \\n\\nI've never felt happy about anyone's death before but I actually feel like celebrating. It's not relief because he was already out of my life and I was never scared of him showing up or hurting me again. It's just.. triumph. I still suffer the consequences of what he did to me. I still can't make relationships work and I still flinch when men get close to touching me because of him. I'm not ashamed to say that I hope he suffered before he died.\\n\\nThere's not much to discuss here I guess, I just didn't know where else to share this honestly.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   I was kidnapped at the age of 22 by a psychotic maniac on the run from the law and held against my will for 11 months\\nIt was hell.  Everyday was hell.  Of course I now have complex PTSD.  I'm 64 now and am still traumatized.  My whole life was ruined by the time I was 23.  I never got married, never had kids.  I've been a loner ever since. I still get intrusive memories of horrific child abuse.  I don't know why I'm even posting this.  But I know people here understand.   \n",
       "\n",
       "                                     title  created_utc             datetime  \\\n",
       "0                      Can PTSD be healed?   1647751986  2022-03-20 04:53:06   \n",
       "1         Just found out my abuser is dead   1647747979  2022-03-20 03:46:19   \n",
       "2  PTSD never goes away... I'm tired of it   1647747031  2022-03-20 03:30:31   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 clean_selftext  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        So I was on ticktock and a therapist was talking about healing PTSD and I dont know if its my night shift brain but I thought I kinda had PTSD forever now Likeyeahi can learn to love with it but I wouldnt class that as healing it Idek Im confused and sleepy sorry for the ramble   \n",
       "1  I just need to share this and my feelings about it somewhere Its too personal for my regular social media but I have to put it into writing in some way Ive been avoiding googling my abusive ex boyfriend for ten years Just thinking about him made me sick Two years ago I finally got trauma therapy to deal with what he did to me Constant humiliation degradation sexual abuse and rape  Tonight I randomly felt curious about where he would be in life now so I googled him Turns out he died two years ago about the same time as my trauma therapy started I found this webpage where his friends and family had written how much they missed him How theyd never forget his smile the same smile that makes my skin crawl just thinking about it  Ive never felt happy about anyones death before but I actually feel like celebrating Its not relief because he was already out of my life and I was never scared of him showing up or hurting me again Its just triumph I still suffer the consequences of what he did to me I still cant make relationships work and I still flinch when men get close to touching me because of him Im not ashamed to say that I hope he suffered before he died Theres not much to discuss here I guess I just didnt know where else to share this honestly   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   I was kidnapped at the age of 22 by a psychotic maniac on the run from the law and held against my will for 11 months It was hell  Everyday was hell  Of course I now have complex PTSD  Im 64 now and am still traumatized  My whole life was ruined by the time I was 23  I never got married never had kids  Ive been a loner ever since I still get intrusive memories of horrific child abuse  I dont know why Im even posting this  But I know people here understand   \n",
       "\n",
       "                           clean_title  \\\n",
       "0                   Can PTSD be healed   \n",
       "1     Just found out my abuser is dead   \n",
       "2  PTSD never goes away Im tired of it   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 lower_selftext  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        so i was on ticktock and a therapist was talking about healing ptsd and i dont know if its my night shift brain but i thought i kinda had ptsd forever now likeyeahi can learn to love with it but i wouldnt class that as healing it idek im confused and sleepy sorry for the ramble   \n",
       "1  i just need to share this and my feelings about it somewhere its too personal for my regular social media but i have to put it into writing in some way ive been avoiding googling my abusive ex boyfriend for ten years just thinking about him made me sick two years ago i finally got trauma therapy to deal with what he did to me constant humiliation degradation sexual abuse and rape  tonight i randomly felt curious about where he would be in life now so i googled him turns out he died two years ago about the same time as my trauma therapy started i found this webpage where his friends and family had written how much they missed him how theyd never forget his smile the same smile that makes my skin crawl just thinking about it  ive never felt happy about anyones death before but i actually feel like celebrating its not relief because he was already out of my life and i was never scared of him showing up or hurting me again its just triumph i still suffer the consequences of what he did to me i still cant make relationships work and i still flinch when men get close to touching me because of him im not ashamed to say that i hope he suffered before he died theres not much to discuss here i guess i just didnt know where else to share this honestly   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   i was kidnapped at the age of 22 by a psychotic maniac on the run from the law and held against my will for 11 months it was hell  everyday was hell  of course i now have complex ptsd  im 64 now and am still traumatized  my whole life was ruined by the time i was 23  i never got married never had kids  ive been a loner ever since i still get intrusive memories of horrific child abuse  i dont know why im even posting this  but i know people here understand   \n",
       "\n",
       "                           lower_title  \n",
       "0                   can ptsd be healed  \n",
       "1     just found out my abuser is dead  \n",
       "2  ptsd never goes away im tired of it  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'ptsd',\n",
       " 'anxiety',\n",
       " 'trauma',\n",
       " 'posttraumatic',\n",
       " 'stress',\n",
       " 'disorder',\n",
       " 'traumatic',\n",
       " \"'d\",\n",
       " \"'ll\",\n",
       " \"'re\",\n",
       " \"'s\",\n",
       " \"'ve\",\n",
       " 'could',\n",
       " 'doe',\n",
       " 'ha',\n",
       " 'might',\n",
       " 'must',\n",
       " \"n't\",\n",
       " 'need',\n",
       " 'sha',\n",
       " 'wa',\n",
       " 'wo',\n",
       " 'would']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create stop word list \n",
    "stopwordlist = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# to input in subreddit headers so that we can exclude it for model\n",
    "headers = ['ptsd', 'anxiety','trauma',\"cptsd\",\"posttraumatic\",'stress','disorder',\"traumatic\",\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'doe', 'ha', 'might', 'must', \"n't\", 'need', 'sha', 'wa', 'wo', 'would']\n",
    "for head in headers:\n",
    "    stopwordlist.append(head)\n",
    "\n",
    "\n",
    "stopwordlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subreddit'] = df['subreddit'].map(lambda x: 1 if x == 'ptsd' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare X and y\n",
    "\n",
    "X = df['lower_selftext']\n",
    "y = df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train test split \n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "#                                                     y,\n",
    "#                                                     test_size=0.33,\n",
    "#                                                     stratify=y,\n",
    "#                                                     random_state=42)\n",
    "\n",
    "# pipe = Pipeline([\n",
    "#     ('cvec', CountVectorizer(stop_words = stopwordlist)),\n",
    "#     ('lr', LogisticRegression())\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self,articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]\n",
    "\n",
    "# Train test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(\n",
    "        stop_words = stopwordlist,\n",
    "        tokenizer=LemmaTokenizer(),\n",
    "        )\n",
    "    ),\n",
    "    ('lr', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('cvec',\n",
       "   CountVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
       "                               'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
       "                               \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
       "                               'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
       "                               'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
       "                               'itself', ...],\n",
       "                   tokenizer=<__main__.LemmaTokenizer object at 0x00000219C171CA90>)),\n",
       "  ('lr', LogisticRegression())],\n",
       " 'verbose': False,\n",
       " 'cvec': CountVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
       "                             'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
       "                             \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
       "                             'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
       "                             'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
       "                             'itself', ...],\n",
       "                 tokenizer=<__main__.LemmaTokenizer object at 0x00000219C171CA90>),\n",
       " 'lr': LogisticRegression(),\n",
       " 'cvec__analyzer': 'word',\n",
       " 'cvec__binary': False,\n",
       " 'cvec__decode_error': 'strict',\n",
       " 'cvec__dtype': numpy.int64,\n",
       " 'cvec__encoding': 'utf-8',\n",
       " 'cvec__input': 'content',\n",
       " 'cvec__lowercase': True,\n",
       " 'cvec__max_df': 1.0,\n",
       " 'cvec__max_features': None,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__preprocessor': None,\n",
       " 'cvec__stop_words': ['i',\n",
       "  'me',\n",
       "  'my',\n",
       "  'myself',\n",
       "  'we',\n",
       "  'our',\n",
       "  'ours',\n",
       "  'ourselves',\n",
       "  'you',\n",
       "  \"you're\",\n",
       "  \"you've\",\n",
       "  \"you'll\",\n",
       "  \"you'd\",\n",
       "  'your',\n",
       "  'yours',\n",
       "  'yourself',\n",
       "  'yourselves',\n",
       "  'he',\n",
       "  'him',\n",
       "  'his',\n",
       "  'himself',\n",
       "  'she',\n",
       "  \"she's\",\n",
       "  'her',\n",
       "  'hers',\n",
       "  'herself',\n",
       "  'it',\n",
       "  \"it's\",\n",
       "  'its',\n",
       "  'itself',\n",
       "  'they',\n",
       "  'them',\n",
       "  'their',\n",
       "  'theirs',\n",
       "  'themselves',\n",
       "  'what',\n",
       "  'which',\n",
       "  'who',\n",
       "  'whom',\n",
       "  'this',\n",
       "  'that',\n",
       "  \"that'll\",\n",
       "  'these',\n",
       "  'those',\n",
       "  'am',\n",
       "  'is',\n",
       "  'are',\n",
       "  'was',\n",
       "  'were',\n",
       "  'be',\n",
       "  'been',\n",
       "  'being',\n",
       "  'have',\n",
       "  'has',\n",
       "  'had',\n",
       "  'having',\n",
       "  'do',\n",
       "  'does',\n",
       "  'did',\n",
       "  'doing',\n",
       "  'a',\n",
       "  'an',\n",
       "  'the',\n",
       "  'and',\n",
       "  'but',\n",
       "  'if',\n",
       "  'or',\n",
       "  'because',\n",
       "  'as',\n",
       "  'until',\n",
       "  'while',\n",
       "  'of',\n",
       "  'at',\n",
       "  'by',\n",
       "  'for',\n",
       "  'with',\n",
       "  'about',\n",
       "  'against',\n",
       "  'between',\n",
       "  'into',\n",
       "  'through',\n",
       "  'during',\n",
       "  'before',\n",
       "  'after',\n",
       "  'above',\n",
       "  'below',\n",
       "  'to',\n",
       "  'from',\n",
       "  'up',\n",
       "  'down',\n",
       "  'in',\n",
       "  'out',\n",
       "  'on',\n",
       "  'off',\n",
       "  'over',\n",
       "  'under',\n",
       "  'again',\n",
       "  'further',\n",
       "  'then',\n",
       "  'once',\n",
       "  'here',\n",
       "  'there',\n",
       "  'when',\n",
       "  'where',\n",
       "  'why',\n",
       "  'how',\n",
       "  'all',\n",
       "  'any',\n",
       "  'both',\n",
       "  'each',\n",
       "  'few',\n",
       "  'more',\n",
       "  'most',\n",
       "  'other',\n",
       "  'some',\n",
       "  'such',\n",
       "  'no',\n",
       "  'nor',\n",
       "  'not',\n",
       "  'only',\n",
       "  'own',\n",
       "  'same',\n",
       "  'so',\n",
       "  'than',\n",
       "  'too',\n",
       "  'very',\n",
       "  's',\n",
       "  't',\n",
       "  'can',\n",
       "  'will',\n",
       "  'just',\n",
       "  'don',\n",
       "  \"don't\",\n",
       "  'should',\n",
       "  \"should've\",\n",
       "  'now',\n",
       "  'd',\n",
       "  'll',\n",
       "  'm',\n",
       "  'o',\n",
       "  're',\n",
       "  've',\n",
       "  'y',\n",
       "  'ain',\n",
       "  'aren',\n",
       "  \"aren't\",\n",
       "  'couldn',\n",
       "  \"couldn't\",\n",
       "  'didn',\n",
       "  \"didn't\",\n",
       "  'doesn',\n",
       "  \"doesn't\",\n",
       "  'hadn',\n",
       "  \"hadn't\",\n",
       "  'hasn',\n",
       "  \"hasn't\",\n",
       "  'haven',\n",
       "  \"haven't\",\n",
       "  'isn',\n",
       "  \"isn't\",\n",
       "  'ma',\n",
       "  'mightn',\n",
       "  \"mightn't\",\n",
       "  'mustn',\n",
       "  \"mustn't\",\n",
       "  'needn',\n",
       "  \"needn't\",\n",
       "  'shan',\n",
       "  \"shan't\",\n",
       "  'shouldn',\n",
       "  \"shouldn't\",\n",
       "  'wasn',\n",
       "  \"wasn't\",\n",
       "  'weren',\n",
       "  \"weren't\",\n",
       "  'won',\n",
       "  \"won't\",\n",
       "  'wouldn',\n",
       "  \"wouldn't\",\n",
       "  'ptsd',\n",
       "  'anxiety',\n",
       "  'trauma',\n",
       "  'posttraumatic',\n",
       "  'stress',\n",
       "  'disorder',\n",
       "  'traumatic',\n",
       "  \"'d\",\n",
       "  \"'ll\",\n",
       "  \"'re\",\n",
       "  \"'s\",\n",
       "  \"'ve\",\n",
       "  'could',\n",
       "  'doe',\n",
       "  'ha',\n",
       "  'might',\n",
       "  'must',\n",
       "  \"n't\",\n",
       "  'need',\n",
       "  'sha',\n",
       "  'wa',\n",
       "  'wo',\n",
       "  'would'],\n",
       " 'cvec__strip_accents': None,\n",
       " 'cvec__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'cvec__tokenizer': <__main__.LemmaTokenizer at 0x219c171ca90>,\n",
       " 'cvec__vocabulary': None,\n",
       " 'lr__C': 1.0,\n",
       " 'lr__class_weight': None,\n",
       " 'lr__dual': False,\n",
       " 'lr__fit_intercept': True,\n",
       " 'lr__intercept_scaling': 1,\n",
       " 'lr__l1_ratio': None,\n",
       " 'lr__max_iter': 100,\n",
       " 'lr__multi_class': 'auto',\n",
       " 'lr__n_jobs': None,\n",
       " 'lr__penalty': 'l2',\n",
       " 'lr__random_state': None,\n",
       " 'lr__solver': 'lbfgs',\n",
       " 'lr__tol': 0.0001,\n",
       " 'lr__verbose': 0,\n",
       " 'lr__warm_start': False}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec',\n",
       "                                        CountVectorizer(stop_words=['i', 'me',\n",
       "                                                                    'my',\n",
       "                                                                    'myself',\n",
       "                                                                    'we', 'our',\n",
       "                                                                    'ours',\n",
       "                                                                    'ourselves',\n",
       "                                                                    'you',\n",
       "                                                                    \"you're\",\n",
       "                                                                    \"you've\",\n",
       "                                                                    \"you'll\",\n",
       "                                                                    \"you'd\",\n",
       "                                                                    'your',\n",
       "                                                                    'yours',\n",
       "                                                                    'yourself',\n",
       "                                                                    'yourselves',\n",
       "                                                                    'he', 'him',\n",
       "                                                                    'his',\n",
       "                                                                    'himself',\n",
       "                                                                    'she',\n",
       "                                                                    \"she's\",\n",
       "                                                                    'her',\n",
       "                                                                    'hers',\n",
       "                                                                    'herself',\n",
       "                                                                    'it',\n",
       "                                                                    \"it's\",\n",
       "                                                                    'its',\n",
       "                                                                    'itself', ...],\n",
       "                                                        tokenizer=<__main__.LemmaTokenizer object at 0x00000219C171CA90>)),\n",
       "                                       ('lr', LogisticRegression())]),\n",
       "             param_grid={'cvec__max_df': [0.6], 'cvec__max_features': [1000],\n",
       "                         'cvec__min_df': [0.002],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'lr__max_iter': [1000]})"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_params = {\n",
    "    'cvec__max_features': [1_000],\n",
    "    'cvec__min_df': [.002],\n",
    "    'cvec__max_df': [.6],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)],\n",
    "    'lr__max_iter': [1000]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, # what object are we optimizing?\n",
    "                  param_grid=pipe_params, # what parameters values are we searching?\n",
    "                  cv=5) # 5-fold cross-validation\n",
    "\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7950586829067781\n"
     ]
    }
   ],
   "source": [
    "# What's the best score?\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8081473779287368"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('cvec',\n",
      "                 CountVectorizer(max_df=0.6, max_features=1000, min_df=0.002,\n",
      "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
      "                                             'our', 'ours', 'ourselves', 'you',\n",
      "                                             \"you're\", \"you've\", \"you'll\",\n",
      "                                             \"you'd\", 'your', 'yours',\n",
      "                                             'yourself', 'yourselves', 'he',\n",
      "                                             'him', 'his', 'himself', 'she',\n",
      "                                             \"she's\", 'her', 'hers', 'herself',\n",
      "                                             'it', \"it's\", 'its', 'itself', ...],\n",
      "                                 tokenizer=<__main__.LemmaTokenizer object at 0x00000219C716F880>)),\n",
      "                ('lr', LogisticRegression(max_iter=1000))])\n"
     ]
    }
   ],
   "source": [
    "# What's the best score?\n",
    "print(gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8452827413780425\n"
     ]
    }
   ],
   "source": [
    "# Score model on training set.\n",
    "print(gs.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8107180176145693\n"
     ]
    }
   ],
   "source": [
    "# Score model on testing set.\n",
    "print(gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "preds = gs.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEGCAYAAACQO2mwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAkLUlEQVR4nO3debxVVf3/8df7XgZRQFCECFAw0cQhEBxJQxsks9S0hPylld9QH44N3xxL0yyt1L5qzpmaEw6ZZJrzRI6ACIKiJKMigjmgIQh8fn/sBRyv5xzOhbvvcO776WM/7t5rr7332tzr+Zy11t5rKSIwMzMrpqapC2BmZs2Xg4SZmZXkIGFmZiU5SJiZWUkOEmZmVlKbpi6A1Z/adAi169TUxbB6GLT1pk1dBKuHWbNmsnDhQq3LOWo7bxaxbHFFeWPxgnsjYvi6XC8vDhItkNp1ov1W327qYlg9/Ovpi5u6CFYPQ3cess7niGWLK/7/9MOJf+y2zhfMiYOEmVkuBGr5LfoOEmZmeRBQU9vUpVhnDhJmZnnROnVrNAsOEmZmuXBzk5mZleOahJmZFSVckzAzs1LkmoSZmZXhp5vMzKw4d1ybmVkpws1NZmZWhmsSZmZWnJubzMysFAG17rg2M7NS3CdhZmbFubnJzMzKcU3CzMxKck3CzMyKkoflMDOzcjwsh5mZFeeOazMzK8fNTWZmVpTnkzAzs9Lc3GRmZuW449rMzEpyn4SZmRUlNzeZmVk5VVCTaPlhzsysmZJU0VLBefpIeljSi5KmSDo+pZ8h6TVJE9OyT8ExJ0uaLmmapL0L0gdLmpz2Xag1FMA1CTOzHGSzlzZYTWIZ8JOImCCpEzBe0v1p3wUR8fuPXVsaAIwAtgE+DTwgacuIWA5cCowCngLuBoYD95S6sGsSZmZ5kFBNZcuaRMS8iJiQ1hcBLwK9yhyyH3BzRCyJiBnAdGAnST2BzhHxZEQEcB2wf7lrO0iYmeWkHs1N3SSNK1hGlTlnX2AQ8HRKOkbSJElXS+qa0noBcwoOm5vSeqX1uuklOUiYmeWkHkFiYUQMKViuKHG+jsDtwAkR8R5Z09FngIHAPOC8lVmLHB5l0ktyn4SZWU4asE8CSW3JAsQNEfFXgIiYX7D/SuCutDkX6FNweG/g9ZTeu0h6Sa5JmJnlQfVY1nSqLNr8CXgxIs4vSO9ZkO0A4IW0PgYYIam9pH5Af+CZiJgHLJK0SzrnocCd5a7tmoSZWQ5EZY+3Vmgo8F1gsqSJKe0UYKSkgWRNRjOBIwAiYoqkW4CpZE9GHZ2ebAI4CrgG6ED2VFPJJ5vAQcLMLDc1NQ3TWBMRYyle57i7zDFnA2cXSR8HbFvptR0kzMxy0pB9Ek3FQcLMLA8V9jc0dw4SZmY5cU3CzMyKauCO6ybjIGFmlpNKhtxo7hwkzMzyIDc3mZlZGQ4SZmZWkoOEmZkV5Y5rMzMrr+XHCAcJM7NcqOGG5WhKDhJmZjlxc5OZmZXW8mOEg4Tlp1ePLlx6xqF037gzKyK49o5/cfnNj7Dtlr04/6QRrNe+LcuWreCn545mwtRZq47r3aMrT95yGudeeTcXX/8gHdq35ZpzDqdv724sXxHc+/hkfnnxmCa8s9Zl+fIV7Hnob+nZfUNGX3AUk1+ey0/OuZn3/7uETXtuzBVnHUbnjh2Y/fpb7PztX7HFpt0BGLJdXy44eWQTl75puSZRhqQewAXALsDbwFLgtxFxR17XXEN5vgcMiYhjSuy/E+geEbuuwzWGAIdGxHFl8gwEPh0RJYf4rRbLlq3gtD/8lUnT5tJx/fY8fN2JPPL0S/zy2P357VX38MATU/nybgP45XH78/Uj/2/VcWf/+EAeeGLKx8510fUPMnb8K7RtU8udlxzLl3YbwANPTG3sW2qVLrv5Ybbs14NFH3wIwPG/upGzjj+AoYP7c/2YJ7noLw9y6lH7AtC3Vzcev/Hkpixus1EwNWmLlkuvSprx6G/AYxGxeUQMBkbw8Wnz8rjuWgU9SV2AHYAuaRantRIR48oFiGQgsM/aXqMlmf/We0yals25/v5/l/DyzDfouUkXIqDTBusB0LljB95Y8O6qY/b5wvbMem0hL736xqq0xUs+Yuz4VwD4aNlynp82h09379J4N9KKvTb/be4bO4VD99ttVdr02W+y2w5bADBsp8/y94cnNlHpmr96zHHdbOXV9b4XsDQiLluZEBGzIuIiAEm1kn4n6VlJkyQdkdKHSXpE0m2SXpJ0Qwo4SBos6VFJ4yXdu3LavpT/15IeBY6X9HVJT0t6TtIDqUazJgcCfwduJgtmpHNfI+lCSU9IelXSQSn9gHRuSeop6WVJn0rlvyvl2UDS1eken5O0n6R2wJnAwZImSjpY0iuSNknH1EiaLqnbuv4Cmps+PTdi+616M37KTE45/zbOPG5/XrjrLM48/gDO/GM2e+L667Xj+EO/zLlXlq5kde7YgeG7b8ejz05rrKK3aqecfzu/PG5/agrGIPrs5j2557HJANz54ARem//2qn2zX3+LPQ45h6+N+gNPPDe90cvb3KhGFS3NWV5BYhtgQpn9hwPvRsSOwI7ADwu+wQ8CTgAGAJsDQ9ME4BcBB6VaydV8fMalLhHxhYg4DxgL7BIRg8g+9H9WQXlHAjelpW4jak/g88C+wDkAqcnsDeBo4Erg9Ih4o85xpwIPpXvcE/gd0Bb4BTA6IgZGxGjgeuCQdMyXgOcjYmHdAkoaJWmcpHGxbHEFt9R8bNChHded+z+cfP7tLPrgQ35w4O6ccv5f2Xbfn3PqBbdz4c+z2z/piK9x6U0P8cHipUXPU1tbw5/O/h6Xj36EWa+91Zi30Cr98/HJdOvaiYFbb/qx9It/cQhX3foYw757Lu//dwlt29YC0KNbZyb//Uweu+Ekzv7RN/nhadfw3vst62+1oVVDTaJROq4l/ZHsg3Zp+tD8CrD9ym/mwIZkE3UvJZuse246biLQF3iHbLq9+9M/aC0wr+ASowvWewOjU02jHTBjDWXrAWwBjI2IkLRM0rYRsXJC8b9FxApgap1aybFkk44/FRE3FTn1V4BvSPpp2l4P2LRIvqvJJiL/A/AD4M/FyhkRVwBXANSs3z3K3VNz0qa2hmvP/SG3/nMcdz38PAAj992Zk867DYC/PfAc/3fqdwAYss1m7LfXQH557P5s2KkDK1YES5Z8xJW3PgbAH04Zyb9nL+Cymx5pkntpbZ5+/lX++fhk7n9iCkuWfMSiDz5k1M+v5YqzDuOvF2dde9Nnzee+sVn/Uft2bWnfri0AA7felH69u/Hv2W8yaMBmTXYPTcoD/JU1hawJB4CIODo1oYxLSQKOjYh7Cw+SNAxYUpC0PJVRwJQyncofFKxfBJwfEWPS+c5YQ1kPBroCM9IvtDNZk9NpaX9heQp/472AFUAPSTUpkFAn74ER8bF2EUk7F25HxBxJ8yXtBezM6lpFVbjo54fw8sw3uOTGh1alzVvwLkN36M+/JrzCHjtuyatzFgCwz6g/rMpz4g/34YPFS1YFiFOP3JfOHTtw3K9ubNTyt2anH7Mfpx+zHwBjx7/MRdc/yBVnHcaC/yxik406sWLFCn5/9b18/8DPA7Dw7UV07bwBtbU1zJy7kFfnLKBvr6prOa2YgCqIEbkFiYeAX0s6KiIuTWnrF+y/FzhK0kMR8ZGkLYHXypxvGrCJpF0j4snU/LRlREwpknfDgnMdVkFZRwLDI+JJgNTsdT+rg8QnpA7yPwPfAQ4Ffgz8vk62e4FjJR2baiiDIuI5YBHQqU7eq8ianf4SEcsrKHOLsMvnNmfE13Zmyiuv8dgNJwFw1h/HcMLZN/KbnxxEm9oaPly6jBN+Xawittqnu3fhp4cPZ9qMN3j0+hMBuPKWR/nLnU/mfg/2SbffO46rbsuC977DBnLI13cB4InnpvOby/5BbZtaamvEeSeNoOuGGzRlUZtY829KqkQuQSJ9KO4PXCDpZ8ACsm/7J6YsV5E1I01IHdMLgP3LnG9papq6UNKGqdx/IKux1HUGcKuk14CngJJPK0nqS9YE9FTBtWZIeq/uN/46TgEej4jHU5PYs5L+USfPWamMk9I9ziTr13gYOCkd95vULzGGLOgUbWpqqZ56/lW67lj0iWP2PPS3ZY8t7Lx+/c13Sp7HGsfnB2/J5wdvCcCRI/fkyJF7fiLPN/YaxDf2GtTYRWvWapp5p3QlFNFimrerlrL3Ky6IiN0ryV+zfvdov9W3cy6VNaS3n724qYtg9TB05yGMHz9unT7h1+u5ZfQ97KKK8k47d/j4iBiyLtfLi9+4bmKSTgKOosr6IsxaO1EdNYmWP0RhCxcR50TEZhExtqnLYmYNS6psac5ckzAzy4k7rs3MrLgWUEuohIOEmVkOhDzpkJmZleaahJmZleQ+CTMzK859EmZmVko2dlPLjxIOEmZmOamCGOEgYWaWl2p449pBwswsD55PwszMSvF8EmZmVkZ1zCfR8l8HNDNrphpqgD9JfSQ9LOlFSVMkHZ/SN5J0v6RX0s+uBcecLGm6pGmS9i5IHyxpctp3odYQyRwkzMzyoKzjupKlAsuAn0TE1sAuwNGSBgAnAQ9GRH/gwbRN2jcC2AYYDlwiqTad61JgFNA/LcPLXdhBwswsByvfk6hkWZOImBcRE9L6IuBFoBewH3BtynYtq2f43A+4OSKWRMQMYDqwk6SeQOeIeDKyGeeuo8ysoOA+CTOz3NSjT6KbpHEF21dExBUlztkXGAQ8DfSIiHmQBRJJ3VO2XhRMywzMTWkfpfW66SU5SJiZ5aQe/dYLK5m+VFJH4HbghIh4r0wQKrYjyqSX5OYmM7OcNFRzUzpXW7IAcUNE/DUlz09NSKSfb6b0uUCfgsN7A6+n9N5F0ktykDAzy0OFTzZV+HSTgD8BL0bE+QW7xgCHpfXDgDsL0kdIai+pH1kH9TOpaWqRpF3SOQ8tOKYoNzeZmeUgm3Sowd6TGAp8F5gsaWJKOwU4B7hF0uHAbOBbABExRdItwFSyJ6OOjojl6bijgGuADsA9aSnJQcLMLCc1DfQyXUSMpXh/AsAXSxxzNnB2kfRxwLaVXttBwswsJ1XwwrWDhJlZHuQB/szMrJwqGCncQcLMLC+eT8LMzIoS2RNOLZ2DhJlZTqqgIuEgYWaWi3q8Td2cOUiYmeWkCmKEg4SZWR5Ew71M15QcJMzMcuKnm8zMrKhKB+9r7hwkzMxy4uYmMzMrqeWHCAcJM7Pc+BFYMzMrKnu6qalLse4cJMzM8qAGnXSoyaxx+lJl/p+kX6TtTSXtlH/RzMxatoac47qpVDLH9SXArsDItL0I+GNuJTIzqwIrm5sqWZqzSpqbdo6IHSQ9BxARb0tql3O5zMxavOZeS6hEJUHiI0m1QABI2gRYkWupzMyqQMsPEZUFiQuBO4Duks4GDgJOy7VUZmYtnAS1zb0tqQJrDBIRcYOk8cAXyQLj/hHxYu4lMzNr4VpFc5OkTYH/An8vTIuI2XkWzMyspauCGFFRc9M/yPojBKwH9AOmAdvkWC4zsxZNqHWM3RQR2xVuS9oBOCK3EpmZVYPWOgpsREyQtGMehbHKbLtlH8bc//umLobVQ9f9/WpRS7Lk3282yHlaS5/Ejws2a4AdgAW5lcjMrAoIqG0NQQLoVLC+jKyP4vZ8imNmVj2q4AnY8kEivUTXMSL+t5HKY2ZWNao6SEhqExHLUke1mZnVQzZ9acuPEuVqEs+Q9T9MlDQGuBX4YOXOiPhrzmUzM2vRqromUWAj4C1gL1a/LxGAg4SZWRlVUJEoGyS6pyebXmB1cFgpci2VmVkLJ6BNFUSJckGiFuhI8YEMHSTMzNagCmJE2SAxLyLObLSSmJlVEan6h+Vo+XdnZtaEqiBGlA0SX2y0UpiZVaGqfropIv7TmAUxM6smojomHapp6gKYmVUlZTWJSpY1nkq6WtKbkl4oSDtD0muSJqZln4J9J0uaLmmapL0L0gdLmpz2XagK3vZzkDAzy4kq/K8C1wDDi6RfEBED03I3gKQBwAiyOX+GA5ekIZYALgVGAf3TUuycH+MgYWaWA9FwNYmIeAyotAtgP+DmiFgSETOA6cBOknoCnSPiyYgI4Dpg/zWdzEHCzCwn9QgS3SSNK1hGVXiJYyRNSs1RXVNaL2BOQZ65Ka1XWq+bXla9Jx0yM7PK1GOAv4URMaSep78UOIvs5eazgPOAH1D6Bei1ejHaQcLMLAcS1ObYVhMR81dfS1cCd6XNuUCfgqy9gddTeu8i6WW5ucnMLCc16a3rNS1rI/UxrHQA2Th7AGOAEZLaS+pH1kH9TETMAxZJ2iU91XQocOearuOahJlZDlZ2XDfIuaSbgGFkfRdzgdOBYZIGkjUZzQSOAIiIKZJuAaaSzSZ6dEQsT6c6iuxJqQ7APWkpy0HCzCwnDTUsR0SMLJL8pzL5zwbOLpI+Dti2Ptd2kDAzy4WoqYIh8BwkzMxyIKp/gD8zM1tbgjZVMHaTg4SZWQ5ckzAzs7KqfdIhMzNbB1UQIxwkzMzyIKrjbWUHCTOzPMjNTWZmVkL2xrWDhJmZldDyQ4SDhJlZbqqgIuEgYWaWD9VnPolmy0HCzCwHfrrJzMzKcse1mZkVp3pNX9psOUiYmeXAzU1mZlaWaxJmZlZSyw8RDhJmZrkQUOuahJmZlVIFMcJBwswsH0JV0ODkIGFmlhPXJMzMrKjsEdiWHyUcJMzM8iDXJMzMrAwPy2FmZkVlkw41dSnWnYOEmVlO/HSTmZmVVAWtTQ4S1jhmzHmTH//q+lXbc954i2MP25uJU2cxc84CAN77YDGdN+jAHZf/mEkvzeb0C24DIAiO/u5X+PLnt2uSsrcmvbp15NLjv0j3LuuzIuDa+6Zw+V2TOHHEjhz65QG89d6HAJx1/VPcP34WbWpruPDoPfncZzahtkaMfmQaF9w+AYADhm7BT741mJqaGu4fP5PTr32yKW+tSbgm0UpJWg5MJvv3exE4AfhH2v0pYDmwIG3vBPwv8J2UvgI4IiKelvQI0BNYArQDHgBOi4h3GuM+GlO/Pt254/IfA7B8+QqGjTyLLw3dlsO+uceqPOdeNoaOG6wHQP++n+LWS46nTW0tb771HgcceR577jqANrW1TVL+1mLZ8hWc9ud/MenVhXRcry0Pn/dtHpk4B4BLxzzPxXdO/Fj+/Yd+hvZtaxl6/M10aNeGpy4eyW2Pv8L7i5dy5vd2Y9hPbuGt9z7kkuO+yB7b9+axSXOb4K6aRrX0SVTDSLZNYXFEDIyIbYGlwMFpeyBwGXBBwfZgYF9gh4jYHvgSMKfgXIek9O3JgsWdjXgfTeKp516hT8+N6dVjo1VpEcE/H3uer+05CIAO67VbFRCWLv2oKr6RtQTz3/4vk15dCMD7H37Ey3PfpufGG5TMHwHrr9eG2hqxXvtaln60gkX/XUrfHhsy/fV3VtU8Hp00h2/sunmj3EOzIVFT4dKcuSax7h4n+4AvpSewMCKWAETEwmKZImKppJ8B0yV9LiKeb/iiNg93PzKRr+058GNp4ya/ysZdOtG39yar0p5/cRannncL8+a/zTknjnQtopH16d6J7TfvxviX57Pz1j354de2Y8SeW/Hc9AWc9ud/8e4HS7jziX+zz079eOnP36dD+zacevVY3nl/Ca/Oe5f+vbrSp3snXl/4PvvsvDnt2rS+76TN++O/Mq3vt9aAJLUBvkrW9FTKfUAfSS9LukTSF0pljIjlwPPAZ4tca5SkcZLGvfXWgk8e3EIs/WgZDz05hb2/8LmPpf/j4U8Gjs9tvRl3XfW/3HLx8Vx580MsWfpRI5a0ddtgvbZcd+JwTv7TWBYt/oir73mBQUdez+4/Gs38tz/gV98fCsDg/t1ZviLY+gfXMPCIv3D0fgPZrEdn3v1gCT+9/FGu/une3P3rbzL7zUUsWx5NfFeNK2tuavk1CQeJtdNB0kRgHDAb+FOpjBHxPlmT0yiyforRkr5X5txF/2Ii4oqIGBIRQzbeeJNiWVqEx599iQFb9KZb106r0pYtX84DYyfz1WEDix7zmc160GG9drwy441GKmXr1qa2hmtPHM6tj77MXU+9CsCCdxezYkUQAdfeP5XB/bsDcNAeW/Lgc7NYtnwFC99dzNMvvsGgLbJ9/3x2Jl/+2W3sfdLtTH/tbV6d905T3VKTUYVLc+YgsXZW9kkMjIhjI2JpucwRsTwiHomI04FjgAOL5ZNUC2xH1hlelYrVGJ6c8Ar9+nTnU5t0WZU2d95bLFu+HIDX5v+HGXMW0OtTG2H5u+iYPXl57ttcMmZ1i2ePruuvWt935815cfZ/AJi7YBG7b9cbgPXbt2HIVj14Ze7bAHTbsAMAG27QnsO/uh3X3T+1sW6h+aiCKOE+iZxJ2gpYERGvpKSBwKwi+doCZwNzImJS45Ww8Sz+cClPjH+ZX57w8Rh5d5HAMf6FmVw5+iHa1taiGvGL475J1w1Ld6Baw9hl656M2POzTJm5kMcuOBjIHnc9cPf+bNevGxHB7DcX8aNLHwHgqnte4OJj9+KJC0ciwY0PvsSUWW8BcM7hn2ebft0A+N3oZ/n36+82yT01pebelFQJRbSudsKGIOn9iOhYYt8ZwPsR8fu0PRi4COgCLAOmA6MiYmGdR2Dbkz0Ce+qaHoHdfuDgGPPAvxrkXqxxbP29ki2S1gwtGXsuK96ZvU6f8FtvNyiuu/ORivLu9Jku4yNiyLpcLy+uSayFUgEi7TujzvZ4YLcSeYc1aMHMrHlpoIqEpKvJHqV/Mz16j6SNgNFAX2Am8O2IeDvtOxk4nOzdrOMi4t6UPhi4BugA3A0cH2uoKbhPwswsB1l3Q2X/VeAaYHidtJOAByOiP/Bg2kbSAGAEsE065pLU3wlwKdlDNP3TUvecn+AgYWaWhzSfRCXLmkTEY8B/6iTvB1yb1q8F9i9IvzkilkTEDLIm7p0k9QQ6R8STqfZwXcExJbm5ycwsJ/VobeomaVzB9hURccUajukREfMAImKepO4pvRfwVEG+uSnto7ReN70sBwkzs1wIVf5008IG7LgudtEok16Wm5vMzHLSUM1NJcxPTUikn2+m9LlAn4J8vYHXU3rvIullOUiYmeWg0vfo1uEBqDHAYWn9MFYPDjoGGCGpvaR+ZB3Uz6SmqUWSdlFWxTmUCgYUdXOTmVleGu4R2JuAYWR9F3OB04FzgFskHU42PNC3ACJiiqRbgKlk72YdncaFAziK1Y/A3pOWshwkzMxy0lBD3EfEyBK7vlgi/9lkIzjUTR8HbFufaztImJnlpApG5XCQMDPLxbp1SjcbDhJmZjmphhkVHSTMzHIgXJMwM7MyqiBGOEiYmeWmCqKEg4SZWU6qYdIhBwkzs5y0/BDhIGFmlp8qiBIOEmZmOVg56VBL5yBhZpYHv0xnZmblVEGMcJAwM8tHvSYdarYcJMzMclIFMcJBwswsD+s4oVCz4SBhZpaXKogSDhJmZjnxI7BmZlaS+yTMzKw4QY2DhJmZldbyo4SDhJlZDjzpkJmZlVUFMcJBwswsL65JmJlZSR6Ww8zMSmr5IcJBwswsF/JQ4WZmVo7fuDYzs9JafoxwkDAzy0sVxAgHCTOzfIiaKuiUcJAwM8tBtbxxXdPUBTAzs+bLNQkzs5xUQ03CQcLMLCd+BNbMzIrzy3RmZlZKtXRcO0iYmeWkGpqb/HSTmVlOVo7ftKalsnNppqTJkiZKGpfSNpJ0v6RX0s+uBflPljRd0jRJe6/tPThImJnlRBUu9bBnRAyMiCFp+yTgwYjoDzyYtpE0ABgBbAMMBy6RVLs29+AgYWaWlxyiRB37Adem9WuB/QvSb46IJRExA5gO7LQ2F3CQMDPLgYAaqaIF6CZpXMEyqsgpA7hP0viC/T0iYh5A+tk9pfcC5hQcOzel1Zs7rlugyc9PWNhvkw6zmrocOegGLGzqQli9VOvvbLN1PcGECePv7dBW3SrMvjAihq8hz9CIeF1Sd+B+SS+VyVusfhIVluVjHCRaoIjYpKnLkAdJ4wraWq0F8O+stAo+9Ot7vtfTzzcl3UHWfDRfUs+ImCepJ/Bmyj4X6FNweG/g9bW5rpubzMyaOUkbSOq0ch34CvACMAY4LGU7DLgzrY8BRkhqL6kf0B94Zm2u7ZqEmVnz1wO4Q1n/RRvgxoj4p6RngVskHQ7MBr4FEBFTJN0CTAWWAUdHxPK1ubAi1qqZyqzBSRoVEVc0dTmscv6dVT8HCTMzK8l9EmZmVpKDhJmZleQg0cpI6iHpRkmvppdynpR0QBOW53uSLi6z/05JT67jNYZIunANeQZK2mddrlMNJC1PYwO9IOlWSb3S9kRJb0h6rWC7naRTJU2RNCml7ZzO80gaM2iSpJckXSypSxPfnq0FB4lWRNmjEX8DHouIzSNiMNn4Lr1zvu5aPUWXPlR2ALqkx/jWSkSMi4jj1pBtINDqgwSwOI0NtC2wFDg4bQ8ELgMuKNgeDOwL7BAR2wNf4uNv+R6S0rcHlrD68UxrQRwkWpe9gKURcdnKhIiYFREXAUiqlfQ7Sc+mb4BHpPRh6Zvhbelb4Q0p4CBpsKRHU63k3vRCz8pvkr+W9ChwvKSvS3pa0nOSHpDUo4LyHgj8HbiZLJiRzn2NpAslPZFqRAel9APSuSWpp6SXJX0qlf+ulGcDSVene3xO0n6S2gFnAgenb8MHp1E1N0nH1KTRNCt9e7ZaPA5sUWZ/T7I3hZcARMTClS98FYqIpcDPgE0lfS6XklpuHCRal22ACWX2Hw68GxE7AjsCPyz4Bj8IOAEYAGwODJXUFrgIOCjVSq4Gzi44X5eI+EJEnAeMBXaJiEFkH/o/q6C8I4Gb0jKyzr6ewOfJvsmeAxARdwBvAEcDVwKnR8QbdY47FXgo3eOewO+AtsAvgNHpW/Jo4HrgkHTMl4DnI6Iah58oKtX+vgpMLpPtPqBPCsaXSPpCqYzpGf3ngc82bEktb36ZrhWT9EeyD9ql6UPzK8D2K7+ZAxuSvam5FHgmIuam4yYCfYF3gG3JxpEBqAXmFVxidMF6b2B0qmm0A2asoWw9yL7Fjo2IkLRM0rYR8ULK8reIWAFMrVMrOZbsTdSnIuKmIqf+CvANST9N2+sBmxbJdzVZ88gfgB8Afy5X3irSIf1+IatJ/KlUxoh4X9JgYHeygDta0kkRcU2JQ1r+DDytkINE6zKFrAkHgIg4OjWhjEtJAo6NiHsLD5I0jKxNeaXlZH87AqZExK4lrvdBwfpFwPkRMSad74w1lPVgoCswIwWgzmRNTqel/YXlKfzw6QWsAHpIqkmBhDp5D4yIaR9LTB2uK0XEHEnzJe0F7MzqWkW1W5z6GyqSagiPAI9Imkw2NMQ1dfMpm8tgO+DFBimlNRo3N7UuDwHrSTqqIG39gvV7gaNSMxKStlQ2Tkwp04BNJO2a8reVtE2JvBsCr6X1w0rkKTQSGB4RfSOiL1kn6YhyB6Qmkj8D3yH7MPpxkWz3AscW9KkMSumLgE518l5F1ux0y9oOaVDNJG0lqX9B0kDgE6MTp7+n3wBzImJSIxXPGoiDRCsS2ev1+wNfkDRD0jNkE5WcmLJcRTbWywRJLwCXU6a2mTokDwLOlfQ8MBHYrUT2M4BbJT3OGoaWltSXrAnoqYJrzQDeq/uNv45TgMcj4nGyAPE/krauk+cssj6ISekez0rpDwMDVnZcp7QxQEdaT1NTfXUErpU0VdIksv6qMwr235DSXwA2IJsIx1oYD8thVoKkIWSPfO7e1GUxayrukzArQtJJwFG0nr4Is6JckzAzs5LcJ2FmZiU5SJiZWUkOEmZmVpKDhFmiT46Auv6ajyp5rmsKxpS6StKAMnmHSSr16HC5a8xsheNJWSNzkDBbre4IqEcW7kxvDddbRPxPREwtk2UYpd8vMWtSDhJmxT0ObJG+5T8s6UZgskqPlCtlcyZMlfQPoPvKE6URcYek9eGSJkh6XtKD6cXBI4EfpVrM7pI2kXR7usazkoamYzeWdF8avfZyPBaSNQK/J2FWR8EIqP9MSTsB20bEDEmjSCPlSmoP/EvSfWSj5G5FNj5RD7I316+uc95NyEan3SOda6OI+I+ky4D3I+L3Kd+NZC/xjZW0KdlQIlsDp5MNeHimpK8Bo3L9hzDDQcKsULERUHcjGwF35ai1pUbK3QO4KY3x9Lqkh4qcfxeyCZ9mAETEf0qU40tkQ4Ss3O4sqVO6xjfTsf+Q9Pba3aZZ5RwkzFb7xAio6YO6cDTbUiPl7gOs6c1UVZAHsmbgXSNicZGy+O1Xa1TukzCrn1Ij5T4GjEh9Fj3J5leo60mywRX7pWM3Sul1R6C9Dzhm5YakgWn1MdIwIZK+SjaUulmuHCTM6qfUSLl3AK+QzeR2KfBo3QMjYgFZP8Jf06i5Kydl+jtwwMqOa+A4YEjqGJ/K6qesfgnsIWkCWbPX7Jzu0WwVj91kZmYluSZhZmYlOUiYmVlJDhJmZlaSg4SZmZXkIGFmZiU5SJiZWUkOEmZmVtL/B1BzfmioL7/zAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View confusion matrix\n",
    "cmd = plot_confusion_matrix(gs, X_test, y_test, cmap='Blues', values_format='d', display_labels=['General Anxiety','PTSD'])\n",
    "cmd.ax_.set(xlabel='Predicted', ylabel='True');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "lm = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abus\n"
     ]
    }
   ],
   "source": [
    "print(lm.stem(\"abuser\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>flashback</td>\n",
       "      <td>3.631591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>abuser</td>\n",
       "      <td>2.967701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>cptsd</td>\n",
       "      <td>2.909472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>raped</td>\n",
       "      <td>2.853578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>rape</td>\n",
       "      <td>2.831153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>abused</td>\n",
       "      <td>2.160463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>emdr</td>\n",
       "      <td>1.879793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>nightmare</td>\n",
       "      <td>1.847781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>assault</td>\n",
       "      <td>1.703019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>assaulted</td>\n",
       "      <td>1.672336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>triggered</td>\n",
       "      <td>1.466334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>triggering</td>\n",
       "      <td>1.436932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>diagnosis</td>\n",
       "      <td>1.315779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>healing</td>\n",
       "      <td>1.309245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>abuse</td>\n",
       "      <td>1.304287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>memory</td>\n",
       "      <td>1.082435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>emotional</td>\n",
       "      <td>1.028798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>incident</td>\n",
       "      <td>0.989436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>diagnosed</td>\n",
       "      <td>0.985573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>event</td>\n",
       "      <td>0.956954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Features  Coefficients\n",
       "322   flashback      3.631591\n",
       "22       abuser      2.967701\n",
       "190       cptsd      2.909472\n",
       "686       raped      2.853578\n",
       "685        rape      2.831153\n",
       "21       abused      2.160463\n",
       "259        emdr      1.879793\n",
       "589   nightmare      1.847781\n",
       "80      assault      1.703019\n",
       "81    assaulted      1.672336\n",
       "896   triggered      1.466334\n",
       "897  triggering      1.436932\n",
       "224   diagnosis      1.315779\n",
       "396     healing      1.309245\n",
       "20        abuse      1.304287\n",
       "541      memory      1.082435\n",
       "261   emotional      1.028798\n",
       "441    incident      0.989436\n",
       "223   diagnosed      0.985573\n",
       "275       event      0.956954"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to create dataframe of highest coefficients \n",
    "\n",
    "df_include_stopwords = pd.DataFrame([[x,y] for x,y in zip(gs.best_estimator_[0].get_feature_names(), gs.best_estimator_[1].coef_.tolist()[0])])\n",
    "df_include_stopwords.rename(columns= {0: 'Features', 1: 'Coefficients'}, inplace = True)\n",
    "df_include_stopwords.sort_values(by = 'Coefficients', ascending = False).head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-154-4478c0c4673d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m                   cv=5) # 5-fold cross-validation\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    339\u001b[0m         \"\"\"\n\u001b[0;32m    340\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[0;32m    343\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    301\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m             \u001b[1;31m# Fit or load from cache the current transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[0;32m    304\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Pipeline'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1203\u001b[1;33m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[0;32m   1204\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1115\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1116\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1117\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mngrams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m                 \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mngrams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m                 \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mngrams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_word_ngrams\u001b[1;34m(self, tokens, stop_words)\u001b[0m\n\u001b[0;32m    247\u001b[0m                            min(max_n + 1, n_original_tokens + 1)):\n\u001b[0;32m    248\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_original_tokens\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m                     \u001b[0mtokens_append\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspace_join\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_tokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = df['lower_selftext']\n",
    "y = df['subreddit']\n",
    "\n",
    "#  Train test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words = stopwordlist)),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [1_000, 2_000],\n",
    "    'cvec__min_df': [0.001, .002, .005],\n",
    "    'cvec__max_df': [.6, .7, .8],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, # what object are we optimizing?\n",
    "                  param_grid=pipe_params, # what parameters values are we searching?\n",
    "                  cv=5) # 5-fold cross-validation\n",
    "\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.808441252190468\n",
      "Best training score: 0.8172659754393705\n",
      "Best test score: 0.8166890580683684\n"
     ]
    }
   ],
   "source": [
    "# What's the best score?\n",
    "print('Best score:', gs.best_score_)\n",
    "\n",
    "# Score model on training set.\n",
    "print('Best training score:', gs.score(X_train, y_train))\n",
    "\n",
    "# Score model on testing set.\n",
    "print('Best test score:', gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEGCAYAAAB2EqL0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAj0UlEQVR4nO3deZwVxbnG8d8zwyIKCMjiyCJGcV9AEFFvlKhXiTvRKMbtxjVGjYl6jVtcr0aj0Vxx3+Vq3KLGLS64oGIUBEQWETGCiqCCRgVFkJn3/tENHseZM43MOTNz5vn66Q+nq6urqxk871RVd5UiAjMzs7qUNXQFzMysaXDAMDOzTBwwzMwsEwcMMzPLxAHDzMwyadHQFbCVoxZtQq3aNXQ1bAX026hXQ1fBVsC7785i/vz5WpkyytuvHbF0Uaa8sWjekxExZGWuVygOGE2cWrWj9Qb7N3Q1bAW8NOaqhq6CrYDtth6w0mXE0kWZ/z/9euLVnVf6ggXigGFmVnACNf0RAAcMM7NCE1BW3tC1WGkOGGZmxaCVGgZpFBwwzMwKzl1SZmaWlVsYZmZWJ+EWhpmZZSG3MMzMLCM/JWVmZnXzoLeZmWUh3CVlZmYZuYVhZmZ1c5eUmZllIaDcg95mZpaFxzDMzKxu7pIyM7Os3MIwM7NM3MIwM7M6yVODmJlZVp4axMzM6uZBbzMzy8pdUmZmVievh2FmZtm4S8rMzLIqgUHvph/yzMyagmWP1ta11VmMekp6TtI0SVMlnZimnyvpA0kT0223nHNOl/S2pOmSds1J7y9pcnrsSil/BdzCMDMrNNVrl9RS4OSImCCpHTBe0sj02BURcdl3L62NgWHAJsBawNOS1o+ISuBa4GjgFeAfwBDg8dou7BaGmVkx1FMLIyLmRsSE9PMCYBrQPc8pewN3R8TiiJgJvA0MlFQBtI+IlyMigBHAPvmu7YBhZlYEkjJtQGdJ43K2o/OU2RvoB4xJk46XNEnSLZI6pmndgfdzTpudpnVPP1dPr5UDhplZgSUrtGYOGPMjYkDOdkONZUptgfuB30bEFyTdS+sCfYG5wJ9zLl9d5EmvlccwzMwKTUJl9ffinqSWJMHizoh4ACAiPso5fiPwaLo7G+iZc3oPYE6a3qOG9Fq5hWFmVgQr0MKoqxwBNwPTIuLynPSKnGxDgSnp54eBYZJaS1oH6AOMjYi5wAJJg9IyDwUeyndttzDMzIogSzDIaDvgEGCypIlp2hnAgZL6knQrzQKOAYiIqZLuBd4gecLquPQJKYBjgduANiRPR9X6hBQ4YJiZFUV9BYyIGE3N4w//yHPOhcCFNaSPAzbNem0HDDOzQhM1f8U3MQ4YZmYFJrKNTzR2DhhmZkVQVtb0nzFywDAzKwK3MMzMrG4ewzAzs6zcwjAzszp50NvMzDKrz6lBGooDhplZocldUmZmlpEDhpmZZeKAYWZmdfKgt5mZZdf044UDhplZwclTg5iZWUbukjIzs2yafrxwwLDi6N6tA9eeeyhd12hPVQS3P/gS1989ipsv+iV91u4GwOpt2/D5wkVsf9DFtGxRzhVnHEi/jXpRVVXFaX++n5cmzABg6H9uycm/3JWy8jJGjp7COcPzripp9WTzvc6m7aqtKS8ro0WLMp4b8XsuvPZR/vHCJMokunRqx9XnHExFlw58s7SS3/zPnbz+5vtUVlZxwG4DOemXuzb0LTQotzDykNQNuAIYBPwbWAL8KSIeLNQ166jPfwEDIuL4Wo4/BHSNiG1W4hoDgEMj4jd58vQF1oqIWlfHKkVLl1Zx1l8eYNL02bRdtTXPjfg9o8a8yRFn3Lo8zwW/HcoXCxcBcNjQ7QDY7sCL6NyxLff976/Z8bBL6dB+Vc7/zT4MPuRPfPLZQq455xC232p9Xnj1rQa5r+bmketOZI0ObZfvn3DITpx57B4AXH/3KP500+NccfqB/P3pCSxespR/3n0mX329hEH7/w/77TqAXmut0VBVb1BZ1+tu7AoyCpMuKP534IWI+FFE9AeGAT0Kcb2c6/6gACipA7Al0CFdJP0HiYhx+YJFqi+w2w+9RlP10SdfMGn6bAAWfrWYt2Z9SEWXDt/JM3TnLbn/yfEAbLDOmrzw6nQA5v97IZ8vXES/jXrRu/savP3ex3zy2UIAnh/7Jnvt2Ldo92Hf1b5tm+Wfv1y0ePmXoiS+WrSEpUsr+frrJbRqWU671VZpqGo2CsuCRl1bY1aoYfsdgSURcd2yhIh4NyKGA0gql3SppFclTZJ0TJo+WNIoSX+T9KakO9Pgg6T+kp6XNF7Sk5Iq0vRRki6S9DxwoqQ9JY2R9Jqkp9OWTl32BR4B7iYJbKRl3ybpSkn/lPSOpP3S9KFp2ZJUIektSWum9X80zbOapFvSe3xN0t6SWgHnAwdImijpAEkzJHVJzymT9Lakziv7A2jMelZ0YvMNejB+6qzladv2W5ePP1nAO+/PA2DKjA/46fabUV5eRq+11qDvhj3p3q0j77w/jz5rd6NnRSfKy8vYbfAWdO/WsYHupHmRxM+Ov4rBh1zCbQ+MXp5+wTUPs8nuZ3HfE+M445jdAdh7p36s2qYVG/70TDbb82yOP2gnOq6+WkNVvVFQmTJtjVmhuqQ2ASbkOX4E8HlEbCWpNfCSpKfSY/3S8+cALwHbSRoDDAf2joh5kg4gWdD88PScDhGxA4CkjsCgiAhJRwKnAifXUd8DgfOAj4C/AX/MOVYB/AewIfAw8LeIeFDSvsBxwBDgnIj4UNKGOeedCTwbEYenLZixwNPA2eR0jaXnHAT8BdgZeD0i5uerrKSjgaMBaNk2X9ZGZ7U2rRhxyZGcfvn9LPjy6+Xp++4ygPufGrd8/46HX2b93t14bsSpvD/3U8ZOmsnSyko+X7CIUy65h1suOpyqqmDs5HfovVZJx9dG44mbfkdFlw7M+3QBQ4+/ij6912S7LdfjD7/eiz/8ei8uv/VJbrz3BU4/ZnfGT51FeVkZ0x6/kM+++IrdjrqCwQM3pHeP5vuzauythyyKMugt6WqSL90lEbEVsAuw+bLf2IHVgT4k4xxjI2J2et5EoDfwGbApMDL9Sy8H5uZc4p6czz2Ae9IWSCtgZh116wasB4xOg8xSSZtGxJQ0y98jogp4o1pr5QRgCvBKRNxVQ9G7AHtJOiXdXwXoVUO+W4CHSALG4cCtNeT5joi4AbgBoGzVrlFX/saiRXkZt19yFPc9MY5Hn3t9eXp5eRl7/GQLfnLon5anVVZWceYVDyzff/Lmk5a3Pp54cQpPvJj8eA4buh1VlVVFuoPmbVkXYpdO7dhj8OZMmDqL7bZcb/nx/YZsxQG/vZbTj9mdvz0xjp223ZiWLcrp0qkdW2/xI16b9l7zDRglMvlgobqkppKMCQAQEccBOwFd0iQBJ0RE33RbJyKWtTAW55RTSRLUBEzNyb9ZROySk+/LnM/DgasiYjPgGJIv6nwOADoCMyXNIglQw3KO59Yn9yfeHagCukmq6e9RwL45de4VEdOqZ4qI94GPJO0IbA08Xkd9m6zhfziIt2Z9yDV/ffY76YMHbsCMdz9izsefLU9r07olq67SKj2+IUuXVjF95ocAdO6YtKpWb9eGI/b7MSMeerk4N9CMfblo8fIW4ZeLFvPsK2+y0bpr8a/3Pl6e54kXJrF+7+R3qh5rduLFV6cTEXy5aDHjpsyiT+8svcOlSYCUbWvMCtXCeBa4SNKxEXFtmrZqzvEngWMlPRsR30haH/ggT3nTgS6StomIlyW1BNaPiKk15F09p6zDMtT1QGBIRLwMkA56jwTOqu2EdHD9VuAXwKHAScBl1bI9CZwg6YS05dIvIl4DFgDtquW9CbgD+L+IqEyvMRQYGBGnZ7iHRm/QFj9i2O5bM3XGB7xw52kAXHD1w4z85xv8bJf+ywe7l+ncqR33Dz+Oqqpg7rzP+NU5ty8/dvHJ+7FJn+4AXHrTE9/50rLCmPfJAg4+9UYAKpdWsu+QAey87cYceuqNzHj3Y8rKRM81O3H56cnvWkf+fHuOP/8Otj3gQgL4xZ6D2DT9mTVPjX9AO4uCBIz0C3If4ApJpwLzSFoBv0+z3ETym/yEdFB7HrBPnvKWpN1XV0paPa33X0haMtWdC9wn6QPgFaDWp54k9SbpJnol51ozJX0haes8t3gG8GJEvJh2m70q6bFqeS5I6zgpvcdZwB7Ac8Bp6Xl/jIh7SMZGbuW73VHrAl/kqUOT8srr79BxqxqfaOa48+74Xtr7cz9l4H4X1Jj/yLNuq8+qWQa9e3Rm9F+//7vLiD8dVWP+tqu25raLjyh0tZqUskY+oJ2FIppMF3jJUvL+xhUR8eOctDuA30XEvHznlq3aNVpvsH+hq2j16N+vXtXQVbAVsN3WAxg/ftxKfduvUrF+9D5seKa80y8ZMj4iBqzM9QrFb3o3MEmnAceSPCm1XEQc3DA1MrP6JkqjhdH0p09s4iLi4ohYOyJG153bzJoqD3qbmVkmHvQ2M7O6NYHWQxYOGGZmBSbkBZTMzCwbtzDMzCwTj2GYmVndPIZhZmZZJHNJNf2I4YBhZlYEJRAvHDDMzIqhFN70dsAwMyu0ElkPwwHDzKzAlq2H0dQ1/TdJzMwavWQ9jCxbnSVJPSU9J2mapKmSTkzTO0kaKWlG+mfHnHNOl/S2pOmSds1J7y9pcnrsStVRAQcMM7MiqMfJB5cCJ0fERsAg4DhJGwOnAc9ERB/gmXSf9NgwYBNgCHCNpPK0rGuBo0mWyO6THq+VA4aZWaEpGfTOstUlIuZGxIT08wJgGsmS0XsDy5amvJ1vF6XbG7g7IhZHxEzgbWCgpAqgfUS8HMnCSCPIs5AdeAzDzKzgVvA9jM6SxuXs3xARN9RYbrJqaD9gDNAtIuZCElQkdU2zdSdnVVFgdpr2Tfq5enqtHDDMzIpgBQLG/Cwr7klqC9wP/DYivshTfk0HIk96rdwlZWZWBPW5gJKkliTB4s6IeCBN/ijtZiL98+M0fTbQM+f0HsCcNL1HDem1csAwMyuCenxKSsDNwLSIuDzn0MPAYennw4CHctKHSWotaR2Swe2xaffVAkmD0jIPzTmnRu6SMjMrtPqdfHA74BBgsqSJadoZwMXAvZKOAN4Dfg4QEVMl3Qu8QfKE1XERUZmedyxwG9AGeDzdauWAYWZWYMkCSvUTMSJiNDWPPwDsVMs5FwIX1pA+Dtg067UdMMzMiqCsBF71dsAwMyuCEogXDhhmZoUmTz5oZmZZlcDs5g4YZmbF4PUwzMysTiJ5Uqqpc8AwMyuCEmhgOGCYmRVcxre4GzsHDDOzIiiBeOGAYWZWaMIv7pmZWUZ+SsrMzOq0IlOXN2YOGGZmReAuKTMzy6TphwsHDDOzovBjtWZmVqfkKamGrsXKc8AwMys01d8CSg2pzjW9lThY0tnpfi9JAwtfNTOz0lFfa3o3pDoDBnANsA1wYLq/ALi6YDUyMysxy7qksmyNWZYuqa0jYktJrwFExL8ltSpwvczMSkpjbz1kkSVgfCOpHAgASV2AqoLWysysxDT9cJEtYFwJPAh0lXQhsB9wVkFrZWZWQiQob+z9TRnUGTAi4k5J44GdSILkPhExreA1MzMrIc2iS0pSL+Ar4JHctIh4r5AVMzMrJSUQLzJ1ST1GMn4hYBVgHWA6sEkB62VmVjKEmsdcUhGxWe6+pC2BYwpWIzOzUtNcZ6uNiAmStipEZWzFbb5hT556/oqGroatgI47ndfQVbAVsPitOfVSTnMZwzgpZ7cM2BKYV7AamZmVGAHlzSFgAO1yPi8lGdO4vzDVMTMrTSXwVG3+gJG+sNc2Iv67SPUxMytJJR0wJLWIiKXpILeZmf1AyRKtTT9i5GthjCUZr5go6WHgPuDLZQcj4oEC183MrGSUdAsjRyfgE2BHvn0fIwAHDDOzjEqggZE3YHRNn5CawreBYpkoaK3MzEqIgBYlEDHyBYxyoC01T7LogGFmtgJKIF7kDRhzI+L8otXEzKxESaU/NUjTvzszs0aiBOJF3oCxU9FqYWZW4kr6KamI+LSYFTEzK1WiNBZQKmvoCpiZlTwlLYwsW51FSbdI+ljSlJy0cyV9IGliuu2Wc+x0SW9Lmi5p15z0/pImp8euVIY3Cx0wzMyKQBn/y+A2YEgN6VdERN90+weApI2BYSTrFw0BrkmnfAK4Fjga6JNuNZX5HQ4YZmYFJuqvhRERLwBZhwz2Bu6OiMURMRN4GxgoqQJoHxEvR0QAI4B96irMAcPMrAhWIGB0ljQuZzs64yWOlzQp7bLqmKZ1B97PyTM7Teuefq6entcKL6BkZmYrbgUmH5wfEQNWsPhrgQtIXqq+APgzcDi1v3j9g17IdsAwMyswCcoL2J8TER99ey3dCDya7s4GeuZk7QHMSdN71JCel7ukzMyKoCx927uu7YdIxySWGUoyByDAw8AwSa0lrUMyuD02IuYCCyQNSp+OOhR4qK7ruIVhZlZgywa966Us6S5gMMlYx2zgHGCwpL4k3UqzgGMAImKqpHuBN0hWTD0uIirToo4leeKqDfB4uuXlgGFmVgT1NTVIRBxYQ/LNefJfCFxYQ/o4YNMVubYDhplZwYmyEpiezwHDzKzAROlPPmhmZvVB0KIE5pJywDAzKzC3MMzMLLNSX0DJzMzqSQnECwcMM7NCE6XxlrQDhplZocldUmZmlkHyprcDhpmZZdD0w4UDhplZUZRAA8MBw8ys8LQi62E0Wg4YZmYF5qekzMwsMw96m5lZ3bRCS7Q2Wg4YZmYF5i4pMzPLzC0MMzPLpOmHCwcMM7OCE1DuFoaZmWVRAvHCAcPMrPCESqBTygHDzKwI3MIwM7M6JY/VNv2I4YBhZlZocgvDzMwy8tQgZmZWp2QBpYauxcpzwDAzKwI/JWVmZpmUQI+UA4Y1jM8XLOL3f7qbt2Z+CMClpx1Im1Vacsaf7+Orr5bQo6Ij//uHQ2i32ioAXH3H09zz2BjKy8S5J/6MHQZu2JDVbxa6d2nPtaftQ9eObamK4PbHJnD9A2MAOGqfgRy1z1Ysraxi5JgZnHPD0/x8p804Yf9tl5+/yY+6scOvrudfsz/htrN/Tu+1OlFZVcWTL7/FeTc901C31WDcwjAkVQKTSf4upwG/BR5LD68JVALz0v2BwH8Dv0jTq4BjImKMpFFABbAYaAU8DZwVEZ8V4z6K7bwrH2CHrTfiugt+yZJvlrLo6284+ORrOfPXezGo73rc89gYrr/rWU45cjfemvUhjzzzGiNv/z0fzf+cg066llF3nkF5eSnM/9l4La2s4qzrnmLSjA9p26YVz113NKPG/4suHduy27Yb8B9HXceSbyrp3GFVAO57ZjL3PTMZgI3X6cqd5w9jyr8+ok3rFgy/72VGT5xFyxZlPHTZoew8cD2eHvt2Q95eUZXKGIb/j1t5iyKib0RsCiwBDkj3+wLXAVfk7PcH9gC2jIjNgZ2B93PKOihN35wkcDxUxPsomgVffs2Y199h2O5bA9CqZQtWb9eGd977mK23WBeAHw9Yn8efnwTAyNFT2HOnfrRu1YJea61B7+6dmTjtvQarf3Px0acLmTQjaQEuXLSEt96dR0Xn9hy+5wD+cvdolnxTCcD8z7763rn77rgp9z83BYBFi5cyeuIsAL5ZWsXrMz5krc7ti3MTjYVEWcatMXPAqF8vAuvlOV4BzI+IxQARMT8i5lTPFBFLgFOBXpK2KEhNG9B7cz5hjQ5tOeWPd/HTIy7j1Evu5qtFi1l/nQpGjk6+ZB4b9TpzP/4MgA/nfU5F1w7Lz1+zSwc+nP9Z8SvejPXstjqbr1fB+GmzWa/HGmyz2dqMvOoIHr38MPptsNb38g8dvAn3Pzv5e+ntV2vNkEHr8/xr7xSj2o2KMm6NmQNGPZHUAvgpSfdUbZ4Cekp6S9I1knaoLWNEVAKvA9/rrJd0tKRxksZ9Mn/+yla96CorK5kyYzYH77Mdj998Cquu0opr7nyGS08bxogHR7P7kX/my6++pmXLcgAi4ntllEJ/cFOx2iotGXHu/px+zRMs+GoJLcrL6NB2Ff7z+Js5+/qR3PqH/b6Tv/+G3Vn09TdMmzXvO+nlZeLms/bl+gfH8O7cz4p4Bw0v6ZJyC8OgjaSJwDjgPeDm2jJGxEKSbqmjScY17pH0X3nKrvFfT0TcEBEDImLAGp07/9B6N5g1u3Sgosvq9Nt4bQB2G7wFU96azXprd+OOy4/lsZtOZq+dt2TttZJ7q+jaYXlrA+DDeZ/RrfPqDVH1ZqdFeRm3n7s/9z0zmUdHvwnAB/O+4JHR0wCYMH0OVRGssfqqy8/52U++7Y7K9ZeT9uRfsz/lunTgvLlxC8Pg2zGMvhFxQtqdVKuIqIyIURFxDnA8sG9N+SSVA5uRDKSXlK5rtKeiawf+9d7HALw0fgZ9eq/J/H8vAKCqqorhI0Zy0N7JEzf/ud0mPPLMayxespT35nzCzNnz6LtRrwarf3My/JS9eOu9+Vzzt1eWp/3jpTfZvt86AKzboxOtWpTzyefJOIYEe++w8fcCxpm//AntV2vN6dc8UbzKNzYlEDH8lFQRSdoAqIqIGWlSX+DdGvK1BC4E3o+IScWrYfGcd+K+nHjB//HNN5X0WmsNLjv9QO5/4lVGPPgSAEO234z9dxsIwPrrVLD7T/qy86EX06K8jAt+t5+fkCqCQZv2ZNguWzD1nY944fpjALjg5me444nXuOq/9+afNx3LkqWVHHvJ35efs+3mazNn3hff6XJaq3M7Tjl4e6a/O4/nr0vKufGhsfzfP14r5u00uMbe3ZSFauoftuwkLYyItrUcOxdYGBGXpfv9geFAB2Ap8DZwdETMr/ZYbWuSx2rPrOux2r5b9o+nnn8lXxZrZNbe46KGroKtgMUTrqdqwZyV+rbfaLN+MeKhUZnyDly3w/iIGLAy1ysUtzBWUm3BIj12brX98cC2teQdXK8VM7PGpek3MBwwzMwKLRmeaPoRwx3BZmaFlq6HkWWrsyjpFkkfS5qSk9ZJ0khJM9I/O+YcO13S25KmS9o1J72/pMnpsSuluq/ugGFmVgT1+JDUbcCQammnAc9ERB/gmXQfSRsDw4BN0nOuSZ/ABLiW5BH/PulWvczvccAwMys4IWXb6hIRLwCfVkveG7g9/Xw7sE9O+t0RsTgiZpI8aDNQUgXQPiJejuTJpxE559TKYxhmZkWwAk/VdpY0Lmf/hoi4oY5zukXEXICImCupa5reHch9jHJ2mvZN+rl6el4OGGZmBbaC7+TNr8fHamu6bORJz8tdUmZmxVDYN70/SruZSP/8OE2fDfTMydcDmJOm96ghPS8HDDOzIlDG/36gh4HD0s+H8e3SCA8DwyS1lrQOyeD22LT7aoGkQenTUYeSYTkFd0mZmRVBfc0MIukuYDDJWMds4BzgYuBeSUeQTIL6c4CImCrpXuANktkljktnwgY4luSJqzbA4+mWlwOGmVmhZXzHIouIOLCWQzvVkv9CkrnpqqePAzZdkWs7YJiZFUEpvOntgGFmVmCi/loYDckBw8ysCEogXjhgmJkVRQlEDAcMM7MiKIUFlBwwzMyKoOmHCwcMM7PiKIGI4YBhZlZgpbKAkgOGmVmh1eOLew3JAcPMrAhKIF44YJiZFV62xZEaOwcMM7MiKIF44YBhZlZoK7fURePhgGFmVgwlEDEcMMzMisCP1ZqZWSYewzAzs7oJyhwwzMwsm6YfMRwwzMwKzAsomZlZZiUQLxwwzMyKwS0MMzPLxFODmJlZJk0/XDhgmJkVnDy9uZmZZeU3vc3MLJumHy8cMMzMiqEE4oUDhplZ4YmyEhjEcMAwMyuwUnnTu6yhK2BmZk2DWxhmZkVQCi0MBwwzsyLwY7VmZlY3v7hnZmZZlMqgtwOGmVkRuEvKzMwycQvDzMwyKYF44YBhZlYUJRAxHDDMzApMUBJTgygiGroOthIkzQPebeh6FEBnYH5DV8JWSKn+zNaOiC4rU4CkJ0j+frKYHxFDVuZ6heKAYY2SpHERMaCh62HZ+WdW+jyXlJmZZeKAYWZmmThgWGN1Q0NXwFaYf2YlzmMYZmaWiVsYZmaWiQOGmZll4oDRDEnqJumvkt6RNF7Sy5KGNmB9/kvSVXmOPyTp5ZW8xgBJV9aRp6+k3VbmOqVEUqWkiZKmSLpPUvd0f6KkDyV9kLPfStKZkqZKmpSmbZ2WM0rS9DT9TUlXSerQwLdnP4ADRjMjScDfgRci4kcR0R8YBvQo8HV/0KwC6RfLlkAHSev80OtHxLiI+E0d2foCDhjfWhQRfSNiU2AJcEC63xe4DrgiZ78/sAewZURsDuwMvJ9T1kFp+ubAYuChIt6H1RMHjOZnR2BJRFy3LCEi3o2I4QCSyiVdKunV9DfCY9L0welvin9Lf0u8Mw0+SOov6fm0tfKkpIo0fZSkiyQ9D5woaU9JYyS9JulpSd0y1Hdf4BHgbpLARlr2bZKulPTPtKW0X5o+NC1bkiokvSVpzbT+j6Z5VpN0S3qPr0naW1Ir4HzggPS34wMkzZDUJT2nTNLbkrK+rVtqXgTWy3O8guQN5cUAETE/IuZUzxQRS4BTgV6StihITa1gHDCan02ACXmOHwF8HhFbAVsBR+X8Zt8P+C2wMfAjYDtJLYHhwH5pa+UW4MKc8jpExA4R8WdgNDAoIvqRBIBTM9T3QOCudDuw2rEK4D9IfrO9GCAiHgQ+BI4DbgTOiYgPq513JvBseo8/AS4FWgJnA/ekvzXfA9wBHJSeszPwekSU4tQXeaWtw58Ck/NkewromQboayTtUFvGiKgEXgc2rN+aWqF58sFmTtLVJF+6S9Iv0F2AzZf9xg6sDvQh6ZIYGxGz0/MmAr2Bz4BNgZFpg6McmJtziXtyPvcA7klbIK2AmXXUrRvJb7WjIyIkLZW0aURMSbP8PSKqgDeqtVZOAKYAr0TEXTUUvQuwl6RT0v1VgF415LuFpOvkL8DhwK356luC2qQ/Z0haGDfXljEiFkrqD/yYJAjfI+m0iLitllOa/kx8zZADRvMzlaSbB4CIOC7tZhmXJgk4ISKezD1J0mCSvudlKkn+/QiYGhHb1HK9L3M+Dwcuj4iH0/LOraOuBwAdgZlpMGpP0i11Vno8tz65X0DdgSqgm6SyNKhQLe++ETH9O4npIO0yEfG+pI8k7QhszbetjeZiUTo+kUnachgFjJI0GTgMuK16PknlwGbAtHqppRWNu6San2eBVSQdm5O2as7nJ4Fj064mJK0vabU85U0HukjaJs3fUtImteRdHfgg/XxYhroeCAyJiN4R0ZtkYHVYvhPS7pNbgV+QfCGdVEO2J4ETcsZg+qXpC4B21fLeRNI1dW/6hbhsnOSPGerfbEjaQFKfnKS+1DCLcvrv6o/A+xExqUjVs3rigNHMRPJq/z7ADpJmShoL3A78Ps1yE/AGMEHSFOB68rRE00HM/YBLJL0OTAS2rSX7ucB9kl6kjmmwJfUm6SZ6JedaM4EvqrcEqjkDeDEiXiQJFkdK2qhangtIxiwmpfd4QZr+HLDxskHvNO1hoC3f7Y5aF/giX/2bobbA7ZLekDSJZJzr3Jzjd6bpU4DVgL2LX0VbWZ4axCwPSQNIHh/9cU7aHcDvImJew9XMrPgcMMxqIek04FiSdwhGN3R9zBqaA4aZmWXiMQwzM8vEAcPMzDJxwDAzs0wcMMxqoO/P1Lpq3WfVWtZtOXNd3SRp4zx5B0uq7bHkfNeY1YznubIiccAwq1n1mVp/lXswfVt5hUXEkRHxRp4sg6n9PRazBuWAYVa3F4H10t/+n5P0V2Cyap/ZV0rWfHhD0mNA12UFKZnBd0D6eYikCZJel/RM+rLir4Dfpa2bH0vqIun+9BqvStouPXcNSU+ls+1ej+dmsiLwXFJmeeTM1PpEmjQQ2DQiZko6mnRmX0mtgZckPUUyq+8GJPMldSN5c/6WauV2IZlNd/u0rE4R8amk64CFEXFZmu+vJC8OjpbUi2Rak42Ac0gmZTxf0u7A0QX9izDDAcOsNjXN1LotyYy9y2bZrW1m3+2Bu9K5p+ZIeraG8geRLGI1EyAiPq2lHjuTTFeybL+9pHbpNX6WnvuYpH//sNs0y84Bw6xm35upNf3Szp19t7aZfXcD6nojVhnyQNJtvE1ELKqhLn7r1orKYxhmP1xtM/u+AAxLxzgqSNaHqO5lkgkg10nP7ZSmV58x9yng+GU7kvqmH18gnW5d0k9JpoE3KygHDLMfrraZfR8EZpCsUHct8Hz1E9OJC48GHkhn+V220NQjwNBlg97Ab4AB6aD6G3z7tNZ5wPaSJpB0jb1XoHs0W85zSZmZWSZuYZiZWSYOGGZmlokDhpmZZeKAYWZmmThgmJlZJg4YZmaWiQOGmZll8v/Bq0BjTBexBgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds = gs.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "# View confusion matrix\n",
    "cmd = plot_confusion_matrix(gs, X_test, y_test, cmap='Blues', values_format='d', display_labels=['General Anxiety,','PTSD'])\n",
    "cmd.ax_.set(xlabel='Predicted', ylabel='True');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:101: FutureWarning: Attribute coef_ was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>like</td>\n",
       "      <td>0.017282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>im</td>\n",
       "      <td>0.013020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>feel</td>\n",
       "      <td>0.012663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>know</td>\n",
       "      <td>0.010511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>get</td>\n",
       "      <td>0.009479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1717</th>\n",
       "      <td>time</td>\n",
       "      <td>0.008272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>even</td>\n",
       "      <td>0.007988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>really</td>\n",
       "      <td>0.007693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>want</td>\n",
       "      <td>0.007297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>dont</td>\n",
       "      <td>0.007228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>people</td>\n",
       "      <td>0.006355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>one</td>\n",
       "      <td>0.006108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>life</td>\n",
       "      <td>0.005529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>years</td>\n",
       "      <td>0.005499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>things</td>\n",
       "      <td>0.005155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>back</td>\n",
       "      <td>0.005109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>never</td>\n",
       "      <td>0.005082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>think</td>\n",
       "      <td>0.005004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>ive</td>\n",
       "      <td>0.004927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>go</td>\n",
       "      <td>0.004851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Features  Coefficients\n",
       "959      like      0.017282\n",
       "852        im      0.013020\n",
       "617      feel      0.012663\n",
       "915      know      0.010511\n",
       "704       get      0.009479\n",
       "1717     time      0.008272\n",
       "553      even      0.007988\n",
       "1348   really      0.007693\n",
       "1830     want      0.007297\n",
       "482      dont      0.007228\n",
       "1217   people      0.006355\n",
       "1162      one      0.006108\n",
       "956      life      0.005529\n",
       "1906    years      0.005499\n",
       "1697   things      0.005155\n",
       "169      back      0.005109\n",
       "1120    never      0.005082\n",
       "1698    think      0.005004\n",
       "891       ive      0.004927\n",
       "716        go      0.004851"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to create dataframe of highest coefficients \n",
    "\n",
    "df_multinomial = pd.DataFrame([[x,y] for x,y in zip(gs.best_estimator_[0].get_feature_names(), np.exp(gs.best_estimator_[1].coef_).tolist()[0])])\n",
    "df_multinomial.rename(columns= {0: 'Features', 1: 'Coefficients'}, inplace = True)\n",
    "df_multinomial.sort_values(by = 'Coefficients', ascending = False).head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-4787bd6de3a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m                   cv=5) # 5-fold cross-validation\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m         \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[0;32m    672\u001b[0m             \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m             \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0merror_score\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'raise'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m_passthrough_scorer\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_passthrough_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[1;34m\"\"\"Function that wraps estimator.score\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    616\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m         \u001b[0mscore_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   1872\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'The TF-IDF vectorizer is not fitted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1873\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1874\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1875\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m         \u001b[1;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1255\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1256\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1257\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1115\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1116\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1117\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mngrams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m                 \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mngrams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m                 \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mngrams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_word_ngrams\u001b[1;34m(self, tokens, stop_words)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m_word_ngrams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m         \u001b[1;34m\"\"\"Turn tokens into a sequence of n-grams after stop words filtering\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[1;31m# handle stop words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = df['lower_selftext']\n",
    "y = df['subreddit']\n",
    "\n",
    "\n",
    "# Train test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('tfid', TfidfVectorizer(stop_words = stopwordlist)),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipe_params = {\n",
    "    'tfid__max_features': [1_000, 2_000],\n",
    "    'tfid__min_df': [0.001, .002, .005],\n",
    "    'tfid__max_df': [.6, .7, .8],\n",
    "    'tfid__ngram_range': [(1,1), (1,2)],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, # what object are we optimizing?\n",
    "                  param_grid=pipe_params, # what parameters values are we searching?\n",
    "                  cv=5) # 5-fold cross-validation\n",
    "\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8115298390411698\n",
      "Best training score: 0.8307228472681815\n",
      "Best test score: 0.8256456187490671\n"
     ]
    }
   ],
   "source": [
    "# What's the best score?\n",
    "print('Best score:', gs.best_score_)\n",
    "\n",
    "# Score model on training set.\n",
    "print('Best training score:', gs.score(X_train, y_train))\n",
    "\n",
    "# Score model on testing set.\n",
    "print('Best test score:', gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEGCAYAAAB2EqL0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAqp0lEQVR4nO3de5xVVf3/8dd7hosoclEuIoigoSloKGhoaaRW5NcLXr4JWVral/SnppWVt2+ahXbVQlOzNOSbEaamZJpiimiBBoggIgqKiqACpqIiOPD5/bHX6HGcOWcPzDkDw/vZYz88Z+21115nhuZz1mWvpYjAzMyslKrmroCZmW0aHDDMzCwXBwwzM8vFAcPMzHJxwDAzs1xaNXcFbMOo9Zahth2buxrWCAN37dncVbBGeP65RSxfvlwbUkZ1hx0jalblyhurlt0dEcM25H7l4oCxiVPbjrTd48TmroY1wpTJlzR3FawRDtx/3w0uI2pW0XbXL+TK+86sX3fZ4BuWibukzMzKTqCqfEepkqQdJN0vaZ6kuZLOTOkTJM1KxyJJs1J6H0mrCs5dU1DWIElzJC2QNEZS0ZaUWxhmZuUmoKq6qUqrAb4dETMlbQ3MkDQpIo5773bSL4DXC65ZGBED6ynramAUMA24ExgG3NXQjd3CMDOrBCnfUUJELI2Imen1SmAe8N7AWGolfAEYX7w66gF0iIipkS35MQ4YXuwaBwwzs7JrVJdUF0nTC45RDZYq9QH2Ah4uSD4AeDkini5I6yvpUUkPSDogpfUEFhfkWUxB4KmPu6TMzCohR+shWR4Rg0sXp/bALcBZEfFGwamRfLB1sRToHRErJA0CbpPUn6yjrK6iiws6YJiZlZvINaCduzipNVmwuDEibi1IbwUcDQyqTYuI1cDq9HqGpIXALmQtil4FxfYClhS7r7ukzMzKLuf4RY5WSBqjuA6YFxGX1Tl9CPBkRCwuyN9VUnV6vRPQD3gmIpYCKyUNSWWeANxe7N5uYZiZVULTzZL6BPBlYE7t1FngvIi4ExjBhwe7DwQullQDrAVOiYhX07lTgbFAO7LZUQ3OkAIHDDOzClCTdUlFxEPUP/5ARHylnrRbyLqv6ss/HRiQ994OGGZm5SYaM+i90XLAMDOrhCYc9G4uDhhmZmXXdF1SzckBw8ys3ARUN9mgd7NxwDAzqwSPYZiZWWnukjIzs7zcwjAzs1zcwjAzs5JyLvuxsXPAMDOrhKZbGqTZOGCYmZWdB73NzCwvd0mZmVlJTbwfRnNxwDAzKzt3SZmZWV4tYNB70w95ZmabgqbbcW8HSfdLmidprqQzU/pFkl6UNCsdhxZcc66kBZLmS/pcQfogSXPSuTFp570GuYVhZlZuatIuqRrg2xExU9LWwAxJk9K5yyPi5x+8tXYn24mvP7A9cK+kXSJiLXA1MAqYBtwJDKPIrntuYZiZVUITtTAiYmlEzEyvVwLzgJ5FLjkS+FNErI6IZ4EFwL6SegAdImJqRAQwDhhe7N4OGGZmFSAp19HIMvsAewEPp6TTJc2WdL2kzimtJ/BCwWWLU1rP9LpueoMcMMzMyizboTV3wOgiaXrBMareMqX2ZHt1nxURb5B1L+0MDASWAr8ouH1dUSS9QR7DMDMrNwlV5W49LI+IwcWLU2uyYHFjRNwKEBEvF5z/LXBHersY2KHg8l7AkpTeq570BrmFYWZWAU3VJZVmMl0HzIuIywrSexRkOwp4PL2eCIyQ1FZSX6Af8EhELAVWShqSyjwBuL3Yvd3CMDOrgMaOTxTxCeDLwBxJs1LaecBISQPJupUWAV8HiIi5km4CniCbYXVamiEFcCowFmhHNjuqwRlS4IBhZlYRTRUwIuIh6h9/uLPINaOB0fWkTwcG5L23A4aZWbmJ+v/Eb2IcMMzMykw0fsrsxsgBw8ysAqqqNv05Rg4YZmYV4BaGmZmV5jEMMzPLyy0MMzMryYPeZmaWWyOWBtloOWCYmZWb3CVlZmY5OWCYmVkuDhhmZlaSB73NzCy/TT9eOGCYmZWdvDSImZnl5C4pMzPLZ9OPFw4YVhk9u3Xk6vO/QLdttmZdBDdMfITf3PxPrrtoJP16dwWgY/t2vP7mKg48aQxDB3+EC08ZRptWrVhTU8P3r7qLB2cuBOCog/bk2yd8mqqqKiZNfZILry66SZg1kddXvs1Zl4znyWeWIsSvLvgiH+ndjf+5YCzPL32V3j224Xejv0qnDlvybs1azrpkPHPmv0BNzTq+cOg+nHXiZ5v7IzSrpmphSNoBGAdsB6wDro2IX0n6GXA4sAZYCHw1Il6T1AeYB8xPRUyLiFNSWYN4f8e9O4EzIyIaunfZAoak7sDlwBDgP2Qf4qcR8Zdy3bNEfb4CDI6I0xs4fzvQLSL224B7DAZOiIhvFMkzENg+IhrcHaslqlm7jgt+/TdmP7WE9u3acP91ZzB5+tOcfNH49/L88LT/4o233gFgxetvM/J7N/DSipXs1rc7N//iJPoffSmdO2zJxf/vUIZ+7QpWvPYWV5333xw4aGemzFjYXB9ts3He5bdy0JDd+P2lJ7Pm3RpWvbOGX46dxAH77MKZJ3yGX42bxJhxk/j+6Ucy8R+PsmZNDVNuPJe331nDJ0dcwtGfGUTv7bdt7o/RLPLu151TDfDtiJgpaWtghqRJwCTg3IiokfQT4Fzge+mahRExsJ6yrgZGAdPIAsYwimzTWpZRmLSh+G3AlIjYKSIGASOAXuW4X8F91ysASuoE7A10Spukr5eImF4sWCQDgUPX9x6bqpdXrGT2U0sAeHPVGp5atIweXTp8IM9Rn96DW+6dBcCcp5fw0oqVAMx79mW2aNOKNq2r6bP9Nix4YRkrXnsLgAdmLOCIT+XeYdLW08q3VjHt0QV86Yjs+1Sb1q3ouPWW3PXgHI47dF8Ajjt0X+6cMgfI/kC+vWo1NTVreWf1u7RuXc3WW23RbPXfGNQGjVJHKRGxNCJmptcryVoPPSPinoioSdmmUeLvraQeQIeImJpaFeOA4cWuKdew/UHAmoi4pjYhIp6LiCtSRasl/UzSvyXNlvT1lD5U0mRJN0t6UtKNKfggaZCkByTNkHR3+rCk/JdIegA4U9Lhkh6W9Kike1NLp5RjgL8CfyILbKSyx0oaI+lfkp6RdGxKPyqVLUk9JD0labtU/ztSnq0kXZ8+46OSjpTUBrgYOE7SLEnHSXpaUtd0TZWkBZK6bOgvYGO2w3ad2XOX7ZnxxAvvpe3/sb688p83eWbxig/lP2LoAGY/vYQ1767lmcUr6Ne7Gzts15nq6ioO/WR/enbrVMHab54WvbiCbTu354wf3sinT/gJZ43+I2+tWs2yV1eyXZeOAGzXpSPL/5MF+cMPGsiW7doy4LAL2OvICznt+IPo3HGr5vwIzU5VynUAXSRNLzhGNVhm1t20F/BwnVMn8cGWQt/0d+gBSQektJ7A4oI8i1Nag8rVJdUfmFnk/MnA6xGxj6S2wD8l3ZPO7ZWuXwL8E/iEpIeBK4AjI2KZpOPINjQ/KV3TKSI+BSCpMzAkIkLS14DvAt8uUd+RwA+Al4GbgUsLzvUAPgl8FJgI3BwRf5F0DHAaWRPuwoh4SdJHC647H7gvIk5KLZhHgHuB71PQNZauOR74JXAI8FhELC9W2fQPKPtH1KZDsawbna3atWHcj47n3DF/ZeXbq99LP+aQj3HLvY99KP9H+3TjolM+z9Hfug6A199cxdm/uI3rfzCSdeuCRx5/nj7bb1Ox+m+u1q5dx+z5i7n0W8cyaEAfzrvsFsaMu7fB/DPnPkd1lZhzx4947Y23OfyUX3HgPrvSp2eL/i5UVCO6pJZHxOAc5bUHbgHOiog3CtLPJ+u2ujElLQV6R8SKNGZxm6T+1D8M3+D4BVRo0FvSr8n+6K6JiH2AzwJ71n5jBzoC/cjGOR6JiMXpullAH+A1YAAwKf3Qq8l+CLUmFLzuBUxILZA2wLMl6tYd+AjwUAoyNZIGRMTjKcttEbEOeKJOa+UM4HGyAaTxfNhngSMknZ3ebwH0riff9cDtZAHjJOD3xeoLEBHXAtcCVLXvUfQXvDFpVV3FDT/6En+eNIs7psx9L726uorDDuzPp792xQfyb9+1A/93yZc5dfRNLFry6nvpf//XPP7+r3kAnHj4vqxbt64yH2Az1qNbJ7bv2olBA/oAWQtizLhJdN1ma15a/jrbdenIS8tfp0vnrQG45Z7pHLTfbrRuVU3XbbZm3z37Mmve85tvwGjixQcltSYLFjdGxK0F6ScChwEH1w5eR8RqYHV6PUPSQmAXshZFYbdVL7Iv6g0qV5fUXLIxAQAi4jTgYKBrShJwRkQMTEffiKhtYawuKGctWVATMLcg/x4RUTjl4q2C11cAV0bEHsDXyf5QF3Mc0Bl4VtIisgA1ouB8YX0Kf+M9yWYodJdU389RwDEFde4dEfPqZoqIF4CXJR0EfJwiA06buivOOZanFr3CVRMe+kD60EEf4ennl7Fk2XtfkujQfgsm/PSrXPybu3l4znMfyN+lU9a10bF9O04+agjj7vh3+Su/meu+bQe2796JBc+9DMCD/57Prn23Y9gBA5hw5yMATLjzET5/wB4A9OremQenP01E8Naq1cx4fBH9dszTO9wyCZDyHSXLyiLPdcC8iLisIH0Y2SD3ERHxdkF6V0nV6fVOZF/On4mIpcBKSUNSmSeQfXltULlaGPcBl0g6NSKuTmlbFpy/GzhV0n0R8a6kXYAXi5Q3H+gqab+ImJqi6y4RMbeevB0LyjoxR11HAsMiYipAGvSeBFzQ0AXKBtd/D3yR7If8LeDndbLdDZwh6YzUctkrIh4FVgJb18n7O+APwP9FxNp0j6OAfSPi3ByfYaM3ZI8dGTFsb+YuXMqU67N5AT+89m4mTZvP0fV0R/3P0fvTt+e2fOfEg/jOiQcBcPS3rmP5a2/x4zMPp/9HegDws7H/YOELRXvwrIlc+u1jOeXCcbz77lp27LktYy44nnURfO3833PjxGn02q4z143+KgAnHXsg3/jRjRzwxUuJCEYeNoT+/Yp2j7dwTTpL6hPAl4E5qRcG4DxgDNCW93tiaqfPHghcLKmG7Ev4KRFR22Q/lfen1d5FiS+sKjLldoOkLqHLyb41LyNrBVwTERPSN/Ifkc0ZVjo/nGz84uyIOCyVcSUwPSLGKpuOOoYsILQCfhkRv5U0OV0zPV1zZLrvi2QzBfaJiKGqZ1ptGjD6J9CrcO6xpJlkP8hTgTsi4uaU/mZEtJf0fbJxk28pm9b2b+AooHtt/SW1I+tm2j99xkUpfRuyYNIauDT9PFoDK8gCxJPpXmcDrSOicDzlQ6ra94i2e+SJi7axWDb5kuaugjXCgfvvy8wZ0zfor/0W2+0SO554RemMwFM/HTYjzxhGcyhbwLD8lD2/cXlEHFCQ9gfgmxGxrNi1DhibHgeMTUuTBIweu0SfnAFj/k823oDhJ72bmaRzyFoyxxemR8SXmqdGZtbUBFS1gC1aN/3lEzdxEfHjiNgxIh4qndvMNlVNNejdnNzCMDOrgKacVttcHDDMzMptE2g95OGAYWZWZkLeQMnMzPJxC8PMzHLxGIaZmZXmMQwzM8sjW0tq048YDhhmZhXQAuKFA4aZWSW0hCe9HTDMzMqtiffDaC4OGGZmZVa7H8amzgHDzKzsmnQ/jGaz6T96aGa2CWjCHfd2kHS/pHmS5ko6M6VvI2mSpKfTfzsXXHOupAWS5kv6XEH6IElz0rkxKhHVHDDMzMpN2aB3niOHGuDbEbEbMAQ4TdLuwDnAPyKiH/CP9J50bgTQHxgGXFW7ZStwNTCKbNvWful8gxwwzMzKrPY5jDxHKRGxNCJmptcrgXlAT+BI4IaU7QayXUxJ6X+KiNUR8SywANg37YraISKmph1HxxVcUy+PYZiZVUAjxjC6SJpe8P7aiLi2gTL7kG1t/TDQPSKWQhZUJHVL2XqSbVdda3FKeze9rpveIAcMM7MKaMSY9/I8W7RKag/cApwVEW8UCUj1nYgi6Q1yl5SZWQU0VZdUKqs1WbC4MSJuTckvp24m0n9fSemLgR0KLu8FLEnpvepJb5ADhplZueWcIZVzlpSA64B5EXFZwamJwInp9YnA7QXpIyS1ldSXbHD7kdR9tVLSkFTmCQXX1MtdUmZmZZZtoNRkz2F8AvgyMEfSrJR2HvBj4CZJJwPPA/8NEBFzJd0EPEE2w+q0iFibrjsVGAu0A+5KR4McMMzMKqCqiR7ci4iHqH/8AeDgBq4ZDYyuJ306MCDvvR0wzMwqoAU86O2AYWZWbvLig2ZmllcLWN3cAcPMrBK8H4aZmZUksplSmzoHDDOzCmgBDQwHDDOzsmvEU9wbMwcMM7MKaAHxwgHDzKzcRNM9uNecHDDMzCrAs6TMzKykvAsLbuwcMMzMKsBdUmZmlsumHy4cMMzMKsLTas3MrKRsllRz12LDecc9M7NyU7aBUp6jdFG6XtIrkh4vSJsgaVY6FtVurCSpj6RVBeeuKbhmkKQ5khZIGqMcTaCSLYxUyPHAThFxsaTewHYR8UjJT2ZmZkCTdkmNBa4ExtUmRMRxBff5BfB6Qf6FETGwnnKuBkYB04A7gWGU2HEvTwvjKmA/YGR6vxL4dY7rzMyM97uk8hylRMQU4NV675NFpS8A44vWR+oBdIiIqRERZMFneKl75wkYH4+I04B3UmX/A7TJcZ2ZmSVK60mVOoAukqYXHKMacZsDgJcj4umCtL6SHpX0gKQDUlpPYHFBnsUprag8g97vSqoGAkBSV2BdrqqbmRnQqGm1yyNi8HreZiQfbF0sBXpHxApJg4DbJPVvoDpRqvA8AWMM8Begm6TRwLHABTmuMzMzsqe8q8s8TUpSK+BoYFBtWkSsBlan1zMkLQR2IWtR9Cq4vBewpNQ9SgaMiLhR0gzgYLKoNDwi5jXic5iZbfYq8BzGIcCTEfFeV1PqEXo1ItZK2gnoBzwTEa9KWilpCPAwcAJwRakblBzDSLOi3gb+CkwE3kppZmaWU+16UqWO0uVoPDAV2FXSYkknp1Mj+PBg94HAbEmPATcDp0RE7YD5qcDvgAXAQkrMkIJ8XVJ/I+vbErAF0BeYD/TPca2Z2WZPqMnWkoqIkQ2kf6WetFuAWxrIPx0Y0Jh75+mS2qPwvaS9ga835iZmZpu1zXW12oiYKWmfclTGGm+vXXvyzwd/3NzVsEbovM/pzV0Fa4TV859vknI2i7WkJH2r4G0VsDewrGw1MjNrYQRUbw4BA9i64HUN2ZhGvX1iZmZWv5aw+GDRgJEe2GsfEd+pUH3MzFqkFh0wJLWKiJo0yG1mZuspmzK76UeMYi2MR8jGK2ZJmgj8GXir9mRE3FrmupmZtRgtuoVRYBtgBXAQ7z+PEYADhplZTi2ggVE0YHRLM6Qe5/1AUavkIlVmZpYR0KoFRIxiAaMaaM96rmpoZmbvawHxomjAWBoRF1esJmZmLZTUdEuDNKdiAWPT/3RmZhuJFhAvigaMgytWCzOzFq5Fz5IqWALXzMw2gCj/BkqV0OjFB83MrJHUMloYJTdQMjOzDaec/ytZjnS9pFckPV6QdpGkFyXNSsehBefOlbRA0nxJnytIHyRpTjo3RjkeRXfAMDMrM5G1MPIcOYwFhtWTfnlEDEzHnQCSdifbia9/uuaqtEYgwNXAKLJtW/s1UOYHOGCYmVVAUwWMiJgC5B1jPhL4U0SsjohnybZj3VdSD6BDREyNiADGAcNLfoacNzUzsw0gKdexAU6XNDt1WXVOaT2BFwryLE5pPdPruulFOWCYmZWZBNVV+Q6gi6TpBceoHLe4GtgZGAgsBX5Re+t68tZd6qkwvSjPkjIzq4BGPOm9PCIGN6bsiHi59rWk3wJ3pLeLgR0KsvYClqT0XvWkF+UWhplZmTXxoPeHy8/GJGodRbZoLMBEYISktpL6kg1uPxIRS4GVkoak2VEnALeXuo9bGGZmFdBUS4NIGg8MJeu6WgxcCAyVNJCsW2kR8HWAiJgr6SbgCbIttk+LiLWpqFPJZly1A+5KR1EOGGZmZSeqmmh5vogYWU/ydUXyjwZG15M+HRjQmHs7YJiZlZlo+YsPmplZUxC0agFrgzhgmJmVmVsYZmaWW0vfQMnMzJpIC4gXDhhmZuUmWsZDbw4YZmblJndJmZlZDtmT3g4YZmaWw6YfLhwwzMwqogU0MBwwzMzKb4P3utgoOGCYmZWZZ0mZmVluHvQ2M7PShLukzMysNHdJmZlZbi2hhdESgp6Z2UZPOY+S5UjXS3pF0uMFaT+T9KSk2ZL+IqlTSu8jaZWkWem4puCaQZLmSFogaYxyRDQHDDOzMhNQLeU6chgLDKuTNgkYEBF7Ak8B5xacWxgRA9NxSkH61cAosn2++9VT5oc4YJiZVYCU7yglIqYAr9ZJuyciatLbaUCv4nVRD6BDREyNiADGAcNL3dsBw8ys7JT7f0AXSdMLjlGNvNlJwF0F7/tKelTSA5IOSGk9gcUFeRantKI86G1mVgGNGPNeHhGD1+8eOh+oAW5MSUuB3hGxQtIg4DZJ/al/uCRKle+AYWZWZtm02vLOkpJ0InAYcHDqZiIiVgOr0+sZkhYCu5C1KAq7rXoBS0rdw11SZmbllnP8Yn1n3koaBnwPOCIi3i5I7yqpOr3eiWxw+5mIWAqslDQkzY46Abi91H3cwjAzq4CmWhpE0nhgKNlYx2LgQrJZUW2BSWl27LQ0I+pA4GJJNcBa4JSIqB0wP5VsxlU7sjGPwnGPejlgmJmVWbaBUtOUFREj60m+roG8twC3NHBuOjCgMfd2wDAzqwC1gC2UHDDMzCqgBawM4oBhzWPPI75P+y3bUl1VRatWVdw/7nsAXDthMr+9aQqtqqv4zCcHcPE3hgNw2e/v5g8Tp1JdVcWPzz6Wg/fbvRlrv3no2b0TV190At227cC6CG74yz/5zZ8mM2CXnlx2zgi2aNuampp1nP2TCcx84jkAvvmVz/KlI/Zj7bp1nPPzm7lv2jzatW3N2B+fTJ9eXVi7Lrj7wTn84MqJzfzpKs8tDEPSWmAO2c9yHnAW8Ld0ejuygaZl6f2+wHeAL6b0dcDXI+JhSZOBHmRT4NoA9wIXRMRrlfgczeGv15zJtp3av/f+welPcecDc3ho/Lm0bdOaZa+uBODJZ5Zy66SZTJ1wPi8te53hp13J9Fu+T3W1J/mVU03NOi745a3Mnr+Y9lu25f5x32Pyw0/ygzOG89Pf3cW9/3qCz+y/Oz/4xnAOP+VX7Np3O47+zN7sd9xotuvakdt+fTqDj7kYgCv+8A8emvE0rVtVc/tVZ3DI/rtz77+eaOZPWDlNOYbRnPz/uA23Kq3RMgBYAxxXu24LcA1wecH7QWTzpPdOa74cArxQUNbxKX1PssBRcppbS3L9LQ9y1omfoW2b1gB03WZrAO58YDZHf2Zv2rZpzY49u7DTDl2YMXdRM9Z08/DyijeYPT97GPjNt1fz1KKX6NG1ExGw9VZbANChfTteWvY6AId+ak9unTSTNe/W8PySFTzzwnIG9e/DqtXv8tCMpwF4t2Ytj81/ge27dWqWz9RsJKpyHhszB4ym9SDwkSLne5A9xVn7IM3yiPjQwzIRsQb4LtBb0sfKUtNmJomjT7+SoV/+CWNvfQiABc+9wtRZCznkKz/jv0b9kplzs26Opctep2f3zu9du323zixNf6SsMnbosQ177tqLGXMXcd5lN3PxN4bz+B0/5OIzj+LiX2ffa3p07ciLL//nvWuWvPIfenTt+IFyOrRvx7AD9uCBf8+vaP03Bk21Wm1zcpdUE5HUCvg88Pci2e4Bvi/pKbIupwkR8UB9GSNiraTHgI8Cj9W51yiyVSbZoXfvJqh95f39d9+kR9dOLHt1JUedfiX9+mxHzdp1vLbybSb9/mxmPvEcXz3vembddhHpodUP2Mi/iLUoW7Vrw7iffI1zL7uFlW+9w/mnHMZ5l93KX++fxfBD9mLM/x7PUaddWe9+D4W/uurqKq4b/RV+M2Eyz724ooKfoPllXVKb/j9atzA2XDtJs4DpwPM0MB8aICLeJOuWGkU2rjFB0leKlF3vv7CIuDYiBkfE4K5duq5vvZtVj66dgKzb6bChezJz7iJ6duvE4Z/+GJIY1L8PVRIrXnuT7bt1+tA31+26dGygZGtKraqruOEn/8Of/z6dO+7PvreMPOzj/PX+WQDcdu+j7L37jgAseeW1D7UEX1r+fkvwl+eNZOHzy7hm/OSK1X9j0hJaGA4YG652DGNgRJyRupMaFBFrI2JyRFwInA4cU1++9Dj/HmQD6S3KW6tWs/Ktd957fd+0J9lt5+05dOieTPn3UwAseO5l1rxbw7ad2vP5A7O+8dVr3uW5F5ez8PllDOrfpxk/webjiv89nqcWvcRVf7zvvbSly17nE3v3A+DAfXbhmReyOR13TcnGmtq0bkXv7bdl595d3xtrOv+Uw+jQvh3nXlbvM2SbhxYQMdwlVUGSdgXWRcTTKWkg8Fw9+VoDo4EXImJ25WpYGctWrORL3/0tAGtr1nLMsMEcsv/urHm3htMvvpH9jhtNm9bVXH3Rl5HEbjv3YPghezHkC6NpVV3Fz777Bc+QqoAhH9uJEf/1ceY+/SJTbjwHgB/+eiJnjf4jl377WFpVV/HOmhrOumQ8AE8+8xK33fso0246n5q16/jOT29i3bpg+26dOPvkYcx/9iUe+EM2ffq3Nz3A/90+tdk+W3NoCV1Sqq9/2PKT9GZEtG/g3EXAmxHx8/R+EHAF0IlsCeIFwKiIWF5nWm1bsjGO80tNqx00aHD88+HpTfJZrDI673N6c1fBGmH1/JtY9/YrG/TXfrc99opxt0/OlXffnTvNWN/lzcvNLYwN1FCwSOcuqvN+BrB/A3mHNmnFzGzjsuk3MBwwzMzKLRue2PQjhgOGmVm5bcBeFxsTBwwzswpoAfHC02rNzMpPSPmOkiVJ10t6RdLjBWnbSJok6en0384F586VtEDSfEmfK0gfJGlOOjdGOW7ugGFmVgFNuEXrWGBYnbRzgH9ERD/gH+k9knYHRgD90zVX1W7ZClxN9hBxv3TULfNDHDDMzMos7zN7eeJFREwBXq2TfCRwQ3p9AzC8IP1PEbE6Ip4lm8q/r6QeQIeImBrZsxXjCq5pkMcwzMwqIf8gRhdJhQ9XXRsR15a4pntELAWIiKWSuqX0nsC0gnyLU9q76XXd9KIcMMzMKqAR02qXN+GDe/XdNIqkF+UuKTOzCmjCMYz6vJy6mUj/fSWlLwZ2KMjXC1iS0nvVk16UA4aZWbnlDBYbEDAmAiem1yfy/uZrE4ERktpK6ks2uP1I6r5aKWlImh11Ajk2bHOXlJlZBTTVk96SxgNDycY6FgMXAj8GbpJ0Mtk2C/8NEBFzJd0EPEG2ft1pEbE2FXUq2YyrdsBd6SjKAcPMrMxE0z3pHREjGzh1cAP5R5Otfl03fTowoDH3dsAwM6uAlvCktwOGmVkltICI4YBhZlYBLWEDJQcMM7MK2PTDhQOGmVlltICI4YBhZlZm3kDJzMzy8QZKZmaWVwuIFw4YZmbll29zpI2dA4aZWQW0gHjhgGFmVm55N0fa2DlgmJlVQguIGA4YZmYV4Gm1ZmaWi8cwzMysNEFVCwgY3nHPzKwilPMoUYq0q6RZBccbks6SdJGkFwvSDy245lxJCyTNl/S59f0EbmGYmZVZE2+gNB8YCCCpGngR+AvwVeDyiPj5B+4t7Q6MAPoD2wP3StqlYOe93NzCMDOrgKZpX3zIwcDCiHiuSJ4jgT9FxOqIeBZYAOzb+Fs5YJiZVYSU7yDbq3t6wTGqSLEjgPEF70+XNFvS9ZI6p7SewAsFeRantEZzwDAzqwBJuQ5geUQMLjiubaC8NsARwJ9T0tXAzmTdVUuBX9RmrefyWJ/P4IBhZlYBZeiS+jwwMyJeBoiIlyNibUSsA37L+91Oi4EdCq7rBSxZn8/ggGFmVmZ5u6MaOTA+koLuKEk9Cs4dBTyeXk8ERkhqK6kv0A94ZH0+h2dJmZlVQFM+6S1pS+AzwNcLkn8qaSBZd9Oi2nMRMVfSTcATQA1w2vrMkAIHDDOzymjCB/ci4m1g2zppXy6SfzQwekPv64BhZlYBLeBBbwcMM7PyE1UtYDEpBwwzszJryie9m5NnSZmZWS5uYZiZVUBLaGE4YJiZVYA3UDIzs9Ia/1DeRskBw8yszFrKoLcDhplZBbhLyszMcnELw8zMcmkB8cIBw8ysIlpAxHDAMDMrM0GLWBpEEeu18ZJtJCQtA4rt57up6gIsb+5KWKO01N/ZjhHRdUMKkPR3sp9PHssjYtiG3K9cHDBsoyRpekQMbu56WH7+nbV8XkvKzMxyccAwM7NcHDBsY3Vtc1fAGs2/sxbOYxhmZpaLWxhmZpaLA4aZmeXigLEZktRd0h8lPSNphqSpko5qxvp8RdKVRc7fLmnqBt5jsKQxJfIMlHTohtynJZG0VtIsSY9L+rOknun9LEkvSXqx4H0bSedLmitpdkr7eCpnsqT5Kf1JSVdK6tTMH8/WgwPGZkaSgNuAKRGxU0QMAkYAvcp83/VaVSD9Ydkb6CSp7/rePyKmR8Q3SmQbCDhgvG9VRAyMiAHAGuC49H4gcA1wecH7QcBhwN4RsSdwCPBCQVnHp/Q9gdXA7RX8HNZEHDA2PwcBayLimtqEiHguIq4AkFQt6WeS/p2+EX49pQ9N3xRvTt8Sb0zBB0mDJD2QWit3S+qR0idLukTSA8CZkg6X9LCkRyXdK6l7jvoeA/wV+BNZYCOVPVbSGEn/Si2lY1P6UalsSeoh6SlJ26X635HybCXp+vQZH5V0pKQ2wMXAcenb8XGSnpbUNV1TJWmBpLxP67Y0DwIfKXK+B9kTyqsBImJ5RCypmyki1gDfBXpL+lhZampl44Cx+ekPzCxy/mTg9YjYB9gH+J+Cb/Z7AWcBuwM7AZ+Q1Bq4Ajg2tVauB0YXlNcpIj4VEb8AHgKGRMReZAHguznqOxIYn46Rdc71AD5J9s32xwAR8RfgJeA04LfAhRHxUp3rzgfuS5/x08DPgNbA94EJ6VvzBOAPwPHpmkOAxyKiJS59UVRqHX4emFMk2z3ADilAXyXpUw1ljIi1wGPAR5u2plZuXnxwMyfp12R/dNekP6CfBfas/cYOdAT6kXVJPBIRi9N1s4A+wGvAAGBSanBUA0sLbjGh4HUvYEJqgbQBni1Rt+5k32ofioiQVCNpQEQ8nrLcFhHrgCfqtFbOAB4HpkXE+HqK/ixwhKSz0/stgN715LuerOvkl8BJwO+L1bcFapd+z5C1MK5rKGNEvClpEHAAWRCeIOmciBjbwCWb/kp8myEHjM3PXLJuHgAi4rTUzTI9JQk4IyLuLrxI0lCyvudaa8n+/QiYGxH7NXC/twpeXwFcFhETU3kXlajrcUBn4NkUjDqQdUtdkM4X1qfwD1BPYB3QXVJVCirUyXtMRMz/QGIapK0VES9IelnSQcDHeb+1sblYlcYnckkth8nAZElzgBOBsXXzSaoG9gDmNUktrWLcJbX5uQ/YQtKpBWlbFry+Gzg1dTUhaRdJWxUpbz7QVdJ+KX9rSf0byNsReDG9PjFHXUcCwyKiT0T0IRtYHVHsgtR98nvgi2R/kL5VT7a7gTMKxmD2Sukrga3r5P0dWdfUTekPYu04yaU56r/ZkLSrpH4FSQOpZxXl9O/qUuCFiJhdoepZE3HA2MxE9mj/cOBTkp6V9AhwA/C9lOV3wBPATEmPA7+hSEs0DWIeC/xE0mPALGD/BrJfBPxZ0oOUWAZbUh+ybqJpBfd6FnijbkugjvOAByPiQbJg8TVJu9XJ80OyMYvZ6TP+MKXfD+xeO+id0iYC7flgd9TOwBvF6r8Zag/cIOkJSbPJxrkuKjh/Y0p/HNgKOLLyVbQN5aVBzIqQNJhs+ugBBWl/AL4ZEcuar2ZmleeAYdYASecAp5I9Q/BQc9fHrLk5YJiZWS4ewzAzs1wcMMzMLBcHDDMzy8UBw6we+vBKrVuWvqrBssYWrHX1O0m7F8k7VFJD05KL3WPRZrzOlVWIA4ZZ/equ1HpK4cn0tHKjRcTXIuKJIlmG0vBzLGbNygHDrLQHgY+kb//3S/ojMEcNr+wrZXs+PCHpb0C32oKUreA7OL0eJmmmpMck/SM9rHgK8M3UujlAUldJt6R7/FvSJ9K120q6J622+xu8NpNVgNeSMiuiYKXWv6ekfYEBEfGspFGklX0ltQX+KekeslV9dyVbL6k72ZPz19cptyvZaroHprK2iYhXJV0DvBkRP0/5/kj24OBDknqTLWuyG3Ah2aKMF0v6L2BUWX8QZjhgmDWkvpVa9ydbsbd2ld2GVvY9EBif1p5aIum+esofQraJ1bMAEfFqA/U4hGy5ktr3HSRtne5xdLr2b5L+s34f0yw/Bwyz+n1opdb0R7tw9d2GVvY9FCj1RKxy5IGs23i/iFhVT1381K1VlMcwzNZfQyv7TgFGpDGOHmT7Q9Q1lWwByL7p2m1Set0Vc+8BTq99I2lgejmFtNy6pM+TLQNvVlYOGGbrr6GVff8CPE22Q93VwAN1L0wLF44Cbk2r/NZuNPVX4KjaQW/gG8DgNKj+BO/P1voBcKCkmWRdY8+X6TOavcdrSZmZWS5uYZiZWS4OGGZmlosDhpmZ5eKAYWZmuThgmJlZLg4YZmaWiwOGmZnl8v8BENYpzxS+TsMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds = gs.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "# View confusion matrix\n",
    "cmd = plot_confusion_matrix(gs, X_test, y_test, cmap='Blues', values_format='d', display_labels=['General Anxiety,','PTSD'])\n",
    "cmd.ax_.set(xlabel='Predicted', ylabel='True');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:101: FutureWarning: Attribute coef_ was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>like</td>\n",
       "      <td>0.007429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>im</td>\n",
       "      <td>0.007129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>feel</td>\n",
       "      <td>0.006390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>know</td>\n",
       "      <td>0.005455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>get</td>\n",
       "      <td>0.004774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>want</td>\n",
       "      <td>0.004475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1411</th>\n",
       "      <td>really</td>\n",
       "      <td>0.004424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>dont</td>\n",
       "      <td>0.004407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>time</td>\n",
       "      <td>0.004140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>even</td>\n",
       "      <td>0.004137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>people</td>\n",
       "      <td>0.004017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>anyone</td>\n",
       "      <td>0.003641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>one</td>\n",
       "      <td>0.003570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>years</td>\n",
       "      <td>0.003550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>life</td>\n",
       "      <td>0.003479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>ive</td>\n",
       "      <td>0.003375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>things</td>\n",
       "      <td>0.003276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>help</td>\n",
       "      <td>0.003213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>think</td>\n",
       "      <td>0.003097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>back</td>\n",
       "      <td>0.003092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Features  Coefficients\n",
       "1010     like      0.007429\n",
       "892        im      0.007129\n",
       "645      feel      0.006390\n",
       "962      know      0.005455\n",
       "736       get      0.004774\n",
       "1908     want      0.004475\n",
       "1411   really      0.004424\n",
       "506      dont      0.004407\n",
       "1789     time      0.004140\n",
       "579      even      0.004137\n",
       "1273   people      0.004017\n",
       "115    anyone      0.003641\n",
       "1214      one      0.003570\n",
       "1985    years      0.003550\n",
       "1007     life      0.003479\n",
       "933       ive      0.003375\n",
       "1767   things      0.003276\n",
       "829      help      0.003213\n",
       "1768    think      0.003097\n",
       "175      back      0.003092"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to create dataframe of highest coefficients \n",
    "\n",
    "df_ = pd.DataFrame([[x,y] for x,y in zip(gs.best_estimator_[0].get_feature_names(), np.exp(gs.best_estimator_[1].coef_).tolist()[0])])\n",
    "df_.rename(columns= {0: 'Features', 1: 'Coefficients'}, inplace = True)\n",
    "df_.sort_values(by = 'Coefficients', ascending = False).head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split into single words \n",
    "\n",
    "# columns = ['lower_selftext', 'lower_title']\n",
    "\n",
    "# for col in columns:\n",
    "#     new_col = str('split_' + col.split('_')[1])\n",
    "#     df[new_col] = df[col].apply(lambda x: x.split())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Stop words present in the library\n",
    "# stopwords = nltk.corpus.stopwords.words('english')\n",
    "# stopwords[0:10]\n",
    "\n",
    "# #defining the function to remove stopwords from tokenized text\n",
    "# def remove_stopwords(text):\n",
    "#     output= [i for i in text if i not in stopwords]\n",
    "#     return output\n",
    "\n",
    "# columns = ['split_selftext', 'split_title']\n",
    "\n",
    "# for col in columns:\n",
    "#     new_col = str('stopwords_' + col.split('_')[1])\n",
    "#     df[new_col] = df[col].apply(lambda x:remove_stopwords(x))   "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
