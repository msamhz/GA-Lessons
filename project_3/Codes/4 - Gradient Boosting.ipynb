{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- [Data Importing](#Data-Importing)\n",
    "- [Classification metrics](#Classification-metrics)\n",
    "- [Vectorizer Selection via GridSeachCV](#Vectorizer-Selection-via-GridSeachCV)\n",
    "- [Hyper-parameter tuning](#Hyper-parameter-tuning)\n",
    "- [Error Analysis](#Error-Analysis)\n",
    "- [Redefine Data set and run models](#Redefine-Data-set-and-run-models)\n",
    "- [Production Model Selection](#Production-Model-Selection)\n",
    "- [Conclusion and Recommendation](#Conclusion-and-Recommendation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import string\n",
    "string.punctuation\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import contractions\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score, \\\n",
    "    plot_roc_curve, roc_auc_score, recall_score, precision_score, f1_score\n",
    "from transformers import pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk import word_tokenize   \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "import matplotlib.dates as mdate\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "\n",
    "from sklearn.model_selection import(\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    "    GridSearchCV\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    PolynomialFeatures\n",
    ")\n",
    "from datetime import timezone\n",
    "import datetime\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/df.csv')\n",
    "df.drop(columns = 'Unnamed: 0', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author                   0\n",
       "subreddit                0\n",
       "selftext                 0\n",
       "title                    0\n",
       "created_utc              0\n",
       "datetime                 0\n",
       "link_flair_css_class     0\n",
       "alltext                  0\n",
       "length_text              0\n",
       "wrdcount_text            0\n",
       "month                    0\n",
       "day                      0\n",
       "clean_text               1\n",
       "ttl_post                 0\n",
       "user_contribute_where    0\n",
       "stem_clean_text          1\n",
       "lemmi_clean_text         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model Prep: Create `X` and `y` variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our features will be:\n",
    "- `subreddit`\n",
    "- `stem_clean_text`\n",
    "- `lemmi_clean_text`\n",
    "\n",
    "For our baseline modelling will be using lemmi_clean_text\n",
    "\n",
    "Our target will be `subreddit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['lemmi_clean_text']\n",
    "y = df['subreddit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible classification metrics that can be used how well my model perform are *Accuracy, Misclassification Rate, Sensitivity (True Positive Rate), Specificity (True Negative Rate), Precision (Positive Predictive Value), F1 Score and ROC AUC*.\n",
    "\n",
    "For this project I will be mainly using *Accuracy* accompanied with confusion matrix to determine effectiveness of my models\n",
    "\n",
    "For further evaluations, I will be using Specificity to choose the best model that helps gauge on how best to minimize this in order to reduce missing out identifying users potentionally having PTSD.\n",
    "\n",
    "I will also use ROC to gave a gauge the degree of overlap between the words in post from the two subreddits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Accuracy Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total post: 20228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    0.500395\n",
       "0    0.499605\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Total post: {len(df)}')\n",
    "df['subreddit'].value_counts(normalize= True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 10000 post added into each class, the classes are very well balanced from both sides \n",
    "\n",
    "Also, from the above, we can see the ***baseline accuracy*** is at 50.1%. \n",
    "If nothing ws done for the classification model, and just to assign every post to the PTSD class, i would classify 50.1% of the post correctly. \n",
    "\n",
    "Therefore, any classification model designed for this data must have an accuracy higher than the ***baseline accuracy*** of 50.1%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizer Selection via GridSeachCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider two NLP vectorizers and iterate over parameters below with Logistic regression model first.\n",
    "- *Count Vectorizer*\n",
    "- *TF-IDF Vectorizer*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embed Stopword list into vectorizers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stop word list \n",
    "stopwordlist = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# to input in subreddit headers so that we can exclude it for model\n",
    "headers = ['ptsd', 'anxiety','anxious', \"cptsd\", 'trauma','traumatized','traumas',\"posttraumatic\",'stress','disorder',\"traumatic\", 'www', 'https', 'mentalgrenade', 'com']\n",
    "for head in headers:\n",
    "    stopwordlist.append(head)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Pipeline with:\n",
    "# Estimator: LogisticRegression (both)\n",
    "# Transformer: CountVectorizer - pipe1, TfidfVectorizer - pipe2\n",
    "\n",
    "pipe1 = Pipeline([('tvec', TfidfVectorizer(stop_words= stopwordlist)),\n",
    "                  ('gboost', GradientBoostingClassifier())\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ccp_alpha',\n",
       " 'criterion',\n",
       " 'init',\n",
       " 'learning_rate',\n",
       " 'loss',\n",
       " 'max_depth',\n",
       " 'max_features',\n",
       " 'max_leaf_nodes',\n",
       " 'min_impurity_decrease',\n",
       " 'min_samples_leaf',\n",
       " 'min_samples_split',\n",
       " 'min_weight_fraction_leaf',\n",
       " 'n_estimators',\n",
       " 'n_iter_no_change',\n",
       " 'random_state',\n",
       " 'subsample',\n",
       " 'tol',\n",
       " 'validation_fraction',\n",
       " 'verbose',\n",
       " 'warm_start']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GradientBoostingClassifier()._get_param_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['memory', 'steps', 'verbose']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1._get_param_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipe1_params = {'tvec__max_features': [1000],\n",
    "                'tvec__min_df': [0.02,0.01],\n",
    "                'tvec__max_df': [0.7,0.8],\n",
    "                'tvec__ngram_range': [(1,1)],\n",
    "                'gboost__max_depth': [4,5,6],\n",
    "                'gboost__n_estimators': [150,200],\n",
    "                'gboost__learning_rate': [.12,.15,.2]\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating two separate GridSearchCV objects for:\n",
    "# CountVectorizer and TfidfVectorizer\n",
    "\n",
    "gs_pipe1 = GridSearchCV(pipe1, param_grid=pipe1_params, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Admin\\Desktop\\Github Desktop Local\\GA-Lessons\\project_3\\Codes\\4 - Gradient Boosting.ipynb Cell 27'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/Github%20Desktop%20Local/GA-Lessons/project_3/Codes/4%20-%20Gradient%20Boosting.ipynb#ch0000024?line=0'>1</a>\u001b[0m \u001b[39m# Fitting GridSearchCV with CountVectorizer transformer on X_train and y_train.\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/Github%20Desktop%20Local/GA-Lessons/project_3/Codes/4%20-%20Gradient%20Boosting.ipynb#ch0000024?line=2'>3</a>\u001b[0m gs_pipe1\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=884'>885</a>\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=885'>886</a>\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=886'>887</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=888'>889</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=890'>891</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=892'>893</a>\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=893'>894</a>\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=894'>895</a>\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=1389'>1390</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=1390'>1391</a>\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=1391'>1392</a>\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=829'>830</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=830'>831</a>\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=831'>832</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=832'>833</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=833'>834</a>\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=834'>835</a>\u001b[0m         )\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=835'>836</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=837'>838</a>\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=838'>839</a>\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=839'>840</a>\u001b[0m         clone(base_estimator),\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=840'>841</a>\u001b[0m         X,\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=841'>842</a>\u001b[0m         y,\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=842'>843</a>\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=843'>844</a>\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=844'>845</a>\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=845'>846</a>\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=846'>847</a>\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=847'>848</a>\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=848'>849</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=849'>850</a>\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=850'>851</a>\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=851'>852</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=852'>853</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=854'>855</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=855'>856</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=856'>857</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=857'>858</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=858'>859</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=859'>860</a>\u001b[0m     )\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=1052'>1053</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=1054'>1055</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=1055'>1056</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=1056'>1057</a>\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=1057'>1058</a>\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=932'>933</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=933'>934</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=934'>935</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=935'>936</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=936'>937</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/_parallel_backends.py?line=538'>539</a>\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/_parallel_backends.py?line=539'>540</a>\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/_parallel_backends.py?line=540'>541</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/_parallel_backends.py?line=541'>542</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/_parallel_backends.py?line=542'>543</a>\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/_parallel_backends.py?line=543'>544</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\concurrent\\futures\\_base.py:440\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/concurrent/futures/_base.py?line=436'>437</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/concurrent/futures/_base.py?line=437'>438</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/concurrent/futures/_base.py?line=439'>440</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/concurrent/futures/_base.py?line=441'>442</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/concurrent/futures/_base.py?line=442'>443</a>\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/threading.py?line=309'>310</a>\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/threading.py?line=310'>311</a>\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/threading.py?line=311'>312</a>\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/threading.py?line=312'>313</a>\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/threading.py?line=313'>314</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fitting GridSearchCV with CountVectorizer transformer on X_train and y_train.\n",
    "\n",
    "gs_pipe1.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gboost__learning_rate': 0.12,\n",
       " 'gboost__max_depth': 4,\n",
       " 'gboost__n_estimators': 150,\n",
       " 'tvec__max_df': 0.7,\n",
       " 'tvec__max_features': 1000,\n",
       " 'tvec__min_df': 0.02,\n",
       " 'tvec__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_pipe1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7952665398954626"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_pipe1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7929602531144948"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_pipe1.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8679058730472612"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_pipe1.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "592c428e42f6e4511884ace7c9b495d167f60b904bd88ca4683897c5c1f20061"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
