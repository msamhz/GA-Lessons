{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import string\n",
    "string.punctuation\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk import word_tokenize   \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "\n",
    "from sklearn.model_selection import(\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    "    GridSearchCV\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    PolynomialFeatures\n",
    ")\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data importing and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anxiety = pd.read_csv('Anxiety.csv')\n",
    "df_ptsd = pd.read_csv('PTSD.csv')\n",
    "\n",
    "df_anxiety = df_anxiety.drop(columns = 'Unnamed: 0')\n",
    "df_ptsd.drop(columns = 'Unnamed: 0', inplace = True)\n",
    "\n",
    "df = pd.concat([df_ptsd,df_anxiety])\n",
    "df.reset_index(inplace = True)\n",
    "df.drop(columns = 'index', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20294, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'subreddit', 'selftext', 'title', 'created_utc', 'datetime'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create all text column for self text and title combined \n",
    "\n",
    "df['alltext'] = df['selftext'] + ' ' + df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create calculate length of text and title \n",
    "\n",
    "df['length_text'] = df['alltext'].map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create calculate status word cout of text and title \n",
    "tokenizer = RegexpTokenizer('\\s+', gaps=True)\n",
    "\n",
    "def tokenizer_func(text):\n",
    "    return len(tokenizer.tokenize(text))\n",
    "\n",
    "df['wrdcount_text'] = df['alltext'].apply(lambda x: tokenizer_func(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>datetime</th>\n",
       "      <th>alltext</th>\n",
       "      <th>length_text</th>\n",
       "      <th>wrdcount_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cuddlesnakes</td>\n",
       "      <td>ptsd</td>\n",
       "      <td>I'm super mad right now. I've finally managed to call one of the biggest organisations in countries that supports victims of pretty much any crime. \\nI've used their online counseling before cause it's easier to write than to talk, and because I was unsure if they even deal with the kind of violence I've experienced. The counselor said they do, and I should contact the local team for in depth cooperation. \\n\\n\\nTurns out, they don't. I've experienced the wrong kind of crime, the wrong kind of violence and there is no support system for me. Their website says that they don't compare or judge between victims of different crimes and support everyone. They fucking need to add a disclaimer with the exceptions. \\nThanks for nothing.</td>\n",
       "      <td>\"We're helping victims of any crime, but unfortunately you've experienced the wrong kind of crime\"</td>\n",
       "      <td>1648127141</td>\n",
       "      <td>2022-03-24 13:05:41</td>\n",
       "      <td>I'm super mad right now. I've finally managed to call one of the biggest organisations in countries that supports victims of pretty much any crime. \\nI've used their online counseling before cause it's easier to write than to talk, and because I was unsure if they even deal with the kind of violence I've experienced. The counselor said they do, and I should contact the local team for in depth cooperation. \\n\\n\\nTurns out, they don't. I've experienced the wrong kind of crime, the wrong kind of violence and there is no support system for me. Their website says that they don't compare or judge between victims of different crimes and support everyone. They fucking need to add a disclaimer with the exceptions. \\nThanks for nothing. \"We're helping victims of any crime, but unfortunately you've experienced the wrong kind of crime\"</td>\n",
       "      <td>830</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author subreddit  \\\n",
       "0  cuddlesnakes      ptsd   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           selftext  \\\n",
       "0  I'm super mad right now. I've finally managed to call one of the biggest organisations in countries that supports victims of pretty much any crime. \\nI've used their online counseling before cause it's easier to write than to talk, and because I was unsure if they even deal with the kind of violence I've experienced. The counselor said they do, and I should contact the local team for in depth cooperation. \\n\\n\\nTurns out, they don't. I've experienced the wrong kind of crime, the wrong kind of violence and there is no support system for me. Their website says that they don't compare or judge between victims of different crimes and support everyone. They fucking need to add a disclaimer with the exceptions. \\nThanks for nothing.   \n",
       "\n",
       "                                                                                                title  \\\n",
       "0  \"We're helping victims of any crime, but unfortunately you've experienced the wrong kind of crime\"   \n",
       "\n",
       "   created_utc             datetime  \\\n",
       "0   1648127141  2022-03-24 13:05:41   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               alltext  \\\n",
       "0  I'm super mad right now. I've finally managed to call one of the biggest organisations in countries that supports victims of pretty much any crime. \\nI've used their online counseling before cause it's easier to write than to talk, and because I was unsure if they even deal with the kind of violence I've experienced. The counselor said they do, and I should contact the local team for in depth cooperation. \\n\\n\\nTurns out, they don't. I've experienced the wrong kind of crime, the wrong kind of violence and there is no support system for me. Their website says that they don't compare or judge between victims of different crimes and support everyone. They fucking need to add a disclaimer with the exceptions. \\nThanks for nothing. \"We're helping victims of any crime, but unfortunately you've experienced the wrong kind of crime\"   \n",
       "\n",
       "   length_text  wrdcount_text  \n",
       "0          830            140  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to remove punctuation and remove \\n\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    punctuationfree = ' '.join([sentence for sentence in punctuationfree.split('\\n') if sentence != ''])\n",
    "    return punctuationfree\n",
    "\n",
    "df['clean_text'] = df['alltext'].apply(lambda x: x.lower())   \n",
    "df['clean_text']= df['clean_text'].apply(lambda x: remove_punctuation(x))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stop word list \n",
    "stopwordlist = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# to input in subreddit headers so that we can exclude it for model\n",
    "headers = ['ptsd', 'anxiety',\"cptsd\", 'trauma','traumatized','traumas',\"posttraumatic\",'stress','disorder',\"traumatic\",\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'doe', 'ha', 'might', 'must', \"n't\", 'need', 'sha', 'wa', 'wo', 'would']\n",
    "for head in headers:\n",
    "    stopwordlist.append(head)\n",
    "\n",
    "df['clean_text'] = df['clean_text'].apply(lambda x: ' '.join([i for i in x.split() if i not in stopwordlist]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>datetime</th>\n",
       "      <th>alltext</th>\n",
       "      <th>length_text</th>\n",
       "      <th>wrdcount_text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cuddlesnakes</td>\n",
       "      <td>ptsd</td>\n",
       "      <td>I'm super mad right now. I've finally managed to call one of the biggest organisations in countries that supports victims of pretty much any crime. \\nI've used their online counseling before cause it's easier to write than to talk, and because I was unsure if they even deal with the kind of violence I've experienced. The counselor said they do, and I should contact the local team for in depth cooperation. \\n\\n\\nTurns out, they don't. I've experienced the wrong kind of crime, the wrong kind of violence and there is no support system for me. Their website says that they don't compare or judge between victims of different crimes and support everyone. They fucking need to add a disclaimer with the exceptions. \\nThanks for nothing.</td>\n",
       "      <td>\"We're helping victims of any crime, but unfortunately you've experienced the wrong kind of crime\"</td>\n",
       "      <td>1648127141</td>\n",
       "      <td>2022-03-24 13:05:41</td>\n",
       "      <td>I'm super mad right now. I've finally managed to call one of the biggest organisations in countries that supports victims of pretty much any crime. \\nI've used their online counseling before cause it's easier to write than to talk, and because I was unsure if they even deal with the kind of violence I've experienced. The counselor said they do, and I should contact the local team for in depth cooperation. \\n\\n\\nTurns out, they don't. I've experienced the wrong kind of crime, the wrong kind of violence and there is no support system for me. Their website says that they don't compare or judge between victims of different crimes and support everyone. They fucking need to add a disclaimer with the exceptions. \\nThanks for nothing. \"We're helping victims of any crime, but unfortunately you've experienced the wrong kind of crime\"</td>\n",
       "      <td>830</td>\n",
       "      <td>140</td>\n",
       "      <td>im super mad right ive finally managed call one biggest organisations countries supports victims pretty much crime ive used online counseling cause easier write talk unsure even deal kind violence ive experienced counselor said contact local team depth cooperation turns dont ive experienced wrong kind crime wrong kind violence support system website says dont compare judge victims different crimes support everyone fucking add disclaimer exceptions thanks nothing helping victims crime unfortunately youve experienced wrong kind crime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author subreddit  \\\n",
       "0  cuddlesnakes      ptsd   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           selftext  \\\n",
       "0  I'm super mad right now. I've finally managed to call one of the biggest organisations in countries that supports victims of pretty much any crime. \\nI've used their online counseling before cause it's easier to write than to talk, and because I was unsure if they even deal with the kind of violence I've experienced. The counselor said they do, and I should contact the local team for in depth cooperation. \\n\\n\\nTurns out, they don't. I've experienced the wrong kind of crime, the wrong kind of violence and there is no support system for me. Their website says that they don't compare or judge between victims of different crimes and support everyone. They fucking need to add a disclaimer with the exceptions. \\nThanks for nothing.   \n",
       "\n",
       "                                                                                                title  \\\n",
       "0  \"We're helping victims of any crime, but unfortunately you've experienced the wrong kind of crime\"   \n",
       "\n",
       "   created_utc             datetime  \\\n",
       "0   1648127141  2022-03-24 13:05:41   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               alltext  \\\n",
       "0  I'm super mad right now. I've finally managed to call one of the biggest organisations in countries that supports victims of pretty much any crime. \\nI've used their online counseling before cause it's easier to write than to talk, and because I was unsure if they even deal with the kind of violence I've experienced. The counselor said they do, and I should contact the local team for in depth cooperation. \\n\\n\\nTurns out, they don't. I've experienced the wrong kind of crime, the wrong kind of violence and there is no support system for me. Their website says that they don't compare or judge between victims of different crimes and support everyone. They fucking need to add a disclaimer with the exceptions. \\nThanks for nothing. \"We're helping victims of any crime, but unfortunately you've experienced the wrong kind of crime\"   \n",
       "\n",
       "   length_text  wrdcount_text  \\\n",
       "0          830            140   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  clean_text  \n",
       "0  im super mad right ive finally managed call one biggest organisations countries supports victims pretty much crime ive used online counseling cause easier write talk unsure even deal kind violence ive experienced counselor said contact local team depth cooperation turns dont ive experienced wrong kind crime wrong kind violence support system website says dont compare judge victims different crimes support everyone fucking add disclaimer exceptions thanks nothing helping victims crime unfortunately youve experienced wrong kind crime  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>---Scotty---</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--A-lost-soul--</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--Eug--</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--Nature--</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-7hr0w4w4y-</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwitterion76</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zylonrave</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zynopsis61</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzfailureloser123</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzzzzbubbly</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13617 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   subreddit\n",
       "author                      \n",
       "---Scotty---               1\n",
       "--A-lost-soul--            1\n",
       "--Eug--                    1\n",
       "--Nature--                 1\n",
       "-7hr0w4w4y-                1\n",
       "...                      ...\n",
       "zwitterion76               1\n",
       "zylonrave                  1\n",
       "zynopsis61                 1\n",
       "zzfailureloser123          1\n",
       "zzzzzbubbly                6\n",
       "\n",
       "[13617 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new set of data frame that contains how many post per unique user \n",
    "\n",
    "unique_counts = df.groupby(['author']).count()[['subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>---Scotty---</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--A-lost-soul--</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--Eug--</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--Nature--</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-7hr0w4w4y-</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwitterion76</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zylonrave</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zynopsis61</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzfailureloser123</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzzzzbubbly</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13617 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   subreddit\n",
       "author                      \n",
       "---Scotty---               1\n",
       "--A-lost-soul--            1\n",
       "--Eug--                    1\n",
       "--Nature--                 1\n",
       "-7hr0w4w4y-                1\n",
       "...                      ...\n",
       "zwitterion76               1\n",
       "zylonrave                  1\n",
       "zynopsis61                 1\n",
       "zzfailureloser123          1\n",
       "zzzzzbubbly                6\n",
       "\n",
       "[13617 rows x 1 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(unique_counts, on = 'author').fillna(1)\n",
    "df.rename(columns = {'subreddit_x': 'subreddit', 'subreddit_y': 'ttl_post'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cuddlesnakes',\n",
       " 'vampyydemon',\n",
       " 'starlinamidnight',\n",
       " 'josephinabb123',\n",
       " 'BeautifulMind3000',\n",
       " 'Lee-Lemom',\n",
       " 'Dinosandnuggies',\n",
       " 'clusterheadachegal',\n",
       " 'IndependentVibes2214',\n",
       " 'AlwaysShip',\n",
       " 'No_Cut_3680',\n",
       " 'ThrowRAdeathcorefan',\n",
       " 'veryprettygood2020',\n",
       " 'minnieboss',\n",
       " 'aliendylan24',\n",
       " 'Jinxedes',\n",
       " 'litlittlecandle',\n",
       " 'Tony00237',\n",
       " 'BloomStarrwyn',\n",
       " 'Martymartysson',\n",
       " 'traegerundercover',\n",
       " 'just-curious62',\n",
       " 'qbtic',\n",
       " 'moxalerumpi',\n",
       " 'blondeariessun',\n",
       " 'sanpedro12',\n",
       " 'Economy-Stretch-1675',\n",
       " 'HeartlightKiss',\n",
       " 'captainkirk_lin_17',\n",
       " 'Blue00217',\n",
       " 'asinglearrow',\n",
       " 'palexsly123',\n",
       " 'Nidiocehai',\n",
       " 'SomeKind-Of-Username',\n",
       " 'what_the_duck29',\n",
       " 'thatsnotjade',\n",
       " 'Ordinary-Advantage22',\n",
       " 'mjobby',\n",
       " 'PureFud80',\n",
       " 'gracef1713',\n",
       " 'Ela25_',\n",
       " 'Low-Bit2048',\n",
       " 'n00b89_',\n",
       " 'Sweet-Help-3197',\n",
       " 'nloddis91',\n",
       " 'alfonzloren',\n",
       " 'vampiregucci',\n",
       " 'eccentricgalaxy',\n",
       " 'therat006',\n",
       " 'Starwarzmom',\n",
       " 'throwawayanon105',\n",
       " 'zoebells',\n",
       " 'Gibbygirl',\n",
       " 'Catpigwithwings',\n",
       " 'virtual_existence',\n",
       " 'pinkheartedrobe-xs',\n",
       " 'WillowEconomy2401',\n",
       " 'tanvib3',\n",
       " 'Unsainted22',\n",
       " 'sunfloras',\n",
       " 'hauntedhelium',\n",
       " 'chonbas',\n",
       " 'eixlix',\n",
       " 'incubussucubusll',\n",
       " 'MeduusaK',\n",
       " 'astroseedling',\n",
       " 'Mememachie',\n",
       " 'yagbblzv',\n",
       " 'Jaded_Sprinkles_6378',\n",
       " 'Background-Heat-5293',\n",
       " 'Middle_Ant_426',\n",
       " 'Anderz2',\n",
       " 'IvyPidge',\n",
       " 'MentalGrenade',\n",
       " 'Kizzzylil',\n",
       " 'NoSuspect3688',\n",
       " 'fuckedshittily',\n",
       " 'Glad_Engineering_479',\n",
       " 'domloveslife',\n",
       " 'yung_erik_',\n",
       " 'gregisntonline',\n",
       " 'ShotBarracuda6',\n",
       " 'nibiyabi',\n",
       " 'Unlikely-Ad949',\n",
       " 'dinakiii',\n",
       " 'mandajapanda',\n",
       " 'rmbrwhen',\n",
       " 'Quirky_Phase5960',\n",
       " 'JunketPast7729',\n",
       " 'mostadont',\n",
       " 'sixfeetbelow',\n",
       " 'Chronic_Trauma',\n",
       " 'ScoreImaginary',\n",
       " 'SeeSea8',\n",
       " 'Nymunariya',\n",
       " 'lil_vicks',\n",
       " 'Throwaway-Lemons-7',\n",
       " 'xDlolzor',\n",
       " 'studio28',\n",
       " 'SurvivingComplexPTSD',\n",
       " 'GatoBlanco_',\n",
       " 'Correct_Buddy2082',\n",
       " 'Heretolearn47',\n",
       " 'FrenziedMode',\n",
       " 'Bulky_Highlight_3352',\n",
       " 'Ok-Ferret-2093',\n",
       " 'StopAbusingAbusedPpl',\n",
       " 'AJ_Social',\n",
       " 'velvetnigh',\n",
       " 'avenixly',\n",
       " 'MentallyFucked127',\n",
       " 'bheesechurger777',\n",
       " 'bunmom3000',\n",
       " 'ResistAlternative',\n",
       " 'anogurl',\n",
       " 'Nervous-Bee-5134',\n",
       " 'sammyleepee94',\n",
       " 'ManicTypist',\n",
       " 'uglydumbidiot',\n",
       " 'MyCatIsInMyLap',\n",
       " 'IMWWW',\n",
       " 'wtfam1supposed2do',\n",
       " 'throw0OO0away',\n",
       " 'Opening_Rutabaga_569',\n",
       " 'Wendellmaximov',\n",
       " 'lil_smore',\n",
       " 'moxwantstogototexas',\n",
       " 'Debber10',\n",
       " 'Adventurous_Web_8901',\n",
       " 'locusthewolf',\n",
       " 'yammuyammu',\n",
       " 'cetiya',\n",
       " 'AidePast',\n",
       " 'dollsystemalt',\n",
       " 'Kitchen-Expression59',\n",
       " 'daphydoods',\n",
       " 'frijolepicante',\n",
       " 'Ok_District1230',\n",
       " 'rachelnessxo',\n",
       " 'SurvivalVet',\n",
       " 'tanktopped',\n",
       " 'HecateCorinne',\n",
       " 'Snapchthrowaway',\n",
       " 'HailstheLion',\n",
       " 'Throw11_11',\n",
       " 'Jaded_Still8757',\n",
       " 'sacocrapninja420',\n",
       " 'Cannibaliser',\n",
       " 'EastEntertainment947',\n",
       " '_Crashley_',\n",
       " 'madhatter42069',\n",
       " '__error',\n",
       " 'Injectingmyballs',\n",
       " 'damdums',\n",
       " 'Opening_Yoghurt2229',\n",
       " 'stabbyburgerman',\n",
       " 'Turb0toast',\n",
       " 'ArizonaDustBunny',\n",
       " 'fallen_leaves_99',\n",
       " 'BackStreetsBackPain',\n",
       " 'JigglyGelatin',\n",
       " 'ihatemakinguserna',\n",
       " 'lab_a_cat',\n",
       " 'ByeongHyeongLee',\n",
       " 'DirtyAngelToes',\n",
       " 'Naphthy',\n",
       " 'thatbeechz',\n",
       " 'antidoxthroway',\n",
       " 'AlreadyTakenNow',\n",
       " 'problematic_ferret',\n",
       " 'AbbreviationsHot5236',\n",
       " 'Moncalamaricruiser',\n",
       " 'Narcoleptic_Galaxy',\n",
       " 'Former-Ad-7561',\n",
       " 'SupermarketLazy8444',\n",
       " 'cheesesovereign',\n",
       " 'SaberSpyder',\n",
       " 'LovMachain',\n",
       " 'Sister-Sarah',\n",
       " 'Fair_Growth7335',\n",
       " 'CatsForMeh',\n",
       " 'muksnup',\n",
       " 'stayflyyy',\n",
       " 'phat79pat1985',\n",
       " 'pigeonboy_blues',\n",
       " 'imaginingfreedom',\n",
       " 'natigate',\n",
       " 'mundaneshow_25',\n",
       " 'Advanced_Door1259',\n",
       " 'bunnydigs',\n",
       " 'hallucinogenic_honey',\n",
       " 'Lilyflamingo1109',\n",
       " 'rock_angel_19',\n",
       " 'Aware-Inflation410',\n",
       " 'Weirdo_Saucey',\n",
       " 'nothigh__justkawaii',\n",
       " 'msbonnie0414',\n",
       " 'AgileLynx4109',\n",
       " 'dascott',\n",
       " 'zeme10',\n",
       " 'ChocCheesecake08',\n",
       " 'Hot_Objective_8239',\n",
       " 'w0nderfuI',\n",
       " 'sxndaygirl',\n",
       " 'diarrheaisnice',\n",
       " 'spacekwe3n',\n",
       " 'throwthewholemeaway-',\n",
       " 'olopithecus',\n",
       " 'Canuck_Voyageur',\n",
       " 'StinkerLove',\n",
       " 'arooes',\n",
       " 'faerieonwheels',\n",
       " 'approaching-infinity',\n",
       " 'smokmjohnny',\n",
       " 'Repulsive_Apricot974',\n",
       " 'ohnoitsmckenzie',\n",
       " 'Vix011',\n",
       " 'OllieCad',\n",
       " 'if-and-but',\n",
       " 'Guitarbox',\n",
       " 'FlamingoStrange8386',\n",
       " 'pepperep',\n",
       " 'fermentedyellow',\n",
       " 'Josh48111',\n",
       " 'ashashergill',\n",
       " 'Lyndis-of-Pherae',\n",
       " 'WarPigs02',\n",
       " 'Adorable_Muscle_1774',\n",
       " 'little_tat',\n",
       " 'heartlckt',\n",
       " 'gnikayam',\n",
       " 'PurpIeDemon',\n",
       " 'intjonsteroids',\n",
       " 'BrotherTyron',\n",
       " 'not_a_throwaway64',\n",
       " '50Bullseye',\n",
       " 'Winter-Mammoth1',\n",
       " 'atomglimpse',\n",
       " 'babybrotherdrama',\n",
       " 'Kalensia',\n",
       " 'R3Tr0tt',\n",
       " 'Pastel-Demon1423',\n",
       " 'thewalkingbed010',\n",
       " 'parsteel',\n",
       " 'Realpcdly',\n",
       " 'Orphanedsweet',\n",
       " 'Federal-Guava-2326',\n",
       " 'lilmisstiny5',\n",
       " 'UltraRunner97',\n",
       " '-_NightKnight_-',\n",
       " 'PoeticPuddles',\n",
       " 'ahauntedsnickersbar',\n",
       " 'Immediate_Home_4926',\n",
       " 'julezz30',\n",
       " 'The_alchemist667',\n",
       " 'hyruleans',\n",
       " 'Leanacupcake',\n",
       " 'Unfair-Big-2663',\n",
       " 'BamSlamThankYouSir',\n",
       " 'Justarandombookworm',\n",
       " 'Affectionate_Hat494',\n",
       " 'ZealousidealAnt8600',\n",
       " 'anonymous_24601',\n",
       " 'Kapri22',\n",
       " 'ExchangePowerful3225',\n",
       " 'Heavy_Dawn',\n",
       " 'skywriter90',\n",
       " 'Detectves',\n",
       " 'Clear_Radio1776',\n",
       " 'graveyardlamb',\n",
       " 'Cherribomb',\n",
       " '6anxiety9',\n",
       " 'nuclear_blender',\n",
       " 'minsuni',\n",
       " 'decepticon_artist',\n",
       " 'rosa1347',\n",
       " 'ffantomize',\n",
       " 'Which_Night_5210',\n",
       " 'Lostmaybelonely',\n",
       " 'advilglasses',\n",
       " 'sophieprichard',\n",
       " 'cokeman234',\n",
       " 'somethngsomewhere',\n",
       " 'Ok_Register9361',\n",
       " 'maybeitsbees',\n",
       " 'alittletootired13',\n",
       " 'Ne3dT0B3Sk1nny55',\n",
       " 'throwaway348933',\n",
       " 'TheLastMcfuckinYeet',\n",
       " 'rcreporter',\n",
       " 'AShadeOfNormal',\n",
       " 'ig0t_somprobloms',\n",
       " 'daz3d-n-c0nfus3d',\n",
       " 'jkvf1026',\n",
       " 'Heinrich_Bluecher',\n",
       " 'lilsnaxxus',\n",
       " 'SnooEagles2991',\n",
       " 'Kat82292',\n",
       " 'mrmeowmeowington',\n",
       " 'Serious_Unit_4118',\n",
       " 'strudeltoastie',\n",
       " 'Betty-White-666',\n",
       " 'wisteria_tea',\n",
       " 'Beautiful_Crab_7979',\n",
       " 'pete280693',\n",
       " 'fuckmeuntilicecream',\n",
       " '_-Ally-_',\n",
       " 'sxmdxmhxe',\n",
       " 'CodGroundbreaking854',\n",
       " 'ncorlch99',\n",
       " 'islandsxy45',\n",
       " 'AdWeird6452',\n",
       " '2fy54gh6',\n",
       " 'icanseeshampoo',\n",
       " 'Healthy_Bookkeeper38',\n",
       " 'anothxrthrowawayacc',\n",
       " 'Much-Ranger1422',\n",
       " 'compartmentelisa',\n",
       " 'Pleasehelp793',\n",
       " 'Cunninglingmiss',\n",
       " 'Ethereal_Sundrop',\n",
       " 'vaporwave_vibes',\n",
       " 'BSBfan1994',\n",
       " 'StripperThatReads',\n",
       " 'LetisLipstick',\n",
       " 'acatcalledmellow',\n",
       " 'majetikmouse',\n",
       " 'dooombug',\n",
       " 'Miserable-Term-2932',\n",
       " 'p4pp13z',\n",
       " 'sunny200123',\n",
       " 'Andandromeda3821',\n",
       " 'Malkozaine',\n",
       " 'Rodneybasher',\n",
       " 'no-maincharacter',\n",
       " 'Other_Taro_3806',\n",
       " '_GenderNotFound',\n",
       " 'Dandunndunnnn',\n",
       " 'Diane1967',\n",
       " 'Grimm-psychology',\n",
       " 'flowercrown_909_uwu',\n",
       " 'smotheredwithemotion',\n",
       " 'Wrong-Employee-9369',\n",
       " 'mariposa__6',\n",
       " 'ScratchThatIGotThis',\n",
       " 'Specific_Taro_156',\n",
       " 'taoshka',\n",
       " 'CaptainBackwoods420',\n",
       " 'here4budz',\n",
       " 'butterfly0848',\n",
       " 'Barbystreisand',\n",
       " 'Another-just-person',\n",
       " 'PagingDrDouchebag',\n",
       " 'Due_Championship_372',\n",
       " 'Conscious-Forever-66',\n",
       " 'CaneVeritas',\n",
       " 'synthswing',\n",
       " 'sad_g1rl_m4d_g1rl',\n",
       " 'Ok_Raspberry_9911',\n",
       " 'Ancient_Effective552',\n",
       " 'BagofFriddos',\n",
       " 'heximintii',\n",
       " 'myceliummadness420',\n",
       " 'numbshame',\n",
       " 'PhantomVessel',\n",
       " 'cutemuffin98654',\n",
       " 'Tyler22A1',\n",
       " 'Lamingtonluv',\n",
       " 'RandyTailpipe',\n",
       " 'kompot-od-marelice',\n",
       " 'frogge_hugsx',\n",
       " 'alphsig55',\n",
       " 'Gay-and-Happy',\n",
       " 'KriitaRhythms',\n",
       " 'hungryseabear',\n",
       " 'IllustratorOrnery238',\n",
       " 'hellokitty997',\n",
       " 'Professional_Toe_755',\n",
       " 'Plenty-Attempt7083',\n",
       " 'galabija',\n",
       " 'rosymaplewitch',\n",
       " 'IllAd5333',\n",
       " 'Ninja_Vagabond',\n",
       " 'all_things_bar',\n",
       " '_Oflh_hb',\n",
       " 'A_Body_In_Motion',\n",
       " 'tiredbarista61937',\n",
       " 'anoninturmoil5',\n",
       " 'Willing_2_behave-85',\n",
       " 'darbydiddle',\n",
       " 'Mean-Bend4286',\n",
       " 'strokes_your_nose',\n",
       " 'TheBigBadBrit89',\n",
       " 'Automatic-Alarm2612',\n",
       " 'Bitter_Researcher759',\n",
       " 'Beansidhe0',\n",
       " 'InuKamiNee',\n",
       " 'zzzzzbubbly',\n",
       " 'MattPilkerson',\n",
       " 'Ungrateful_Verb',\n",
       " 'Piiiickle_Riiiick',\n",
       " 'butcherstwine',\n",
       " 'brokenstagelight',\n",
       " 'greencats45',\n",
       " 'FakePrsonMdeofSqrrls',\n",
       " 'LordChapman23',\n",
       " 'claustrophobic_betta',\n",
       " 'BeeTHC',\n",
       " 'Electrical_Store_907',\n",
       " 'SignificantPrescence',\n",
       " 'helloptret',\n",
       " 'samir2603',\n",
       " 'TAantiwork',\n",
       " '-d-e-d-',\n",
       " 'n_o_t_r_o_M_M_i_s_s',\n",
       " 'macabreroses',\n",
       " 'APVS2',\n",
       " 'vibeux420',\n",
       " 'MikeOxHuge',\n",
       " 'eve_ecc',\n",
       " 'a2z91',\n",
       " 'feverfew2',\n",
       " 'blondynka377',\n",
       " 'http_cake',\n",
       " 'lilfifi',\n",
       " 'Negative_Judge9823',\n",
       " 'jimmylovesads',\n",
       " 'sunnygoodbye',\n",
       " 'Feed_Ashamed',\n",
       " 'incubabes',\n",
       " 'nonameadultperson',\n",
       " 'esbiano',\n",
       " 'WeirdDude_95',\n",
       " 'StumpyStumpkinton',\n",
       " 'CardiologistActual83',\n",
       " 'ranonymous7',\n",
       " 'Nadayogi',\n",
       " 'Temporary-Range-3839',\n",
       " 'Z3ro_Zer0',\n",
       " 'syberburns',\n",
       " 'dumbassneetgirl',\n",
       " 'Hammertime2938',\n",
       " 'csosiaeq',\n",
       " 'GodlyPumpkin',\n",
       " 'TsotyliBoi',\n",
       " 'Goldenwolf_',\n",
       " 'sweetechoes2008',\n",
       " 'bananas_crazy',\n",
       " 'Forestfernweh',\n",
       " 'Xchela1195',\n",
       " 'elatele',\n",
       " 'DefiantCup8149',\n",
       " 'TexasTiger70',\n",
       " 'RudeChicken445n',\n",
       " 'robgoboomboom',\n",
       " 'snildeep',\n",
       " 'Tea_and_sugar',\n",
       " 'Careful_Trouble_1059',\n",
       " 'FluidUnderstanding40',\n",
       " 'Vandsaz',\n",
       " 'lezwearbeanies',\n",
       " 'alienmanik',\n",
       " 'GoodInt3ntions',\n",
       " 'PlasticFlower90',\n",
       " 'Unlikely-Echo-9879',\n",
       " 'sweet_billy_pilgrim',\n",
       " 'Gr4vitysouth',\n",
       " 'jkelley223',\n",
       " 'tobecontinued89',\n",
       " 'StukelyT7',\n",
       " 'Illustrious_Golf_452',\n",
       " 'rosytoesies3',\n",
       " 'Excellent_Visit_527',\n",
       " 'pantsareweird',\n",
       " 'More-Low8697',\n",
       " 'BettyY1',\n",
       " 'luujunk',\n",
       " 'Artistic_Fee_1285',\n",
       " '-anxious',\n",
       " 'ducdePuce2',\n",
       " 'praxeologue',\n",
       " 'Robotmaiden',\n",
       " 'Probablyidkthough',\n",
       " 'FoxyFreckles1989',\n",
       " 'frottingotter',\n",
       " 'helloitschelsea',\n",
       " 'throwaway7854309',\n",
       " 'Lonely_Record3544',\n",
       " 'Haandbaag',\n",
       " 'SmallTownRunna',\n",
       " 'IronicHoodies',\n",
       " 'Kathrynrachelwilson',\n",
       " 'punkboy198',\n",
       " 'NocturnalTwitch',\n",
       " 'Witty_Bid9860',\n",
       " 'Loiter_er',\n",
       " 'heartmadeofbrass',\n",
       " 'Indecisive-V',\n",
       " 'no_manufacture1',\n",
       " 'spiritlinktracks',\n",
       " 'gautamayu',\n",
       " 'dharmachaser',\n",
       " 'LancelotTheBrave',\n",
       " 'taylorcorbean',\n",
       " 'ImaginationStrong905',\n",
       " 'Katekat0974',\n",
       " 'd3finitelynotmo',\n",
       " 'papricot',\n",
       " 'sappy__',\n",
       " 'khshkhs',\n",
       " 'Professional-Bee-137',\n",
       " 'justsomeA1C',\n",
       " 'Horst0815',\n",
       " 'petrolsiphon',\n",
       " 'CryingAlice463663',\n",
       " 'Shina93',\n",
       " 'GambleaDict',\n",
       " 'tastysoil',\n",
       " 'JaneChlo',\n",
       " 'sssoitgoes',\n",
       " 'Sugmasendrome',\n",
       " 'Xstarkbutt',\n",
       " 'eruditecow',\n",
       " 'salamipope',\n",
       " 'Fresyes7734',\n",
       " 'GainHealthy4744',\n",
       " 'SnooPeripherals3206',\n",
       " 'idkreddituser11',\n",
       " 'scatterbrainjane3547',\n",
       " 'Obvious_Web_8785',\n",
       " 'sapphiccx',\n",
       " 'MalaFuryBringer',\n",
       " 'disposable_999',\n",
       " 'IntelligentString961',\n",
       " 'oshunofoceans',\n",
       " 'quadruple_b',\n",
       " 'Altrustic-Dictator',\n",
       " 'pizzagoblin69',\n",
       " '10SneksInATrenchcoat',\n",
       " 'Ornery_Monk_7014',\n",
       " 'fish-with-arms',\n",
       " 'MegavirusOfDoom',\n",
       " 'Mesmer115',\n",
       " 'kmanzzz',\n",
       " 'Calm-Communication55',\n",
       " 'Bostongirlgreenwood',\n",
       " 'Sharpshooter09475',\n",
       " 'LilyWolf32',\n",
       " 'damianED',\n",
       " 'krazykakes262',\n",
       " 'AviatorPrints',\n",
       " 'admittedhaunted',\n",
       " 'These-Mycologist-126',\n",
       " 'FeedOk2725',\n",
       " 'enoshimakuro',\n",
       " 'Slyke4',\n",
       " 'Embarrassed-Place454',\n",
       " 'Zephyrinx',\n",
       " 'moedooboebee',\n",
       " 'Cgreening',\n",
       " 'Status_Wolf4604',\n",
       " 'InvestigatorRude472',\n",
       " 'ResponsibleLaw0',\n",
       " 'Abda1972',\n",
       " 'disco-vorcha',\n",
       " 'meelah16',\n",
       " 'delta2111',\n",
       " 'Celtic_King_LovesPi',\n",
       " 'AshtonRX',\n",
       " 'Lemon_lgbtq',\n",
       " 'jalezvilla',\n",
       " 'TalkaboutJoudy',\n",
       " 'Biskibis',\n",
       " 'RedbirdAnon',\n",
       " 'DanDeMarbre',\n",
       " 'shabaluv',\n",
       " 'AeitherMitBunnies',\n",
       " 'neilkj1993',\n",
       " 'deadenergizerbunny',\n",
       " 'InvictusAnima',\n",
       " 'bellsbarista',\n",
       " 'Past-Organization-14',\n",
       " 'Schizo_Spooks',\n",
       " 'bigmisssteak7',\n",
       " 'veryanxiousopossum',\n",
       " 'GrillBabey',\n",
       " 'jsbnwf',\n",
       " 'neonturtle69420',\n",
       " 'Educational_Sort9545',\n",
       " 'Pleasant_Meat503',\n",
       " 'Fit-Aspect7372',\n",
       " 'Laurel2000SGX',\n",
       " 'TGSGOfficial',\n",
       " 'bighappychappy',\n",
       " 'ravenlenxre',\n",
       " 'holographicGargoyle',\n",
       " 'RosyTeaLad',\n",
       " 'lexxandar',\n",
       " 'Hypeman111',\n",
       " 'ColorfulFlowers',\n",
       " 'shawam812',\n",
       " 'felledby',\n",
       " 'ediwankenobi',\n",
       " 'NaisTrappd',\n",
       " 'Complex-Place',\n",
       " 'pizzaeater246810',\n",
       " 'Fun-Drop-7589',\n",
       " 'nnthrowaway333',\n",
       " 'Vipassana1',\n",
       " '600-shot-of-autism',\n",
       " 'Affectionate-Bad105',\n",
       " 'Flameworkingraccoon',\n",
       " 'disappointingtent',\n",
       " 'MedicMalfunction',\n",
       " 'ripped_masterpiece',\n",
       " 'kaitlinrs',\n",
       " 'Technical-Paper1697',\n",
       " 'narcoleptic64',\n",
       " 'Any_add',\n",
       " 'Available_Fun_5039',\n",
       " 'nodnizzle',\n",
       " 'bighugecumsinmypussy',\n",
       " 'Beware_my_presents',\n",
       " 'am219810',\n",
       " 'lizlemonesq',\n",
       " 'NipplelessWoman',\n",
       " 'trainchoou',\n",
       " 'wallpapersdance',\n",
       " 'T-Bone_Dynasty',\n",
       " 'Casual_Shroom',\n",
       " 'Rare-Ad-6448',\n",
       " 'Grid1992',\n",
       " 'Psychological-Sale64',\n",
       " 'sombody_el-se',\n",
       " 'CatsGamesMemes',\n",
       " 'thisusernameexists_',\n",
       " 'GladPen',\n",
       " 'sarcast1cartist',\n",
       " 'SolomaniX',\n",
       " 'arospikefuckery',\n",
       " 'anonymousrisktaker',\n",
       " 'CryptographerNo1882',\n",
       " 'LizzyLeonhart',\n",
       " 'Puzzleheaded_Hotel76',\n",
       " 'PeakRepresentative92',\n",
       " '_spaceguy-_-',\n",
       " 'Inevitable_Contest31',\n",
       " 'Sammydean-20',\n",
       " 'melaniatraamp',\n",
       " 'brakeupzsuckz',\n",
       " 'luvly_v',\n",
       " 'aggelosbill',\n",
       " 'alwaysintosomethin',\n",
       " 'Perfection_in_pink',\n",
       " 'kinky-winky-achoo',\n",
       " 'tridentcommercial',\n",
       " 'mytoeitchesalot',\n",
       " 'etetries',\n",
       " 'TraceNoPlace',\n",
       " 'AdministrationFast59',\n",
       " 'whitleytrillbert',\n",
       " 'Psychward_unit',\n",
       " 'IncomeNatural8178',\n",
       " 'Inside-Wonder-5761',\n",
       " 'Let_them_eat_Kayke',\n",
       " 'Crochetcreature',\n",
       " 'VeryMentallyStable',\n",
       " 'Ysarde',\n",
       " 'Misssticks04',\n",
       " 'AutumnPhenixArts',\n",
       " 'arimione',\n",
       " 'cats119',\n",
       " 'DeathAngel-X',\n",
       " 'sewingdreamer',\n",
       " 'Coffee_In_Nebula',\n",
       " 'HiItsOjjO',\n",
       " 'womaninsideme',\n",
       " 'laracynara',\n",
       " 'sunny278',\n",
       " 'caobartw',\n",
       " 'canigetabottle',\n",
       " 'my_crazy_spunky',\n",
       " 'UnnamedPictureShow',\n",
       " 'MrJingles333333333',\n",
       " 'R_we_done_yet',\n",
       " 'spectrum_whale',\n",
       " '_Fauna_',\n",
       " '19NotMe73',\n",
       " 'space_cowgirl_lily',\n",
       " 'chloenickole',\n",
       " 'archaicdesires',\n",
       " 'mpearce10',\n",
       " 'PairPrestigious7452',\n",
       " 'ClassDimissed',\n",
       " 'fatdachshund27',\n",
       " 'c0dette',\n",
       " 'Ecstatic_Policy_1569',\n",
       " 'saryl',\n",
       " 'RealStrangerDanger',\n",
       " 'xesnuts',\n",
       " 'JasminePanda',\n",
       " 'Prestigious_Lie9820',\n",
       " 'heytherekay',\n",
       " 'snakeflip',\n",
       " 'Wise_Bug7172',\n",
       " 'simplyaless',\n",
       " 'Neanderthal888',\n",
       " 'professorkmusic',\n",
       " 'Alaska-Alan-11',\n",
       " 'icoulntthink',\n",
       " 'Learning2thrive',\n",
       " 'sourcherry666',\n",
       " 'throwaway293922393',\n",
       " 'beemuncherx',\n",
       " 'Lime_Tree_Ghost',\n",
       " 'BiJonesy',\n",
       " 'throwaway9999-22222',\n",
       " 'Comfortable-Map-6287',\n",
       " 'quora2211',\n",
       " 'kccinsomniac',\n",
       " 'Tessluv',\n",
       " 'epinomyg',\n",
       " 'Confident-Machine199',\n",
       " 'Puzzleheaded_Lie_968',\n",
       " 'rodrigo34891',\n",
       " 'hopeless_romantic19',\n",
       " 'ridingcropbandit',\n",
       " 'BlueJaySan',\n",
       " 'Real-Analysis7496',\n",
       " 'JUSTKIDDING205',\n",
       " 'postitqueen84',\n",
       " 'PoorClassWarRoom',\n",
       " 'sushirole1212',\n",
       " 'RadSpatula',\n",
       " 'catnip666420',\n",
       " 'Leovlish3re',\n",
       " 'Necessary_Sleep4596',\n",
       " 'SafeMarzipan406',\n",
       " 'chalky87',\n",
       " 'opps0000',\n",
       " 'Lady-Shipp',\n",
       " 'Numerous-Tough4599',\n",
       " 'chronicheartache',\n",
       " 'Throwaway737387373',\n",
       " 'lost_in_space54',\n",
       " 'thattherian',\n",
       " 'jediment',\n",
       " 'Stewy_434',\n",
       " 'Aubaleina',\n",
       " 'Disastrous_Froyo2398',\n",
       " 'TheRottedBitch',\n",
       " 'IntegralGuideAuthor',\n",
       " 'WIboiforyou',\n",
       " 'Occaligirl73',\n",
       " 'joooliea',\n",
       " 'Toasty-p0tatO',\n",
       " 'Momoftwosweeties',\n",
       " 'ForMyLAHoes',\n",
       " 'flute_sarah123',\n",
       " 'soot-newt',\n",
       " 'Natural_Empath',\n",
       " 'arthritic_cricket',\n",
       " 'Delicious_Standard_8',\n",
       " 'MyHolofractalLife',\n",
       " 'uganda-unlucki',\n",
       " 'Natural_Zebra_866',\n",
       " 'Downtown_Name_4896',\n",
       " 'pinkjuless',\n",
       " 'RapidCorrus',\n",
       " 'meldiwin',\n",
       " 'meladey',\n",
       " 'citrusbanananana',\n",
       " 'Zealousideal-Cake509',\n",
       " 'ZeroTolerance07762',\n",
       " 'juno_october',\n",
       " 'chaotic-tempo',\n",
       " 'Individual_Note_4922',\n",
       " 'Whole-Implement-3019',\n",
       " 'International-Roll27',\n",
       " 'SnooOnions8429',\n",
       " 'asteriskelipses',\n",
       " 'carlotakerry',\n",
       " 'throwawayforventing6',\n",
       " 'CinnamonrollMile',\n",
       " 'blehblo',\n",
       " 'raduh5777',\n",
       " 'psb_fwb',\n",
       " 'dance2mystery',\n",
       " 'PM_about_discipline',\n",
       " 'catsinbananahats',\n",
       " 'hungryandlooking',\n",
       " 'Siberiayuki',\n",
       " 'RedGruu',\n",
       " 'ManySource6997',\n",
       " 'Herovsevil11',\n",
       " 'C0ffeeCoffeeC0ffee',\n",
       " 'denizsd',\n",
       " 'recoupest',\n",
       " 'Few_Time_8754',\n",
       " 'merferrets',\n",
       " 'Yeethawbiotches',\n",
       " 'DingusChrist',\n",
       " 'JCV-16',\n",
       " 'ZZ_Raven_25',\n",
       " 'clairelecric',\n",
       " 'fictitiousfemale',\n",
       " 'Ray3369',\n",
       " 'Sea_Marionberry1034',\n",
       " 'Noah_is_Trash',\n",
       " 'smallzreddit',\n",
       " 'Ghost_Chance',\n",
       " 'CorgiCoffeeBeccaroo',\n",
       " 'stonedandhydrated',\n",
       " 'AccurateConfection1',\n",
       " 'angel_wave',\n",
       " 'VesuviusZee',\n",
       " 'maggiec2727',\n",
       " 'wowzaps',\n",
       " 'MadNoodlez',\n",
       " 'Pixie_Lizard',\n",
       " 'dramatikstesolid',\n",
       " 'yeetyeetmybeepbeep',\n",
       " 'Arronh4599',\n",
       " 'Orangeesquee',\n",
       " 'littlewitch1990',\n",
       " 'Chris_Bag',\n",
       " 'sugarJackal',\n",
       " 'relativelyrelative1',\n",
       " 'najaqplc',\n",
       " 'Definitely-Daisy',\n",
       " 'FunBoE',\n",
       " '04butch',\n",
       " 'Unlucky-Set-6781',\n",
       " 'Few_Mycologist_4666',\n",
       " 'ennsam77',\n",
       " 'eskkrima',\n",
       " 'Upper-Set6026',\n",
       " 'ricks35',\n",
       " 'theresanelephant444',\n",
       " 'Loanloner',\n",
       " 'IGotWeirdTalents',\n",
       " 'usosexibitch',\n",
       " 'wontonn_soup',\n",
       " 'Wistful_Yellowtail',\n",
       " 'Odd-Car8112',\n",
       " 'GrimRapture',\n",
       " 'Teatookle',\n",
       " 'Melodic-Valuable-440',\n",
       " 'Agreeable-Mud2607',\n",
       " 'bluefox_in_glasses',\n",
       " 'throwalanon',\n",
       " 'Tomoe_Tomioka',\n",
       " 'PatrickStarsAF',\n",
       " 'disamorforming',\n",
       " 'Fair-Prior-8664',\n",
       " 'Throwawaydbjejekekej',\n",
       " 'cooperdupa',\n",
       " 'AzraelReturns',\n",
       " 'MissyMiyake',\n",
       " 'Koalaluvs',\n",
       " 'thatonedik3',\n",
       " 'wookie-bowcaster',\n",
       " 'bigtimechicagoaccent',\n",
       " 'Top-Effective3617',\n",
       " 'AfraidEngine6729',\n",
       " 'caffinatee',\n",
       " 'SmartAd9380',\n",
       " 'Survivor451',\n",
       " 'Justme0207',\n",
       " 'Worms_gone_wild',\n",
       " 'Iammydiagnosis2005',\n",
       " 'earl_grey_tea99',\n",
       " 'Pingugoesnootnoot1',\n",
       " 'Tasty-Memory-6099',\n",
       " 'fyhxgjydgbvxdfgbvnku',\n",
       " 'haveyouseenmysnail',\n",
       " 'ZealousidealCow8680',\n",
       " 'johannsen3',\n",
       " 'seishinfuantei',\n",
       " 'jessiethehutt',\n",
       " 'yeah_no_obviously',\n",
       " 'twabtahc',\n",
       " 'MeandThorne',\n",
       " 'Tiictoks',\n",
       " 'Sparabic17',\n",
       " 'Kilo_G_looked_up',\n",
       " 'No_Decision9022',\n",
       " 'Rantingsister',\n",
       " 'Homicidal_Ideation88',\n",
       " 'RealSimonLee',\n",
       " 'hassidk',\n",
       " 'arder96',\n",
       " 'Cthothlu',\n",
       " 'lalalalalandforever',\n",
       " 'Due-Tear-2798',\n",
       " 'MellorineMoments',\n",
       " 'space-kardi',\n",
       " 'anonventing',\n",
       " 'OkHabit3',\n",
       " 'Relevant-Extreme9101',\n",
       " 'tardyaaron14',\n",
       " 'Zealousideal_Desk100',\n",
       " 'VisualBicycle8473',\n",
       " 'theunknownhurts',\n",
       " 'can3689',\n",
       " 'Grey_Balance',\n",
       " 'creeping_ninja',\n",
       " 'UniqueParade',\n",
       " '9_9Aurora9_9',\n",
       " 'a_s_h_1_y_n',\n",
       " 'Ok-Literature-1173',\n",
       " 'AccidentalOverload',\n",
       " 'NewEstablishment1870',\n",
       " 'SonicDeathMareczku',\n",
       " 'huffingtontoast',\n",
       " 'numbandcloudy',\n",
       " 'XSarahmlx',\n",
       " 'blahblahblahplaydoh',\n",
       " 'JazziestCabbage',\n",
       " 'ReallyBadBacon',\n",
       " 'loju1154',\n",
       " 'iaobd',\n",
       " 'MoxViolatesTheNFA',\n",
       " 'SerenityMcC',\n",
       " 'Alarmed-Dig-1639',\n",
       " 'Thenascarguy2017',\n",
       " 'mothbaabe',\n",
       " 'Foreign-Inflation683',\n",
       " 'PeteyZee1998',\n",
       " 'Busy-Friend1072',\n",
       " 'vanessasmymiddlename',\n",
       " 'postraumata',\n",
       " 'ducks-laughing',\n",
       " 'WaterEater444',\n",
       " 'boogaloey',\n",
       " 'missregretful',\n",
       " 'mysteriam',\n",
       " 'dontpmmetoes',\n",
       " 'ReniMenee',\n",
       " 'foxterlight',\n",
       " 'sg1256',\n",
       " 'allendrea130',\n",
       " 'Allisonrosex',\n",
       " 'pizzapicnic',\n",
       " 'DareToBeDefiant',\n",
       " 'TheFlamingTiger777',\n",
       " 'CuriousRelish',\n",
       " 'littledumpsterfire69',\n",
       " 'Myrmor',\n",
       " 'maddie6ix9ineeeeeeee',\n",
       " 'lightblackmagicwoman',\n",
       " 'Spiritual_TreeHugger',\n",
       " 'norashepard',\n",
       " 'Bubulubuenabb',\n",
       " 'Interesting_Rich7393',\n",
       " 'flyinghigh92',\n",
       " 'aresALT',\n",
       " 'W3dn3sdaysChild',\n",
       " 'Code-x1',\n",
       " 'Apprehensive-Car-602',\n",
       " 'FennecsFox',\n",
       " 'kayhxp',\n",
       " 'LaLucertola',\n",
       " 'Foureyelaureye',\n",
       " 'Snoo97890',\n",
       " 'estelanova',\n",
       " 'Bobamilktea0',\n",
       " 'DifficultProject2835',\n",
       " 'psyhcopig',\n",
       " 'EvilDuck91',\n",
       " 'Anna-Jackson00',\n",
       " 'jdjdkdnewnwb',\n",
       " 'idk678678',\n",
       " 'umbrella_boy',\n",
       " 'i_am_soap-',\n",
       " 'god-fuck-owch',\n",
       " 'orochimemelords',\n",
       " 'KN-KYU',\n",
       " 'lilmdma',\n",
       " 'Djjshebdhudjbsw',\n",
       " 'turntraumaintacomedy',\n",
       " 'memeaddicted00',\n",
       " 'PsychologicalSafe709',\n",
       " 'Top-Computer3690',\n",
       " 'Every-Moose-8567',\n",
       " 'spagggh',\n",
       " 'horsehockey64',\n",
       " 'Annihilated56',\n",
       " 'Material_Profit8262',\n",
       " 'AwkwardJibs',\n",
       " 'SpecialShift3159',\n",
       " 'Acceptable_Gas8861',\n",
       " 'Hazama_Kirara',\n",
       " 'orphanbigfoot',\n",
       " 'swolf962',\n",
       " 'Ok-Bug3499',\n",
       " 'DoctorWolfpaw',\n",
       " 'Iamrabbit25',\n",
       " 'MagicDog1234',\n",
       " 'kissmegirl-im-a-dyke',\n",
       " ...]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['author'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit\n",
       "Anxiety    3.431425\n",
       "ptsd       4.885982\n",
       "Name: ttl_post, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['subreddit'])['ttl_post'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'ptsd',\n",
       " 'anxiety',\n",
       " 'cptsd',\n",
       " 'trauma',\n",
       " 'traumatized',\n",
       " 'traumas',\n",
       " 'posttraumatic',\n",
       " 'stress',\n",
       " 'disorder',\n",
       " 'traumatic',\n",
       " \"'d\",\n",
       " \"'ll\",\n",
       " \"'re\",\n",
       " \"'s\",\n",
       " \"'ve\",\n",
       " 'could',\n",
       " 'doe',\n",
       " 'ha',\n",
       " 'might',\n",
       " 'must',\n",
       " \"n't\",\n",
       " 'need',\n",
       " 'sha',\n",
       " 'wa',\n",
       " 'wo',\n",
       " 'would',\n",
       " 'abov',\n",
       " 'ani',\n",
       " 'anxieti',\n",
       " 'becaus',\n",
       " 'befor',\n",
       " 'disord',\n",
       " 'dure',\n",
       " 'hi',\n",
       " 'onc',\n",
       " 'onli',\n",
       " 'ourselv',\n",
       " 'posttraumat',\n",
       " 'themselv',\n",
       " 'thi',\n",
       " 'traumat',\n",
       " 'veri',\n",
       " 'whi',\n",
       " 'yourselv',\n",
       " 'becau']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create stop word list \n",
    "stopwordlist = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# to input in subreddit headers so that we can exclude it for model\n",
    "headers = ['ptsd', 'anxiety',\"cptsd\", 'trauma','traumatized','traumas',\"posttraumatic\",'stress','disorder',\"traumatic\",\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'doe', 'ha', 'might', 'must', \"n't\", 'need', 'sha', 'wa', 'wo', 'would']\n",
    "for head in headers:\n",
    "    stopwordlist.append(head)\n",
    "\n",
    "\n",
    "# Add additional list from stemmed words \n",
    "\n",
    "stemmed_data = ['abov', 'ani', 'anxieti', 'becaus', 'befor', 'disord', 'dure', 'hi', 'onc', 'onli', 'ourselv', 'posttraumat', 'themselv', 'thi', 'traumat', 'veri', 'whi', 'yourselv', 'becau']\n",
    "for stem in stemmed_data:\n",
    "    stopwordlist.append(stem)\n",
    "\n",
    "stopwordlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>datetime</th>\n",
       "      <th>LengthOf_selftext</th>\n",
       "      <th>LengthOf_title</th>\n",
       "      <th>WrdCnt_selftext</th>\n",
       "      <th>WrdCnt_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>So, I was on tick-tock and a therapist was talking about healing PTSD and I don't know if it's my night shift brain but I thought I kinda had PTSD forever now? Like.yeah.i can learn to love with it but I wouldn't class that as healing it? Idek I'm confused and sleepy sorry for the ramble!</td>\n",
       "      <td>Can PTSD be healed?</td>\n",
       "      <td>1647751986</td>\n",
       "      <td>2022-03-20 04:53:06</td>\n",
       "      <td>289</td>\n",
       "      <td>19</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>I just need to share this and my feelings about it somewhere. It's too personal for my regular social media but I have to put it into writing in some way.\\n\\nI've been avoiding googling my abusive ex boyfriend for ten years. Just thinking about him made me sick. Two years ago I finally got trauma therapy to deal with what he did to me. Constant humiliation, degradation, sexual abuse and rape. \\n\\nTonight I randomly felt curious about where he would be in life now, so I googled him. Turns out he died two years ago, about the same time as my trauma therapy started. I found this webpage where his friends and family had written how much they missed him. How they'd never forget his smile, the same smile that makes my skin crawl just thinking about it. \\n\\nI've never felt happy about anyone's death before but I actually feel like celebrating. It's not relief because he was already out of my life and I was never scared of him showing up or hurting me again. It's just.. triumph. I still suffer the consequences of what he did to me. I still can't make relationships work and I still flinch when men get close to touching me because of him. I'm not ashamed to say that I hope he suffered before he died.\\n\\nThere's not much to discuss here I guess, I just didn't know where else to share this honestly.</td>\n",
       "      <td>Just found out my abuser is dead</td>\n",
       "      <td>1647747979</td>\n",
       "      <td>2022-03-20 03:46:19</td>\n",
       "      <td>1300</td>\n",
       "      <td>32</td>\n",
       "      <td>242</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>I was kidnapped at the age of 22 by a psychotic maniac on the run from the law and held against my will for 11 months\\nIt was hell.  Everyday was hell.  Of course I now have complex PTSD.  I'm 64 now and am still traumatized.  My whole life was ruined by the time I was 23.  I never got married, never had kids.  I've been a loner ever since. I still get intrusive memories of horrific child abuse.  I don't know why I'm even posting this.  But I know people here understand.</td>\n",
       "      <td>PTSD never goes away... I'm tired of it</td>\n",
       "      <td>1647747031</td>\n",
       "      <td>2022-03-20 03:30:31</td>\n",
       "      <td>474</td>\n",
       "      <td>39</td>\n",
       "      <td>93</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>As soon as I sit down with a counselor, I begin to shake uncontrollably, and it doesn't end until the appointment ends.</td>\n",
       "      <td>Do you shake uncontrollably during therapy?</td>\n",
       "      <td>1647743359</td>\n",
       "      <td>2022-03-20 02:29:19</td>\n",
       "      <td>119</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>The guy I work for abuses me and I can't get away from him. Everyone around me keeps saying I'll be ok one day but I don't believe that at all. I'm just gonna stop thinking about all of this because ignoring it has been one of the only things that have worked so far. I know I'll be fine if I just stop thinking.</td>\n",
       "      <td>I'm just going to stop thinking about it</td>\n",
       "      <td>1647743100</td>\n",
       "      <td>2022-03-20 02:25:00</td>\n",
       "      <td>312</td>\n",
       "      <td>40</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit  \\\n",
       "0      ptsd   \n",
       "1      ptsd   \n",
       "2      ptsd   \n",
       "3      ptsd   \n",
       "4      ptsd   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       selftext  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             So, I was on tick-tock and a therapist was talking about healing PTSD and I don't know if it's my night shift brain but I thought I kinda had PTSD forever now? Like.yeah.i can learn to love with it but I wouldn't class that as healing it? Idek I'm confused and sleepy sorry for the ramble!   \n",
       "1  I just need to share this and my feelings about it somewhere. It's too personal for my regular social media but I have to put it into writing in some way.\\n\\nI've been avoiding googling my abusive ex boyfriend for ten years. Just thinking about him made me sick. Two years ago I finally got trauma therapy to deal with what he did to me. Constant humiliation, degradation, sexual abuse and rape. \\n\\nTonight I randomly felt curious about where he would be in life now, so I googled him. Turns out he died two years ago, about the same time as my trauma therapy started. I found this webpage where his friends and family had written how much they missed him. How they'd never forget his smile, the same smile that makes my skin crawl just thinking about it. \\n\\nI've never felt happy about anyone's death before but I actually feel like celebrating. It's not relief because he was already out of my life and I was never scared of him showing up or hurting me again. It's just.. triumph. I still suffer the consequences of what he did to me. I still can't make relationships work and I still flinch when men get close to touching me because of him. I'm not ashamed to say that I hope he suffered before he died.\\n\\nThere's not much to discuss here I guess, I just didn't know where else to share this honestly.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   I was kidnapped at the age of 22 by a psychotic maniac on the run from the law and held against my will for 11 months\\nIt was hell.  Everyday was hell.  Of course I now have complex PTSD.  I'm 64 now and am still traumatized.  My whole life was ruined by the time I was 23.  I never got married, never had kids.  I've been a loner ever since. I still get intrusive memories of horrific child abuse.  I don't know why I'm even posting this.  But I know people here understand.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       As soon as I sit down with a counselor, I begin to shake uncontrollably, and it doesn't end until the appointment ends.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      The guy I work for abuses me and I can't get away from him. Everyone around me keeps saying I'll be ok one day but I don't believe that at all. I'm just gonna stop thinking about all of this because ignoring it has been one of the only things that have worked so far. I know I'll be fine if I just stop thinking.   \n",
       "\n",
       "                                         title  created_utc  \\\n",
       "0                          Can PTSD be healed?   1647751986   \n",
       "1             Just found out my abuser is dead   1647747979   \n",
       "2      PTSD never goes away... I'm tired of it   1647747031   \n",
       "3  Do you shake uncontrollably during therapy?   1647743359   \n",
       "4     I'm just going to stop thinking about it   1647743100   \n",
       "\n",
       "              datetime  LengthOf_selftext  LengthOf_title  WrdCnt_selftext  \\\n",
       "0  2022-03-20 04:53:06                289              19               56   \n",
       "1  2022-03-20 03:46:19               1300              32              242   \n",
       "2  2022-03-20 03:30:31                474              39               93   \n",
       "3  2022-03-20 02:29:19                119              43               22   \n",
       "4  2022-03-20 02:25:00                312              40               65   \n",
       "\n",
       "   WrdCnt_title  \n",
       "0             4  \n",
       "1             7  \n",
       "2             8  \n",
       "3             6  \n",
       "4             8  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subreddit'] = df['subreddit'].map(lambda x: 1 if x == 'ptsd' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['selftext']\n",
    "y = df['subreddit']\n",
    "\n",
    "#  Train test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=stopwordlist)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "clf = MultinomialNB(alpha=1.0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.501921\n",
       "0    0.498079\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts(normalize= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'00'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27340891, 0.72659109]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the prediction\n",
    "# for first row, seeing prob of getting PTSD given using the word for 00 is higher than of given not PTSD\n",
    "clf.predict_proba(X_train[0, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20298, 9)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13599, 28788)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to do todense() because after we vectorise, it is in a sparse matrix\n",
    "# hence in order to read, we do todense\n",
    "\n",
    "X_train.todense().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 28788)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two rows of probabilities \n",
    "# first is for 0 (NOT PTSD)\n",
    "# second is for 1 (PTSD)\n",
    "\n",
    "clf.feature_log_prob_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log prob given not PTSD: [-10.50472799 -10.41688442 -11.23886477 ... -11.23886477 -11.23886477\n",
      " -11.23886477]\n",
      "Log prob given PTSD: [ -9.55622364 -10.11461905 -10.79921798 ... -10.99118709 -10.99118709\n",
      " -10.99118709]\n"
     ]
    }
   ],
   "source": [
    "print(f'Log prob given not PTSD: {clf.feature_log_prob_[1, :]}') \n",
    "\n",
    "print(f'Log prob given PTSD: {clf.feature_log_prob_[0, :]}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>log_prob_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10340</th>\n",
       "      <td>flashbacks</td>\n",
       "      <td>3.671784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10338</th>\n",
       "      <td>flashback</td>\n",
       "      <td>3.394755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20389</th>\n",
       "      <td>raped</td>\n",
       "      <td>3.251154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20387</th>\n",
       "      <td>rape</td>\n",
       "      <td>3.243639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>abuser</td>\n",
       "      <td>3.173942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>assault</td>\n",
       "      <td>3.074608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>abused</td>\n",
       "      <td>2.947430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>assaulted</td>\n",
       "      <td>2.771845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>abuse</td>\n",
       "      <td>2.669279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17140</th>\n",
       "      <td>nightmares</td>\n",
       "      <td>2.541429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22665</th>\n",
       "      <td>sexually</td>\n",
       "      <td>2.531362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19380</th>\n",
       "      <td>prazosin</td>\n",
       "      <td>2.387549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8869</th>\n",
       "      <td>emdr</td>\n",
       "      <td>2.350881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20396</th>\n",
       "      <td>rapist</td>\n",
       "      <td>2.339468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>abusers</td>\n",
       "      <td>2.320630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21932</th>\n",
       "      <td>sa</td>\n",
       "      <td>2.241737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10246</th>\n",
       "      <td>fireworks</td>\n",
       "      <td>2.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22656</th>\n",
       "      <td>sexual</td>\n",
       "      <td>2.233356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25450</th>\n",
       "      <td>terrors</td>\n",
       "      <td>2.226751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15918</th>\n",
       "      <td>memories</td>\n",
       "      <td>2.038657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Features  log_prob_diff\n",
       "10340  flashbacks       3.671784\n",
       "10338   flashback       3.394755\n",
       "20389       raped       3.251154\n",
       "20387        rape       3.243639\n",
       "1116       abuser       3.173942\n",
       "2492      assault       3.074608\n",
       "1115       abused       2.947430\n",
       "2493    assaulted       2.771845\n",
       "1114        abuse       2.669279\n",
       "17140  nightmares       2.541429\n",
       "22665    sexually       2.531362\n",
       "19380    prazosin       2.387549\n",
       "8869         emdr       2.350881\n",
       "20396      rapist       2.339468\n",
       "1117      abusers       2.320630\n",
       "21932          sa       2.241737\n",
       "10246   fireworks       2.240000\n",
       "22656      sexual       2.233356\n",
       "25450     terrors       2.226751\n",
       "15918    memories       2.038657"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta = clf.feature_log_prob_[1, :] - clf.feature_log_prob_[0, :]\n",
    "\n",
    "\n",
    "df_multinomial = pd.DataFrame([[x,y] for x,y in zip(vectorizer.get_feature_names(),delta)])\n",
    "df_multinomial.rename(columns= {0: 'Features', 1: 'log_prob_diff'}, inplace = True)\n",
    "df_multinomial.sort_values(by = 'log_prob_diff', ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Admin\\Desktop\\Github Desktop Local\\GA-Lessons\\project_3\\MultinomialNB_Model.ipynb Cell 35'\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/Github%20Desktop%20Local/GA-Lessons/project_3/MultinomialNB_Model.ipynb#ch0000022?line=22'>23</a>\u001b[0m pipe_params \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/Github%20Desktop%20Local/GA-Lessons/project_3/MultinomialNB_Model.ipynb#ch0000022?line=23'>24</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcvec__max_features\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m1_000\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/Github%20Desktop%20Local/GA-Lessons/project_3/MultinomialNB_Model.ipynb#ch0000022?line=24'>25</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcvec__min_df\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m.002\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/Github%20Desktop%20Local/GA-Lessons/project_3/MultinomialNB_Model.ipynb#ch0000022?line=25'>26</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcvec__max_df\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m.6\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/Github%20Desktop%20Local/GA-Lessons/project_3/MultinomialNB_Model.ipynb#ch0000022?line=26'>27</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcvec__ngram_range\u001b[39m\u001b[39m'\u001b[39m: [(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m), (\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m)],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/Github%20Desktop%20Local/GA-Lessons/project_3/MultinomialNB_Model.ipynb#ch0000022?line=27'>28</a>\u001b[0m }\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/Github%20Desktop%20Local/GA-Lessons/project_3/MultinomialNB_Model.ipynb#ch0000022?line=29'>30</a>\u001b[0m gs \u001b[39m=\u001b[39m GridSearchCV(pipe, \u001b[39m# what object are we optimizing?\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/Github%20Desktop%20Local/GA-Lessons/project_3/MultinomialNB_Model.ipynb#ch0000022?line=30'>31</a>\u001b[0m                   param_grid\u001b[39m=\u001b[39mpipe_params, \u001b[39m# what parameters values are we searching?\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/Github%20Desktop%20Local/GA-Lessons/project_3/MultinomialNB_Model.ipynb#ch0000022?line=31'>32</a>\u001b[0m                   cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m) \u001b[39m# 5-fold cross-validation\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/Github%20Desktop%20Local/GA-Lessons/project_3/MultinomialNB_Model.ipynb#ch0000022?line=33'>34</a>\u001b[0m gs\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=884'>885</a>\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=885'>886</a>\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=886'>887</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=888'>889</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=890'>891</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=892'>893</a>\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=893'>894</a>\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=894'>895</a>\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=1389'>1390</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=1390'>1391</a>\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=1391'>1392</a>\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=829'>830</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=830'>831</a>\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=831'>832</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=832'>833</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=833'>834</a>\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=834'>835</a>\u001b[0m         )\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=835'>836</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=837'>838</a>\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=838'>839</a>\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=839'>840</a>\u001b[0m         clone(base_estimator),\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=840'>841</a>\u001b[0m         X,\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=841'>842</a>\u001b[0m         y,\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=842'>843</a>\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=843'>844</a>\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=844'>845</a>\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=845'>846</a>\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=846'>847</a>\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=847'>848</a>\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=848'>849</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=849'>850</a>\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=850'>851</a>\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=851'>852</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=852'>853</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=854'>855</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=855'>856</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=856'>857</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=857'>858</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=858'>859</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_search.py?line=859'>860</a>\u001b[0m     )\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=1042'>1043</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=1043'>1044</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=1045'>1046</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=1046'>1047</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=1049'>1050</a>\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=1050'>1051</a>\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=1051'>1052</a>\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=858'>859</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=859'>860</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=860'>861</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=861'>862</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=776'>777</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=777'>778</a>\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=778'>779</a>\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=779'>780</a>\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=780'>781</a>\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=781'>782</a>\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=782'>783</a>\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=783'>784</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/_parallel_backends.py?line=205'>206</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/_parallel_backends.py?line=206'>207</a>\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/_parallel_backends.py?line=207'>208</a>\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/_parallel_backends.py?line=208'>209</a>\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/_parallel_backends.py?line=209'>210</a>\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/_parallel_backends.py?line=568'>569</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/_parallel_backends.py?line=569'>570</a>\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/_parallel_backends.py?line=570'>571</a>\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/_parallel_backends.py?line=571'>572</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=257'>258</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=258'>259</a>\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=259'>260</a>\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=260'>261</a>\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=261'>262</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=262'>263</a>\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=257'>258</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=258'>259</a>\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=259'>260</a>\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=260'>261</a>\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=261'>262</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/parallel.py?line=262'>263</a>\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/utils/fixes.py?line=213'>214</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/utils/fixes.py?line=214'>215</a>\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/utils/fixes.py?line=215'>216</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_validation.py?line=677'>678</a>\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_validation.py?line=678'>679</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_validation.py?line=679'>680</a>\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_validation.py?line=681'>682</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_validation.py?line=682'>683</a>\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/model_selection/_validation.py?line=683'>684</a>\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\pipeline.py:390\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=363'>364</a>\u001b[0m \u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=364'>365</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=365'>366</a>\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=386'>387</a>\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=387'>388</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=388'>389</a>\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=389'>390</a>\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps)\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=390'>391</a>\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=391'>392</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\pipeline.py:348\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=345'>346</a>\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=346'>347</a>\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=347'>348</a>\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=348'>349</a>\u001b[0m     cloned_transformer,\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=349'>350</a>\u001b[0m     X,\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=350'>351</a>\u001b[0m     y,\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=351'>352</a>\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=352'>353</a>\u001b[0m     message_clsname\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=353'>354</a>\u001b[0m     message\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(step_idx),\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=354'>355</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps[name],\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=355'>356</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=356'>357</a>\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=357'>358</a>\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=358'>359</a>\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=359'>360</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/memory.py?line=347'>348</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/joblib/memory.py?line=348'>349</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=890'>891</a>\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=891'>892</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=892'>893</a>\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit_transform(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=893'>894</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/pipeline.py?line=894'>895</a>\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2077\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=2057'>2058</a>\u001b[0m \u001b[39m\"\"\"Learn vocabulary and idf, return document-term matrix.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=2058'>2059</a>\u001b[0m \n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=2059'>2060</a>\u001b[0m \u001b[39mThis is equivalent to fit followed by transform, but more efficiently\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=2073'>2074</a>\u001b[0m \u001b[39m    Tf-idf-weighted document-term matrix.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=2074'>2075</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=2075'>2076</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params()\n\u001b[1;32m-> <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=2076'>2077</a>\u001b[0m X \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit_transform(raw_documents)\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=2077'>2078</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf\u001b[39m.\u001b[39mfit(X)\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=2078'>2079</a>\u001b[0m \u001b[39m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=2079'>2080</a>\u001b[0m \u001b[39m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1330\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=1321'>1322</a>\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=1322'>1323</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=1323'>1324</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=1324'>1325</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=1325'>1326</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=1326'>1327</a>\u001b[0m             )\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=1327'>1328</a>\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=1329'>1330</a>\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=1331'>1332</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=1332'>1333</a>\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1201\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=1198'>1199</a>\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m raw_documents:\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=1199'>1200</a>\u001b[0m     feature_counter \u001b[39m=\u001b[39m {}\n\u001b[1;32m-> <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=1200'>1201</a>\u001b[0m     \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m analyze(doc):\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=1201'>1202</a>\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=1202'>1203</a>\u001b[0m             feature_idx \u001b[39m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:115\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=112'>113</a>\u001b[0m     doc \u001b[39m=\u001b[39m preprocessor(doc)\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=113'>114</a>\u001b[0m \u001b[39mif\u001b[39;00m tokenizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=114'>115</a>\u001b[0m     doc \u001b[39m=\u001b[39m tokenizer(doc)\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=115'>116</a>\u001b[0m \u001b[39mif\u001b[39;00m ngrams \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/.conda/envs/myenv/lib/site-packages/sklearn/feature_extraction/text.py?line=116'>117</a>\u001b[0m     \u001b[39mif\u001b[39;00m stop_words \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;32mc:\\Users\\Admin\\Desktop\\Github Desktop Local\\GA-Lessons\\project_3\\MultinomialNB_Model.ipynb Cell 35'\u001b[0m in \u001b[0;36mLemmaTokenizer.__call__\u001b[1;34m(self, articles)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/Github%20Desktop%20Local/GA-Lessons/project_3/MultinomialNB_Model.ipynb#ch0000022?line=6'>7</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m,articles):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/Github%20Desktop%20Local/GA-Lessons/project_3/MultinomialNB_Model.ipynb#ch0000022?line=7'>8</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstem\u001b[39m.\u001b[39mstem(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m word_tokenize(articles)]\n",
      "\u001b[1;32mc:\\Users\\Admin\\Desktop\\Github Desktop Local\\GA-Lessons\\project_3\\MultinomialNB_Model.ipynb Cell 35'\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/Github%20Desktop%20Local/GA-Lessons/project_3/MultinomialNB_Model.ipynb#ch0000022?line=6'>7</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m,articles):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/Github%20Desktop%20Local/GA-Lessons/project_3/MultinomialNB_Model.ipynb#ch0000022?line=7'>8</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstem\u001b[39m.\u001b[39mstem(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m word_tokenize(articles)]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = df['selftext']\n",
    "y = df['subreddit']\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.stem = PorterStemmer()\n",
    "    def __call__(self,articles):\n",
    "        return [self.stem.stem(t) for t in word_tokenize(articles)]\n",
    "\n",
    "\n",
    "#  Train test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('cvec', TfidfVectorizer(stop_words = stopwordlist, tokenizer= LemmaTokenizer())),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [1_000],\n",
    "    'cvec__min_df': [.002],\n",
    "    'cvec__max_df': [.6],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, # what object are we optimizing?\n",
    "                  param_grid=pipe_params, # what parameters values are we searching?\n",
    "                  cv=5) # 5-fold cross-validation\n",
    "\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec',\n",
       "                 TfidfVectorizer(max_df=0.6, max_features=1000, min_df=0.002,\n",
       "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...],\n",
       "                                 tokenizer=<__main__.LemmaTokenizer object at 0x00000298490EB970>)),\n",
       "                ('nb', MultinomialNB())])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7998381487571122\n",
      "Best training score: 0.8080005882785499\n",
      "Best test score: 0.8087774294670846\n"
     ]
    }
   ],
   "source": [
    "# What's the best score?\n",
    "print('Best score:', gs.best_score_)\n",
    "\n",
    "# Score model on training set.\n",
    "print('Best training score:', gs.score(X_train, y_train))\n",
    "  \n",
    "# Score model on testing set.\n",
    "print('Best test score:', gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds = gs.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "# View confusion matrix\n",
    "cmd = plot_confusion_matrix(gs, X_test, y_test, cmap='Blues', values_format='d', display_labels=['General Anxiety','PTSD'])\n",
    "cmd.ax_.set(xlabel='Predicted', ylabel='True');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Probability_PTSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>flashback</td>\n",
       "      <td>57.169785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>rape</td>\n",
       "      <td>55.580035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>assault</td>\n",
       "      <td>29.973813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>abus</td>\n",
       "      <td>14.869021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>emdr</td>\n",
       "      <td>11.873103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>sexual</td>\n",
       "      <td>10.409478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>nightmar</td>\n",
       "      <td>8.225898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>victim</td>\n",
       "      <td>7.568245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>dissoci</td>\n",
       "      <td>6.386084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>memori</td>\n",
       "      <td>6.039942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>childhood</td>\n",
       "      <td>5.774831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>diagnosi</td>\n",
       "      <td>5.462144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>manipul</td>\n",
       "      <td>5.352985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>polic</td>\n",
       "      <td>5.307594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>heal</td>\n",
       "      <td>5.176390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>violent</td>\n",
       "      <td>4.942664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>tw</td>\n",
       "      <td>4.802959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>scream</td>\n",
       "      <td>4.485026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>men</td>\n",
       "      <td>4.443334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>trigger</td>\n",
       "      <td>4.122405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>ex</td>\n",
       "      <td>4.048834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>threaten</td>\n",
       "      <td>4.026013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>incid</td>\n",
       "      <td>3.993417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>anger</td>\n",
       "      <td>3.853595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>child</td>\n",
       "      <td>3.705072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>disgust</td>\n",
       "      <td>3.698187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>father</td>\n",
       "      <td>3.656166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>yell</td>\n",
       "      <td>3.546842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>detail</td>\n",
       "      <td>3.541063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>event</td>\n",
       "      <td>3.344467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Features  Probability_PTSD\n",
       "356  flashback         57.169785\n",
       "706       rape         55.580035\n",
       "103    assault         29.973813\n",
       "42        abus         14.869021\n",
       "293       emdr         11.873103\n",
       "778     sexual         10.409478\n",
       "608   nightmar          8.225898\n",
       "937     victim          7.568245\n",
       "260    dissoci          6.386084\n",
       "562     memori          6.039942\n",
       "180  childhood          5.774831\n",
       "252   diagnosi          5.462144\n",
       "548    manipul          5.352985\n",
       "672      polic          5.307594\n",
       "427       heal          5.176390\n",
       "939    violent          4.942664\n",
       "921         tw          4.802959\n",
       "759     scream          4.485026\n",
       "563        men          4.443334\n",
       "913    trigger          4.122405\n",
       "315         ex          4.048834\n",
       "886   threaten          4.026013\n",
       "469      incid          3.993417\n",
       "79       anger          3.853595\n",
       "179      child          3.705072\n",
       "259    disgust          3.698187\n",
       "339     father          3.656166\n",
       "990       yell          3.546842\n",
       "249     detail          3.541063\n",
       "307      event          3.344467"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to create delta between the log probabilities between two classes\n",
    "delta = gs.best_estimator_[1].feature_log_prob_[1, :] - gs.best_estimator_[1].feature_log_prob_[0, :]\n",
    "\n",
    "# Create Df and filter top few log prob \n",
    "df_multinomial = pd.DataFrame([[x,y] for x,y in zip(gs.best_estimator_[0].get_feature_names(), np.exp(delta))])\n",
    "df_multinomial.rename(columns= {0: 'Features', 1: 'Probability_PTSD'}, inplace = True)\n",
    "df_multinomial.sort_values(by = 'Probability_PTSD', ascending = False).head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flashback flashback abuse abused\n"
     ]
    }
   ],
   "source": [
    "def lemmetize_print(words):\n",
    "     from nltk.stem import WordNetLemmatizer\n",
    "     from nltk.tokenize import word_tokenize\n",
    "     lemmatizer = WordNetLemmatizer()\n",
    "     a = []\n",
    "     tokens = word_tokenize(words)\n",
    "     for token in tokens:\n",
    "          if token in ['abused']:\n",
    "              a.append('abuse')\n",
    "          lemmetized_word = lemmatizer.lemmatize(token)\n",
    "          a.append(lemmetized_word)\n",
    "     sentence = \" \".join(a)\n",
    "     print(sentence)\n",
    "\n",
    "\n",
    "\n",
    "text = 'flashbacks flashback abused'\n",
    "\n",
    "lemmetize_print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flashback flashback abus\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "def lemmetize_print(words):\n",
    "     stemmer = PorterStemmer()\n",
    "     a = []\n",
    "     tokens = word_tokenize(words)\n",
    "     for token in tokens:\n",
    "          lemmetized_word = stemmer.stem(token)\n",
    "          a.append(lemmetized_word)\n",
    "     sentence = \" \".join(a)\n",
    "     print(sentence)\n",
    "\n",
    "\n",
    "text = 'flashbacks flashback abuser'\n",
    "\n",
    "lemmetize_print(text)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
