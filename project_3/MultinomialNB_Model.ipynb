{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import string\n",
    "string.punctuation\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk import word_tokenize   \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import(\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    "    GridSearchCV\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    PolynomialFeatures\n",
    ")\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anxiety = pd.read_csv('Anxiety.csv')\n",
    "df_ptsd = pd.read_csv('PTSD.csv')\n",
    "\n",
    "df_anxiety = df_anxiety.drop(columns = 'Unnamed: 0')\n",
    "df_ptsd.drop(columns = 'Unnamed: 0', inplace = True)\n",
    "\n",
    "df = pd.concat([df_ptsd,df_anxiety])\n",
    "df.reset_index(inplace = True)\n",
    "df.drop(columns = 'index', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20298, 5)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'ptsd',\n",
       " 'anxiety',\n",
       " 'cptsd',\n",
       " 'trauma',\n",
       " 'traumatized',\n",
       " 'traumas',\n",
       " 'posttraumatic',\n",
       " 'stress',\n",
       " 'disorder',\n",
       " 'traumatic',\n",
       " \"'d\",\n",
       " \"'ll\",\n",
       " \"'re\",\n",
       " \"'s\",\n",
       " \"'ve\",\n",
       " 'could',\n",
       " 'doe',\n",
       " 'ha',\n",
       " 'might',\n",
       " 'must',\n",
       " \"n't\",\n",
       " 'need',\n",
       " 'sha',\n",
       " 'wa',\n",
       " 'wo',\n",
       " 'would']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create stop word list \n",
    "stopwordlist = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# to input in subreddit headers so that we can exclude it for model\n",
    "headers = ['ptsd', 'anxiety',\"cptsd\", 'trauma','traumatized','traumas',\"posttraumatic\",'stress','disorder',\"traumatic\",\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'doe', 'ha', 'might', 'must', \"n't\", 'need', 'sha', 'wa', 'wo', 'would']\n",
    "for head in headers:\n",
    "    stopwordlist.append(head)\n",
    "\n",
    "\n",
    "# Add additional list from stemmed words \n",
    "\n",
    "stemmed_data = []\n",
    "stopwordlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>So, I was on tick-tock and a therapist was talking about healing PTSD and I don't know if it's my night shift brain but I thought I kinda had PTSD forever now? Like.yeah.i can learn to love with it but I wouldn't class that as healing it? Idek I'm confused and sleepy sorry for the ramble!</td>\n",
       "      <td>Can PTSD be healed?</td>\n",
       "      <td>1647751986</td>\n",
       "      <td>2022-03-20 04:53:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>I just need to share this and my feelings about it somewhere. It's too personal for my regular social media but I have to put it into writing in some way.\\n\\nI've been avoiding googling my abusive ex boyfriend for ten years. Just thinking about him made me sick. Two years ago I finally got trauma therapy to deal with what he did to me. Constant humiliation, degradation, sexual abuse and rape. \\n\\nTonight I randomly felt curious about where he would be in life now, so I googled him. Turns out he died two years ago, about the same time as my trauma therapy started. I found this webpage where his friends and family had written how much they missed him. How they'd never forget his smile, the same smile that makes my skin crawl just thinking about it. \\n\\nI've never felt happy about anyone's death before but I actually feel like celebrating. It's not relief because he was already out of my life and I was never scared of him showing up or hurting me again. It's just.. triumph. I still suffer the consequences of what he did to me. I still can't make relationships work and I still flinch when men get close to touching me because of him. I'm not ashamed to say that I hope he suffered before he died.\\n\\nThere's not much to discuss here I guess, I just didn't know where else to share this honestly.</td>\n",
       "      <td>Just found out my abuser is dead</td>\n",
       "      <td>1647747979</td>\n",
       "      <td>2022-03-20 03:46:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>I was kidnapped at the age of 22 by a psychotic maniac on the run from the law and held against my will for 11 months\\nIt was hell.  Everyday was hell.  Of course I now have complex PTSD.  I'm 64 now and am still traumatized.  My whole life was ruined by the time I was 23.  I never got married, never had kids.  I've been a loner ever since. I still get intrusive memories of horrific child abuse.  I don't know why I'm even posting this.  But I know people here understand.</td>\n",
       "      <td>PTSD never goes away... I'm tired of it</td>\n",
       "      <td>1647747031</td>\n",
       "      <td>2022-03-20 03:30:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>As soon as I sit down with a counselor, I begin to shake uncontrollably, and it doesn't end until the appointment ends.</td>\n",
       "      <td>Do you shake uncontrollably during therapy?</td>\n",
       "      <td>1647743359</td>\n",
       "      <td>2022-03-20 02:29:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>The guy I work for abuses me and I can't get away from him. Everyone around me keeps saying I'll be ok one day but I don't believe that at all. I'm just gonna stop thinking about all of this because ignoring it has been one of the only things that have worked so far. I know I'll be fine if I just stop thinking.</td>\n",
       "      <td>I'm just going to stop thinking about it</td>\n",
       "      <td>1647743100</td>\n",
       "      <td>2022-03-20 02:25:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit  \\\n",
       "0      ptsd   \n",
       "1      ptsd   \n",
       "2      ptsd   \n",
       "3      ptsd   \n",
       "4      ptsd   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       selftext  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             So, I was on tick-tock and a therapist was talking about healing PTSD and I don't know if it's my night shift brain but I thought I kinda had PTSD forever now? Like.yeah.i can learn to love with it but I wouldn't class that as healing it? Idek I'm confused and sleepy sorry for the ramble!   \n",
       "1  I just need to share this and my feelings about it somewhere. It's too personal for my regular social media but I have to put it into writing in some way.\\n\\nI've been avoiding googling my abusive ex boyfriend for ten years. Just thinking about him made me sick. Two years ago I finally got trauma therapy to deal with what he did to me. Constant humiliation, degradation, sexual abuse and rape. \\n\\nTonight I randomly felt curious about where he would be in life now, so I googled him. Turns out he died two years ago, about the same time as my trauma therapy started. I found this webpage where his friends and family had written how much they missed him. How they'd never forget his smile, the same smile that makes my skin crawl just thinking about it. \\n\\nI've never felt happy about anyone's death before but I actually feel like celebrating. It's not relief because he was already out of my life and I was never scared of him showing up or hurting me again. It's just.. triumph. I still suffer the consequences of what he did to me. I still can't make relationships work and I still flinch when men get close to touching me because of him. I'm not ashamed to say that I hope he suffered before he died.\\n\\nThere's not much to discuss here I guess, I just didn't know where else to share this honestly.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   I was kidnapped at the age of 22 by a psychotic maniac on the run from the law and held against my will for 11 months\\nIt was hell.  Everyday was hell.  Of course I now have complex PTSD.  I'm 64 now and am still traumatized.  My whole life was ruined by the time I was 23.  I never got married, never had kids.  I've been a loner ever since. I still get intrusive memories of horrific child abuse.  I don't know why I'm even posting this.  But I know people here understand.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       As soon as I sit down with a counselor, I begin to shake uncontrollably, and it doesn't end until the appointment ends.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      The guy I work for abuses me and I can't get away from him. Everyone around me keeps saying I'll be ok one day but I don't believe that at all. I'm just gonna stop thinking about all of this because ignoring it has been one of the only things that have worked so far. I know I'll be fine if I just stop thinking.   \n",
       "\n",
       "                                         title  created_utc  \\\n",
       "0                          Can PTSD be healed?   1647751986   \n",
       "1             Just found out my abuser is dead   1647747979   \n",
       "2      PTSD never goes away... I'm tired of it   1647747031   \n",
       "3  Do you shake uncontrollably during therapy?   1647743359   \n",
       "4     I'm just going to stop thinking about it   1647743100   \n",
       "\n",
       "              datetime  \n",
       "0  2022-03-20 04:53:06  \n",
       "1  2022-03-20 03:46:19  \n",
       "2  2022-03-20 03:30:31  \n",
       "3  2022-03-20 02:29:19  \n",
       "4  2022-03-20 02:25:00  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subreddit'] = df['subreddit'].map(lambda x: 1 if x == 'ptsd' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['selftext']\n",
    "y = df['subreddit']\n",
    "\n",
    "#  Train test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=stopwordlist)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "clf = MultinomialNB(alpha=1.0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.501921\n",
       "0    0.498079\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts(normalize= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2733584, 0.7266416]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the prediction\n",
    "# for first row, seeing prob of getting PTSD given using the word for 00 is higher than of given not PTSD\n",
    "clf.predict_proba(X_train[0, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20298, 5)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13599, 28789)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to do todense() because after we vectorise, it is in a sparse matrix\n",
    "# hence in order to read, we do todense\n",
    "\n",
    "X_train.todense().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 28789)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two rows of probabilities \n",
    "# first is for 0 (NOT PTSD)\n",
    "# second is for 1 (PTSD)\n",
    "\n",
    "clf.feature_log_prob_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log prob given not PTSD: [-10.50501074 -10.4171901  -11.23914752 ... -11.23914752 -11.23914752\n",
      " -11.23914752]\n",
      "Log prob given PTSD: [ -9.55660388 -10.11501369 -10.79956854 ... -10.99153765 -10.99153765\n",
      " -10.99153765]\n"
     ]
    }
   ],
   "source": [
    "print(f'Log prob given not PTSD: {clf.feature_log_prob_[1, :]}') \n",
    "\n",
    "print(f'Log prob given PTSD: {clf.feature_log_prob_[0, :]}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>log_prob_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10340</th>\n",
       "      <td>flashbacks</td>\n",
       "      <td>3.672172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10338</th>\n",
       "      <td>flashback</td>\n",
       "      <td>3.395683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20390</th>\n",
       "      <td>raped</td>\n",
       "      <td>3.251086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20388</th>\n",
       "      <td>rape</td>\n",
       "      <td>3.243453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>abuser</td>\n",
       "      <td>3.173829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>assault</td>\n",
       "      <td>3.074510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>abused</td>\n",
       "      <td>2.947242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>assaulted</td>\n",
       "      <td>2.771642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>abuse</td>\n",
       "      <td>2.669231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17141</th>\n",
       "      <td>nightmares</td>\n",
       "      <td>2.541344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22666</th>\n",
       "      <td>sexually</td>\n",
       "      <td>2.531174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19381</th>\n",
       "      <td>prazosin</td>\n",
       "      <td>2.386364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8869</th>\n",
       "      <td>emdr</td>\n",
       "      <td>2.351489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20397</th>\n",
       "      <td>rapist</td>\n",
       "      <td>2.339618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>abusers</td>\n",
       "      <td>2.320679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21933</th>\n",
       "      <td>sa</td>\n",
       "      <td>2.241564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10246</th>\n",
       "      <td>fireworks</td>\n",
       "      <td>2.240043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22657</th>\n",
       "      <td>sexual</td>\n",
       "      <td>2.233408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25451</th>\n",
       "      <td>terrors</td>\n",
       "      <td>2.226601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15919</th>\n",
       "      <td>memories</td>\n",
       "      <td>2.039769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Features  log_prob_diff\n",
       "10340  flashbacks       3.672172\n",
       "10338   flashback       3.395683\n",
       "20390       raped       3.251086\n",
       "20388        rape       3.243453\n",
       "1116       abuser       3.173829\n",
       "2492      assault       3.074510\n",
       "1115       abused       2.947242\n",
       "2493    assaulted       2.771642\n",
       "1114        abuse       2.669231\n",
       "17141  nightmares       2.541344\n",
       "22666    sexually       2.531174\n",
       "19381    prazosin       2.386364\n",
       "8869         emdr       2.351489\n",
       "20397      rapist       2.339618\n",
       "1117      abusers       2.320679\n",
       "21933          sa       2.241564\n",
       "10246   fireworks       2.240043\n",
       "22657      sexual       2.233408\n",
       "25451     terrors       2.226601\n",
       "15919    memories       2.039769"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta = clf.feature_log_prob_[1, :] - clf.feature_log_prob_[0, :]\n",
    "\n",
    "\n",
    "df_multinomial = pd.DataFrame([[x,y] for x,y in zip(vectorizer.get_feature_names(),delta)])\n",
    "df_multinomial.rename(columns= {0: 'Features', 1: 'log_prob_diff'}, inplace = True)\n",
    "df_multinomial.sort_values(by = 'log_prob_diff', ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'anxieti', 'becaus', 'befor', 'disord', 'dure', 'hi', 'onc', 'onli', 'ourselv', 'posttraumat', 'themselv', 'thi', 'traumat', 'veri', 'whi', 'yourselv'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'anxieti', 'becaus', 'befor', 'disord', 'dure', 'hi', 'onc', 'onli', 'ourselv', 'posttraumat', 'themselv', 'thi', 'traumat', 'veri', 'whi', 'yourselv'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-177-829ceb7b8e4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m                   cv=5) # 5-fold cross-validation\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    339\u001b[0m         \"\"\"\n\u001b[0;32m    340\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[0;32m    343\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    301\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m             \u001b[1;31m# Fit or load from cache the current transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[0;32m    304\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Pipeline'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1848\u001b[0m         \"\"\"\n\u001b[0;32m   1849\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1850\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1851\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m         \u001b[1;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1203\u001b[1;33m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[0;32m   1204\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1115\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1116\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1117\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mngrams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-177-829ceb7b8e4a>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, articles)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0marticles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-177-829ceb7b8e4a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0marticles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\stem\\porter.py\u001b[0m in \u001b[0;36mstem\u001b[1;34m(self, word, to_lowercase)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[0mstem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[0mstem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m         \u001b[0mstem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[0mstem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step5a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[0mstem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step5b\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\stem\\porter.py\u001b[0m in \u001b[0;36m_step4\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mtidying\u001b[0m \u001b[0mup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m         \"\"\"\n\u001b[1;32m--> 568\u001b[1;33m         \u001b[0mmeasure_gt_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mstem\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_measure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         return self._apply_rule_list(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = df['selftext']\n",
    "y = df['subreddit']\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.stem = PorterStemmer()\n",
    "    def __call__(self,articles):\n",
    "        return [self.stem.stem(t) for t in word_tokenize(articles)]\n",
    "\n",
    "\n",
    "#  Train test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('cvec', TfidfVectorizer(stop_words = stopwordlist, tokenizer= LemmaTokenizer())),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [1_000],\n",
    "    'cvec__min_df': [.002],\n",
    "    'cvec__max_df': [.6],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, # what object are we optimizing?\n",
    "                  param_grid=pipe_params, # what parameters values are we searching?\n",
    "                  cv=5) # 5-fold cross-validation\n",
    "\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec',\n",
       "                 TfidfVectorizer(max_df=0.6, max_features=1000, min_df=0.002,\n",
       "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...])),\n",
       "                ('nb', MultinomialNB())])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.797264105531878\n",
      "Best training score: 0.8094712846532833\n",
      "Best test score: 0.8075832213763249\n"
     ]
    }
   ],
   "source": [
    "# What's the best score?\n",
    "print('Best score:', gs.best_score_)\n",
    "\n",
    "# Score model on training set.\n",
    "print('Best training score:', gs.score(X_train, y_train))\n",
    "\n",
    "# Score model on testing set.\n",
    "print('Best test score:', gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds = gs.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "# View confusion matrix\n",
    "cmd = plot_confusion_matrix(gs, X_test, y_test, cmap='Blues', values_format='d', display_labels=['General Anxiety','PTSD'])\n",
    "cmd.ax_.set(xlabel='Predicted', ylabel='True');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Probability_PTSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>flashbacks</td>\n",
       "      <td>47.365566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>flashback</td>\n",
       "      <td>37.642649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>rape</td>\n",
       "      <td>35.055188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>raped</td>\n",
       "      <td>34.422929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>abuser</td>\n",
       "      <td>30.756123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>assault</td>\n",
       "      <td>24.846401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>abused</td>\n",
       "      <td>20.226173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>assaulted</td>\n",
       "      <td>17.756549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>abuse</td>\n",
       "      <td>13.890207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>sexually</td>\n",
       "      <td>13.172589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>nightmares</td>\n",
       "      <td>12.827221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>emdr</td>\n",
       "      <td>12.265899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>sexual</td>\n",
       "      <td>8.727012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>memories</td>\n",
       "      <td>7.428761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>abusive</td>\n",
       "      <td>7.259795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>victim</td>\n",
       "      <td>6.914578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>childhood</td>\n",
       "      <td>6.056125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>emotional</td>\n",
       "      <td>5.780618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>police</td>\n",
       "      <td>5.480661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>healing</td>\n",
       "      <td>5.412462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Features  Probability_PTSD\n",
       "319  flashbacks         47.365566\n",
       "318   flashback         37.642649\n",
       "689        rape         35.055188\n",
       "690       raped         34.422929\n",
       "18       abuser         30.756123\n",
       "72      assault         24.846401\n",
       "17       abused         20.226173\n",
       "73    assaulted         17.756549\n",
       "16        abuse         13.890207\n",
       "752    sexually         13.172589\n",
       "595  nightmares         12.827221\n",
       "251        emdr         12.265899\n",
       "751      sexual          8.727012\n",
       "544    memories          7.428761\n",
       "19      abusive          7.259795\n",
       "929      victim          6.914578\n",
       "143   childhood          6.056125\n",
       "252   emotional          5.780618\n",
       "659      police          5.480661\n",
       "394     healing          5.412462"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to create delta between the log probabilities between two classes\n",
    "delta = gs.best_estimator_[1].feature_log_prob_[1, :] - gs.best_estimator_[1].feature_log_prob_[0, :]\n",
    "\n",
    "# Create Df and filter top few log prob \n",
    "df_multinomial = pd.DataFrame([[x,y] for x,y in zip(gs.best_estimator_[0].get_feature_names(), np.exp(delta))])\n",
    "df_multinomial.rename(columns= {0: 'Features', 1: 'Probability_PTSD'}, inplace = True)\n",
    "df_multinomial.sort_values(by = 'Probability_PTSD', ascending = False).head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flashback flashback abused\n"
     ]
    }
   ],
   "source": [
    "def lemmetize_print(words):\n",
    "     from nltk.stem import WordNetLemmatizer\n",
    "     from nltk.tokenize import word_tokenize\n",
    "     lemmatizer = WordNetLemmatizer()\n",
    "     a = []\n",
    "     tokens = word_tokenize(words)\n",
    "     for token in tokens:\n",
    "          if token in ['abused']:\n",
    "              a.append('abuse')\n",
    "          lemmetized_word = lemmatizer.lemmatize(token)\n",
    "          a.append(lemmetized_word)\n",
    "     sentence = \" \".join(a)\n",
    "     print(sentence)\n",
    "\n",
    "\n",
    "\n",
    "text = 'flashbacks flashback abused'\n",
    "\n",
    "lemmetize_print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flashback flashback abus\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "def lemmetize_print(words):\n",
    "     stemmer = PorterStemmer()\n",
    "     a = []\n",
    "     tokens = word_tokenize(words)\n",
    "     for token in tokens:\n",
    "          lemmetized_word = stemmer.stem(token)\n",
    "          a.append(lemmetized_word)\n",
    "     sentence = \" \".join(a)\n",
    "     print(sentence)\n",
    "\n",
    "\n",
    "text = 'flashbacks flashback abuser'\n",
    "\n",
    "lemmetize_print(text)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
