{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.linear_model import (\n",
    "    Ridge,RidgeCV,\n",
    "    Lasso,LassoCV,\n",
    "    ElasticNet, ElasticNetCV,\n",
    "    LinearRegression\n",
    ")\n",
    "from sklearn.model_selection import(\n",
    "    cross_val_score,\n",
    "    train_test_split\n",
    ")\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    PolynomialFeatures\n",
    ")\n",
    "# pd.set_option('display.max_rows', 1000)  # or 1000\n",
    "pd.set_option('display.max_columns', 50)  # or 1000\n",
    "\n",
    "from ipywidgets import *\n",
    "from IPython.display import display\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train = pd.read_csv('../data/merged_train.csv')\n",
    "merged_test = pd.read_csv('../data/merged_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8475 entries, 0 to 8474\n",
      "Data columns (total 46 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   date                    8475 non-null   object \n",
      " 1   address                 8475 non-null   object \n",
      " 2   species                 8475 non-null   object \n",
      " 3   block                   8475 non-null   int64  \n",
      " 4   street                  8475 non-null   object \n",
      " 5   trap                    8475 non-null   object \n",
      " 6   addressnumberandstreet  8475 non-null   object \n",
      " 7   latitude                8475 non-null   float64\n",
      " 8   longitude               8475 non-null   float64\n",
      " 9   addressaccuracy         8475 non-null   int64  \n",
      " 10  nummosquitos            8475 non-null   float64\n",
      " 11  wnvcount                8475 non-null   float64\n",
      " 12  wnvpresent              8475 non-null   float64\n",
      " 13  station                 8475 non-null   int64  \n",
      " 14  tmax                    8475 non-null   int64  \n",
      " 15  tmin                    8475 non-null   int64  \n",
      " 16  tavg                    8475 non-null   float64\n",
      " 17  dewpoint                8475 non-null   int64  \n",
      " 18  wetbulb                 8475 non-null   float64\n",
      " 19  heat                    8475 non-null   float64\n",
      " 20  cool                    8475 non-null   float64\n",
      " 21  codesum                 8475 non-null   object \n",
      " 22  preciptotal             8475 non-null   float64\n",
      " 23  stnpressure             8475 non-null   float64\n",
      " 24  sealevel                8475 non-null   float64\n",
      " 25  resultspeed             8475 non-null   float64\n",
      " 26  resultdir               8475 non-null   int64  \n",
      " 27  avgspeed                8475 non-null   float64\n",
      " 28  month                   8475 non-null   int64  \n",
      " 29  sunrise                 8475 non-null   float64\n",
      " 30  sunset                  8475 non-null   float64\n",
      " 31  bc                      8475 non-null   int64  \n",
      " 32  br                      8475 non-null   int64  \n",
      " 33  dz                      8475 non-null   int64  \n",
      " 34  fg                      8475 non-null   int64  \n",
      " 35  fg+                     8475 non-null   int64  \n",
      " 36  fu                      8475 non-null   int64  \n",
      " 37  hz                      8475 non-null   int64  \n",
      " 38  mi                      8475 non-null   float64\n",
      " 39  ra                      8475 non-null   int64  \n",
      " 40  sn                      8475 non-null   int64  \n",
      " 41  sq                      8475 non-null   int64  \n",
      " 42  ts                      8475 non-null   int64  \n",
      " 43  vc                      8475 non-null   int64  \n",
      " 44  gr                      8475 non-null   float64\n",
      " 45  sprayed                 8475 non-null   int64  \n",
      "dtypes: float64(18), int64(21), object(7)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_train['date'].dtypes !='O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train = pd.get_dummies(merged_train, columns = ['species'], drop_first = True)\n",
    "merged_test = pd.get_dummies(merged_test, columns = ['species'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_train[[col for col in merged_train.columns if (merged_train[col].dtypes !='O') & (col not in ['block','addressaccuracy','nummosquitos','wnvcount','wnvpresent', 'station','species_CULEX SALINARIUS',\n",
    " 'species_CULEX TARSALIS',\n",
    " 'species_CULEX TERRITANS'])]]\n",
    "y = merged_train['wnvpresent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting X and y into training and testing datasets.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling X_train to the standard scale.\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming X_test to the same scale.\n",
    "\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Balancing Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "adasyn = ADASYN(random_state=42)\n",
    "clustercentroids = ClusterCentroids(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sc_smote, y_train_smote = smote.fit_resample(X_train_sc, y_train)\n",
    "X_train_sc_adasyn, y_train_adasyn = adasyn.fit_resample(X_train_sc, y_train)\n",
    "X_train_sc_clustercentroids, y_train_clustercentroids = clustercentroids.fit_resample(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    6013\n",
       "1.0    6013\n",
       "Name: wnvpresent, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the distribution of classes with SMOTE balancing technique.\n",
    "\n",
    "y_train_smote.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.5\n",
       "1.0    0.5\n",
       "Name: wnvpresent, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the distribution of classes with SMOTE balancing technique.\n",
    "\n",
    "y_train_smote.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    6064\n",
       "0.0    6013\n",
       "Name: wnvpresent, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the distribution of classes with ADASYN balancing technique.\n",
    "\n",
    "y_train_adasyn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    0.502111\n",
       "0.0    0.497889\n",
       "Name: wnvpresent, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the distribution of classes with ADASYN balancing technique.\n",
    "\n",
    "y_train_adasyn.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    343\n",
       "1.0    343\n",
       "Name: wnvpresent, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the distribution of classes with ClusterCentroids balancing technique.\n",
    "\n",
    "y_train_clustercentroids.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.5\n",
       "1.0    0.5\n",
       "Name: wnvpresent, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the distribution of classes with ClusterCentroids balancing technique.\n",
    "\n",
    "y_train_clustercentroids.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained above, all three balancing techniques from the *imblearn* library help to balance the proportions of the classes in our sample population.\n",
    "\n",
    "***SMOTE* and *ADASYN* are over-sampling techniques**, which means they create copies of the minority class data points with small variations, making the synthetic samples more diverse (as explained [here](https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets)). So, as shown above, **the number of data points in the minority class increases to match the number of data points in the majority class (5885)**.\n",
    "\n",
    "***ClusterCentroids* is an under-sampling technique**, which means it gets rid of data from the majority class in order to balance the two classes. It does so by finding clusters of data points in the majority class, and then inferring which data points in the majority class are 'central' in that cluster. The model then uses those centroids (central points) for the majority class instead of all the actual data points (as explained [here](https://dev.to/lberlin/balancing-the-imbalanced-2bgo)). So, as shown above, **the number of data points in the majority class decreases significantly to match the number of data points in the minority class (343)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *GridSearchCV* for *LogisticRegression* with *SMOTE* balancing technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pipeline object using imblearn.pipeline with SMOTE and LogisticRegression.\n",
    "\n",
    "pipe1 = make_pipeline(SMOTE(random_state=42),\n",
    "                      LogisticRegression(penalty='elasticnet', solver='saga', random_state=42, max_iter=500, tol=0.005)\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('smote', SMOTE(random_state=42)),\n",
       "  ('logisticregression',\n",
       "   LogisticRegression(max_iter=500, penalty='elasticnet', random_state=42,\n",
       "                      solver='saga', tol=0.005))],\n",
       " 'verbose': False,\n",
       " 'smote': SMOTE(random_state=42),\n",
       " 'logisticregression': LogisticRegression(max_iter=500, penalty='elasticnet', random_state=42,\n",
       "                    solver='saga', tol=0.005),\n",
       " 'smote__k_neighbors': 5,\n",
       " 'smote__n_jobs': None,\n",
       " 'smote__random_state': 42,\n",
       " 'smote__sampling_strategy': 'auto',\n",
       " 'logisticregression__C': 1.0,\n",
       " 'logisticregression__class_weight': None,\n",
       " 'logisticregression__dual': False,\n",
       " 'logisticregression__fit_intercept': True,\n",
       " 'logisticregression__intercept_scaling': 1,\n",
       " 'logisticregression__l1_ratio': None,\n",
       " 'logisticregression__max_iter': 500,\n",
       " 'logisticregression__multi_class': 'auto',\n",
       " 'logisticregression__n_jobs': None,\n",
       " 'logisticregression__penalty': 'elasticnet',\n",
       " 'logisticregression__random_state': 42,\n",
       " 'logisticregression__solver': 'saga',\n",
       " 'logisticregression__tol': 0.005,\n",
       " 'logisticregression__verbose': 0,\n",
       " 'logisticregression__warm_start': False}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establishing ranges of hyperparameters C and l1_ratio for GridSearchCV.\n",
    "\n",
    "pipe1_params = {'logisticregression__C': np.logspace(-2, 2, 5),\n",
    "                'logisticregression__l1_ratio': [0, 0.25, 0.5, 0.75, 1]\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a GridSearchCV object for the pipeline object defined above.\n",
    "\n",
    "gs_pipe1 = GridSearchCV(pipe1, \n",
    "                        param_grid=pipe1_params, \n",
    "                        cv=5, \n",
    "                        scoring='roc_auc'\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('smote', SMOTE(random_state=42)),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(max_iter=500,\n",
       "                                                           penalty='elasticnet',\n",
       "                                                           random_state=42,\n",
       "                                                           solver='saga',\n",
       "                                                           tol=0.005))]),\n",
       "             param_grid={'logisticregression__C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       "                         'logisticregression__l1_ratio': [0, 0.25, 0.5, 0.75,\n",
       "                                                          1]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting GridSearchCV with SMOTE and LogisticRegression on X_train_sc and y_train.\n",
    "\n",
    "gs_pipe1.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 100.0, 'logisticregression__l1_ratio': 1}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best combination of hyperparameters suggested by GridSearchCV.\n",
    "\n",
    "gs_pipe1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8204137876470015"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best roc_auc score obtained by above combination of hyperparameters.\n",
    "\n",
    "gs_pipe1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8364471730104697"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scoring the model on training dataset (roc_auc score).\n",
    "\n",
    "gs_pipe1.score(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7941549634685217"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scoring the model on testing dataset (roc_auc score).\n",
    "\n",
    "gs_pipe1.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the best parameters were suggested above by *GridSearchCV*, the model was further tuned manually using different combinations of hyperparameters. ***GridSearchCV* only optimizes the model using a single scoring parameter (set as *'roc_auc'* above). However, in this context, we need to find a good balance between *accuracy* and *sensitivity* scores, and so a manual tuning of hyperparameters is required.**\n",
    "\n",
    "The final set of hyperparameters chosen after manual tuning of the model are as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pipeline object using imblearn.pipeline with SMOTE and LogisticRegression using best params suggested by GridSearchCV above.\n",
    "\n",
    "lr_smote_pipe1 = make_pipeline(SMOTE(random_state=42),\n",
    "                               LogisticRegression(penalty='elasticnet',\n",
    "                                                  solver='saga',\n",
    "                                                  C=100,\n",
    "                                                  l1_ratio=0.75,\n",
    "                                                  random_state=42,\n",
    "                                                  max_iter=500,\n",
    "                                                  tol=0.005\n",
    "                                                 )\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('smote', SMOTE(random_state=42)),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=100, l1_ratio=0.75, max_iter=500,\n",
       "                                    penalty='elasticnet', random_state=42,\n",
       "                                    solver='saga', tol=0.005))])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting X_train_sc and y_train on the pipeline object defined above.\n",
    "\n",
    "lr_smote_pipe1.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6875393329137822"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scoring the model on training dataset.\n",
    "# Training Accuracy\n",
    "\n",
    "train_acc1 = lr_smote_pipe1.score(X_train_sc, y_train)\n",
    "train_acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6914715793536511"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimated Testing Accuracy\n",
    "\n",
    "est_test_acc1 = cross_val_score(lr_smote_pipe1, X_train_sc, y_train, cv=5).mean()\n",
    "est_test_acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.680509674374705"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actual Testing Accuracy\n",
    "\n",
    "test_acc1 = lr_smote_pipe1.score(X_test_sc, y_test)\n",
    "test_acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating predictions on testing dataset using the model above.\n",
    "\n",
    "y_pred1 = lr_smote_pipe1.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating prediction probabilities on testing dataset using the model above.\n",
    "\n",
    "y_pred_proba1 = lr_smote_pipe1.predict_proba(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a confusion matrix.\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred1).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual WnvPresent=1</th>\n",
       "      <th>Actual WnvPresent=0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted WnvPresent=1</th>\n",
       "      <td>93 (True Pos)</td>\n",
       "      <td>656 (False Pos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted WnvPresent=0</th>\n",
       "      <td>21 (False Neg)</td>\n",
       "      <td>1349 (True Neg)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Actual WnvPresent=1 Actual WnvPresent=0\n",
       "Predicted WnvPresent=1       93 (True Pos)     656 (False Pos)\n",
       "Predicted WnvPresent=0      21 (False Neg)     1349 (True Neg)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat1 = pd.DataFrame(columns=['Actual WnvPresent=1', 'Actual WnvPresent=0'], \n",
    "                         index=['Predicted WnvPresent=1', 'Predicted WnvPresent=0'],\n",
    "                         data=[[f'{tp} (True Pos)', f'{fp} (False Pos)'], [f'{fn} (False Neg)', f'{tn} (True Neg)']]\n",
    "                        )\n",
    "conf_mat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8157894736842105"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity1 = tp/(tp+fn)\n",
    "sensitivity1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6728179551122194"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specificity1 = tn/(tn+fp)\n",
    "specificity1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12416555407209613"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision1 = tp/(tp+fp)\n",
    "precision1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7941637135232096"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc1 = roc_auc_score(y_test, y_pred_proba1[:, 1])\n",
    "roc_auc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'act_test_X_sc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Github Desktop Local\\GA-Lessons\\project_4\\code\\Modelling.ipynb Cell 45'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Github%20Desktop%20Local/GA-Lessons/project_4/code/Modelling.ipynb#ch0000062?line=0'>1</a>\u001b[0m \u001b[39m# Generating prediction probabilities on actual testing dataset using the model above (for kaggle submission).\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Github%20Desktop%20Local/GA-Lessons/project_4/code/Modelling.ipynb#ch0000062?line=2'>3</a>\u001b[0m submission_pred_proba1 \u001b[39m=\u001b[39m lr_smote_pipe1\u001b[39m.\u001b[39mpredict_proba(act_test_X_sc)[:, \u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'act_test_X_sc' is not defined"
     ]
    }
   ],
   "source": [
    "# Generating prediction probabilities on actual testing dataset using the model above (for kaggle submission).\n",
    "\n",
    "submission_pred_proba1 = lr_smote_pipe1.predict_proba(act_test_X_sc)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting the above predicted probabilities into a dataframe and exporting it as a csv file for submission to kaggle.\n",
    "\n",
    "sub1 = pd.DataFrame({'Id' : test['Id'].values, 'WnvPresent' : submission_pred_proba1})\n",
    "sub1.to_csv('../kaggle_submissions/submission_1_logreg_smote.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame(columns=['Classifier',\n",
    "                                   'Class Balancing Technique',\n",
    "                                   'Train Accuracy',\n",
    "                                   'Est. Test Accuracy (cv=5)',\n",
    "                                   'Actual Test Accuracy',\n",
    "                                   'Overfit / Underfit',\n",
    "                                   'Sensitivity',\n",
    "                                   'Specificity',\n",
    "                                   'Precision',\n",
    "                                   'ROC-AUC',\n",
    "                                   'Kaggle ROC-AUC'\n",
    "                                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Class Balancing Technique</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Est. Test Accuracy (cv=5)</th>\n",
       "      <th>Actual Test Accuracy</th>\n",
       "      <th>Overfit / Underfit</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>Kaggle ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.712</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Classifier Class Balancing Technique  Train Accuracy  \\\n",
       "1  LogisticRegression                     SMOTE           0.707   \n",
       "\n",
       "   Est. Test Accuracy (cv=5)  Actual Test Accuracy  Overfit / Underfit  \\\n",
       "1                      0.698                 0.712              -0.004   \n",
       "\n",
       "   Sensitivity  Specificity  Precision  ROC-AUC  Kaggle ROC-AUC  \n",
       "1        0.851        0.704      0.143    0.858           0.661  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_df.loc[1] = [\"LogisticRegression\",\n",
    "                     \"SMOTE\",\n",
    "                     round(train_acc1, 3),\n",
    "                     round(est_test_acc1, 3),\n",
    "                     round(test_acc1, 3),\n",
    "                     round(train_acc1-test_acc1, 3),\n",
    "                     round(sensitivity1, 3),\n",
    "                     round(specificity1, 3),\n",
    "                     round(precision1, 3),\n",
    "                     round(roc_auc1, 3),\n",
    "                     0.661\n",
    "                    ]\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *RandomForestClassifier* with *SMOTE* balancing technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a similar approach as with *LogisticRegression* above, manual tweaking of hyperparameters was done after using *GridSearchCV*. As explained above, ***GridSearchCV* only optimizes the model using a single scoring parameter. However, in this context, we need to find a good balance between *accuracy* and *sensitivity* scores, and so a manual tuning of hyperparameters is required**.\n",
    "\n",
    "The final set of hyperparameters chosen after manual tuning of the model are as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pipeline object using imblearn.pipeline with SMOTE and RandomForestClassifier.\n",
    "\n",
    "rfc_smote_pipe2 = make_pipeline(SMOTE(random_state=42),\n",
    "                                RandomForestClassifier(n_estimators=100,\n",
    "                                                       ccp_alpha=0,\n",
    "                                                       max_depth=5,\n",
    "                                                       min_samples_split=2,\n",
    "                                                       min_samples_leaf=3,\n",
    "                                                       random_state=42\n",
    "                                                      )\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('smote',\n",
       "                 SMOTE(k_neighbors=5, n_jobs=None, random_state=42,\n",
       "                       sampling_strategy='auto')),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=5, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=3, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=42,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fitting X_train_sc and y_train on the pipeline object defined above.\n",
    "\n",
    "rfc_smote_pipe2.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7784200385356455"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scoring the model on training dataset.\n",
    "# Training Accuracy\n",
    "\n",
    "train_acc2 = rfc_smote_pipe2.score(X_train_sc, y_train)\n",
    "train_acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7681431343350933"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Estimated Testing Accuracy\n",
    "\n",
    "est_test_acc2 = cross_val_score(rfc_smote_pipe2, X_train_sc, y_train, cv=5).mean()\n",
    "est_test_acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7750481695568401"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Actual Testing Accuracy\n",
    "\n",
    "test_acc2 = rfc_smote_pipe2.score(X_test_sc, y_test)\n",
    "test_acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating predictions on testing dataset using the model above.\n",
    "\n",
    "y_pred2 = rfc_smote_pipe2.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating prediction probabilities on testing dataset using the model above.\n",
    "\n",
    "y_pred_proba2 = rfc_smote_pipe2.predict_proba(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a confusion matrix.\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred2).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual WnvPresent=1</th>\n",
       "      <th>Actual WnvPresent=0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted WnvPresent=1</th>\n",
       "      <td>97 (True Pos)</td>\n",
       "      <td>450 (False Pos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted WnvPresent=0</th>\n",
       "      <td>17 (False Neg)</td>\n",
       "      <td>1512 (True Neg)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Actual WnvPresent=1 Actual WnvPresent=0\n",
       "Predicted WnvPresent=1       97 (True Pos)     450 (False Pos)\n",
       "Predicted WnvPresent=0      17 (False Neg)     1512 (True Neg)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mat2 = pd.DataFrame(columns=['Actual WnvPresent=1', 'Actual WnvPresent=0'], \n",
    "                         index=['Predicted WnvPresent=1', 'Predicted WnvPresent=0'],\n",
    "                         data=[[f'{tp} (True Pos)', f'{fp} (False Pos)'], [f'{fn} (False Neg)', f'{tn} (True Neg)']]\n",
    "                        )\n",
    "conf_mat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8508771929824561"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sensitivity2 = tp/(tp+fn)\n",
    "sensitivity2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7706422018348624"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "specificity2 = tn/(tn+fp)\n",
    "specificity2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1773308957952468"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision2 = tp/(tp+fp)\n",
    "precision2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8722369762326305"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc2 = roc_auc_score(y_test, y_pred_proba2[:, 1])\n",
    "roc_auc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating prediction probabilities on actual testing dataset using the model above (for kaggle submission).\n",
    "\n",
    "submission_pred_proba2 = rfc_smote_pipe2.predict_proba(act_test_X_sc)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting the above predicted probabilities into a dataframe and exporting it as a csv file for submission to kaggle.\n",
    "\n",
    "sub2 = pd.DataFrame({'Id' : test['Id'].values, 'WnvPresent' : submission_pred_proba2})\n",
    "sub2.to_csv('../kaggle_submissions/submission_2_rfc_smote.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Class Balancing Technique</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Est. Test Accuracy (cv=5)</th>\n",
       "      <th>Actual Test Accuracy</th>\n",
       "      <th>Overfit / Underfit</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>Kaggle ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.712</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Classifier Class Balancing Technique  Train Accuracy  \\\n",
       "1      LogisticRegression                     SMOTE           0.707   \n",
       "2  RandomForestClassifier                     SMOTE           0.778   \n",
       "\n",
       "   Est. Test Accuracy (cv=5)  Actual Test Accuracy  Overfit / Underfit  \\\n",
       "1                      0.698                 0.712              -0.004   \n",
       "2                      0.768                 0.775               0.003   \n",
       "\n",
       "   Sensitivity  Specificity  Precision  ROC-AUC  Kaggle ROC-AUC  \n",
       "1        0.851        0.704      0.143    0.858           0.661  \n",
       "2        0.851        0.771      0.177    0.872           0.706  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_df.loc[2] = [\"RandomForestClassifier\",\n",
    "                     \"SMOTE\",\n",
    "                     round(train_acc2, 3),\n",
    "                     round(est_test_acc2, 3),\n",
    "                     round(test_acc2, 3),\n",
    "                     round(train_acc2-test_acc2, 3),\n",
    "                     round(sensitivity2, 3),\n",
    "                     round(specificity2, 3),\n",
    "                     round(precision2, 3),\n",
    "                     round(roc_auc2, 3),\n",
    "                     0.706\n",
    "                    ]\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *SVC* with *SMOTE* balancing technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a similar approach as above, manual tweaking of hyperparameters was done after using *GridSearchCV*. As explained above, ***GridSearchCV* only optimizes the model using a single scoring parameter. However, in this context, we need to find a good balance between *accuracy* and *sensitivity* scores, and so a manual tuning of hyperparameters is required**.\n",
    "\n",
    "The final set of hyperparameters chosen after manual tuning of the model are as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pipeline object using imblearn.pipeline with SMOTE and SVC.\n",
    "\n",
    "svc_smote_pipe3 = make_pipeline(SMOTE(random_state=42),\n",
    "                                SVC(C=0.1,\n",
    "                                    kernel='rbf',\n",
    "                                    probability=True, \n",
    "                                    random_state=42\n",
    "                                   )\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('smote',\n",
       "                 SMOTE(k_neighbors=5, n_jobs=None, random_state=42,\n",
       "                       sampling_strategy='auto')),\n",
       "                ('svc',\n",
       "                 SVC(C=0.1, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='scale', kernel='rbf', max_iter=-1, probability=True,\n",
       "                     random_state=42, shrinking=True, tol=0.001,\n",
       "                     verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fitting X_train_sc and y_train on the pipeline object defined above.\n",
    "\n",
    "svc_smote_pipe3.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7032755298651252"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scoring the model on training dataset.\n",
    "# Training Accuracy\n",
    "\n",
    "train_acc3 = svc_smote_pipe3.score(X_train_sc, y_train)\n",
    "train_acc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931616030736106"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Estimated Testing Accuracy\n",
    "\n",
    "est_test_acc3 = cross_val_score(svc_smote_pipe3, X_train_sc, y_train, cv=5).mean()\n",
    "est_test_acc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6936416184971098"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Actual Testing Accuracy\n",
    "\n",
    "test_acc3 = svc_smote_pipe3.score(X_test_sc, y_test)\n",
    "test_acc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating predictions on testing dataset using the model above.\n",
    "\n",
    "y_pred3 = svc_smote_pipe3.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating prediction probabilities on testing dataset using the model above.\n",
    "\n",
    "y_pred_proba3 = svc_smote_pipe3.predict_proba(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a confusion matrix.\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred3).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual WnvPresent=1</th>\n",
       "      <th>Actual WnvPresent=0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted WnvPresent=1</th>\n",
       "      <td>98 (True Pos)</td>\n",
       "      <td>620 (False Pos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted WnvPresent=0</th>\n",
       "      <td>16 (False Neg)</td>\n",
       "      <td>1342 (True Neg)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Actual WnvPresent=1 Actual WnvPresent=0\n",
       "Predicted WnvPresent=1       98 (True Pos)     620 (False Pos)\n",
       "Predicted WnvPresent=0      16 (False Neg)     1342 (True Neg)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mat3 = pd.DataFrame(columns=['Actual WnvPresent=1', 'Actual WnvPresent=0'], \n",
    "                         index=['Predicted WnvPresent=1', 'Predicted WnvPresent=0'],\n",
    "                         data=[[f'{tp} (True Pos)', f'{fp} (False Pos)'], [f'{fn} (False Neg)', f'{tn} (True Neg)']]\n",
    "                        )\n",
    "conf_mat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8596491228070176"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sensitivity3 = tp/(tp+fn)\n",
    "sensitivity3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6839959225280327"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "specificity3 = tn/(tn+fp)\n",
    "specificity3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13649025069637882"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision3 = tp/(tp+fp)\n",
    "precision3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8443451901926069"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc3 = roc_auc_score(y_test, y_pred_proba3[:, 1])\n",
    "roc_auc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating prediction probabilities on actual testing dataset using the model above (for kaggle submission).\n",
    "\n",
    "submission_pred_proba3 = svc_smote_pipe3.predict_proba(act_test_X_sc)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting the above predicted probabilities into a dataframe and exporting it as a csv file for submission to kaggle.\n",
    "\n",
    "sub3 = pd.DataFrame({'Id' : test['Id'].values, 'WnvPresent' : submission_pred_proba3})\n",
    "sub3.to_csv('../kaggle_submissions/submission_3_svc_smote.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Class Balancing Technique</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Est. Test Accuracy (cv=5)</th>\n",
       "      <th>Actual Test Accuracy</th>\n",
       "      <th>Overfit / Underfit</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>Kaggle ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.712</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Classifier Class Balancing Technique  Train Accuracy  \\\n",
       "1      LogisticRegression                     SMOTE           0.707   \n",
       "2  RandomForestClassifier                     SMOTE           0.778   \n",
       "3                     SVC                     SMOTE           0.703   \n",
       "\n",
       "   Est. Test Accuracy (cv=5)  Actual Test Accuracy  Overfit / Underfit  \\\n",
       "1                      0.698                 0.712              -0.004   \n",
       "2                      0.768                 0.775               0.003   \n",
       "3                      0.693                 0.694               0.010   \n",
       "\n",
       "   Sensitivity  Specificity  Precision  ROC-AUC  Kaggle ROC-AUC  \n",
       "1        0.851        0.704      0.143    0.858           0.661  \n",
       "2        0.851        0.771      0.177    0.872           0.706  \n",
       "3        0.860        0.684      0.136    0.844           0.675  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_df.loc[3] = [\"SVC\",\n",
    "                     \"SMOTE\",\n",
    "                     round(train_acc3, 3),\n",
    "                     round(est_test_acc3, 3),\n",
    "                     round(test_acc3, 3),\n",
    "                     round(train_acc3-test_acc3, 3),\n",
    "                     round(sensitivity3, 3),\n",
    "                     round(specificity3, 3),\n",
    "                     round(precision3, 3),\n",
    "                     round(roc_auc3, 3),\n",
    "                     0.675\n",
    "                    ]\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *GradientBoostingClassifier* with *SMOTE* balancing technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a similar approach as above, manual tweaking of hyperparameters was done after using *GridSearchCV*. As explained above, ***GridSearchCV* only optimizes the model using a single scoring parameter. However, in this context, we need to find a good balance between *accuracy* and *sensitivity* scores, and so a manual tuning of hyperparameters is required**.\n",
    "\n",
    "The final set of hyperparameters chosen after manual tuning of the model are as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pipeline object using imblearn.pipeline with SMOTE and GradientBoostingClassifier.\n",
    "\n",
    "grb_smote_pipe4 = make_pipeline(SMOTE(random_state=42),\n",
    "                                GradientBoostingClassifier(learning_rate=0.01,\n",
    "                                                           n_estimators=80,\n",
    "                                                           ccp_alpha=0,\n",
    "                                                           max_depth=5,\n",
    "                                                           min_samples_split=2,\n",
    "                                                           min_samples_leaf=1,\n",
    "                                                           subsample=0.2,\n",
    "                                                           random_state=42\n",
    "                                                          )\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('smote',\n",
       "                 SMOTE(k_neighbors=5, n_jobs=None, random_state=42,\n",
       "                       sampling_strategy='auto')),\n",
       "                ('gradientboostingclassifier',\n",
       "                 GradientBoostingClassifier(ccp_alpha=0,\n",
       "                                            criterion='friedman_mse', init=None,\n",
       "                                            learning_rate=0.01, loss='deviance',\n",
       "                                            max_depth=5, max_features=None,\n",
       "                                            max_leaf_nodes=None,\n",
       "                                            min_impurity_decrease=0.0,\n",
       "                                            min_impurity_split=None,\n",
       "                                            min_samples_leaf=1,\n",
       "                                            min_samples_split=2,\n",
       "                                            min_weight_fraction_leaf=0.0,\n",
       "                                            n_estimators=80,\n",
       "                                            n_iter_no_change=None,\n",
       "                                            presort='deprecated',\n",
       "                                            random_state=42, subsample=0.2,\n",
       "                                            tol=0.0001, validation_fraction=0.1,\n",
       "                                            verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fitting X_train_sc and y_train on the pipeline object defined above.\n",
    "\n",
    "grb_smote_pipe4.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7800256904303147"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scoring the model on training dataset.\n",
    "# Training Accuracy\n",
    "\n",
    "train_acc4 = grb_smote_pipe4.score(X_train_sc, y_train)\n",
    "train_acc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7782585881245689"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Estimated Testing Accuracy\n",
    "\n",
    "est_test_acc4 = cross_val_score(grb_smote_pipe4, X_train_sc, y_train, cv=5).mean()\n",
    "est_test_acc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7649325626204239"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Actual Testing Accuracy\n",
    "\n",
    "test_acc4 = grb_smote_pipe4.score(X_test_sc, y_test)\n",
    "test_acc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating predictions on testing dataset using the model above.\n",
    "\n",
    "y_pred4 = grb_smote_pipe4.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating prediction probabilities on testing dataset using the model above.\n",
    "\n",
    "y_pred_proba4 = grb_smote_pipe4.predict_proba(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a confusion matrix.\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred4).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual WnvPresent=1</th>\n",
       "      <th>Actual WnvPresent=0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted WnvPresent=1</th>\n",
       "      <td>95 (True Pos)</td>\n",
       "      <td>469 (False Pos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted WnvPresent=0</th>\n",
       "      <td>19 (False Neg)</td>\n",
       "      <td>1493 (True Neg)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Actual WnvPresent=1 Actual WnvPresent=0\n",
       "Predicted WnvPresent=1       95 (True Pos)     469 (False Pos)\n",
       "Predicted WnvPresent=0      19 (False Neg)     1493 (True Neg)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mat4 = pd.DataFrame(columns=['Actual WnvPresent=1', 'Actual WnvPresent=0'], \n",
    "                         index=['Predicted WnvPresent=1', 'Predicted WnvPresent=0'],\n",
    "                         data=[[f'{tp} (True Pos)', f'{fp} (False Pos)'], [f'{fn} (False Neg)', f'{tn} (True Neg)']]\n",
    "                        )\n",
    "conf_mat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sensitivity4 = tp/(tp+fn)\n",
    "sensitivity4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7609582059123343"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "specificity4 = tn/(tn+fp)\n",
    "specificity4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16843971631205673"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision4 = tp/(tp+fp)\n",
    "precision4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8709247634887423"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc4 = roc_auc_score(y_test, y_pred_proba4[:, 1])\n",
    "roc_auc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating prediction probabilities on actual testing dataset using the model above (for kaggle submission).\n",
    "\n",
    "submission_pred_proba4 = grb_smote_pipe4.predict_proba(act_test_X_sc)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting the above predicted probabilities into a dataframe and exporting it as a csv file for submission to kaggle.\n",
    "\n",
    "sub4 = pd.DataFrame({'Id' : test['Id'].values, 'WnvPresent' : submission_pred_proba4})\n",
    "sub4.to_csv('../kaggle_submissions/submission_4_gradboost_smote.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Class Balancing Technique</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Est. Test Accuracy (cv=5)</th>\n",
       "      <th>Actual Test Accuracy</th>\n",
       "      <th>Overfit / Underfit</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>Kaggle ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.712</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Classifier Class Balancing Technique  Train Accuracy  \\\n",
       "1          LogisticRegression                     SMOTE           0.707   \n",
       "2      RandomForestClassifier                     SMOTE           0.778   \n",
       "3                         SVC                     SMOTE           0.703   \n",
       "4  GradientBoostingClassifier                     SMOTE           0.780   \n",
       "\n",
       "   Est. Test Accuracy (cv=5)  Actual Test Accuracy  Overfit / Underfit  \\\n",
       "1                      0.698                 0.712              -0.004   \n",
       "2                      0.768                 0.775               0.003   \n",
       "3                      0.693                 0.694               0.010   \n",
       "4                      0.778                 0.765               0.015   \n",
       "\n",
       "   Sensitivity  Specificity  Precision  ROC-AUC  Kaggle ROC-AUC  \n",
       "1        0.851        0.704      0.143    0.858           0.661  \n",
       "2        0.851        0.771      0.177    0.872           0.706  \n",
       "3        0.860        0.684      0.136    0.844           0.675  \n",
       "4        0.833        0.761      0.168    0.871           0.705  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_df.loc[4] = [\"GradientBoostingClassifier\",\n",
    "                     \"SMOTE\",\n",
    "                     round(train_acc4, 3),\n",
    "                     round(est_test_acc4, 3),\n",
    "                     round(test_acc4, 3),\n",
    "                     round(train_acc4-test_acc4, 3),\n",
    "                     round(sensitivity4, 3),\n",
    "                     round(specificity4, 3),\n",
    "                     round(precision4, 3),\n",
    "                     round(roc_auc4, 3),\n",
    "                     0.705\n",
    "                    ]\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the summary of classification metrics above, we note the following:\n",
    "\n",
    "- ***LogisticRegression* with *SMOTE*** - Performs well with train and test *accuracies* of ~71.0% with slight under-fitting on the train data. The *sensitivity* is also high at 85.1%.\n",
    "- ***RandomForestClassifier* with *SMOTE*** - Performs significantly better than *LogisticRegression* in terms of *accuracy* with very little over-fitting on the train data. The *sensitivity* score is same as *LogisticRegression* (85.1%).\n",
    "- ***SVC* with *SMOTE*** - Performs similarly as *LogisticRegression* above with slightly lesser *accuracy* scores and a slight over-fit on the train data. It performs the best among the four models in terms of *sensitivity* (86.0%), even though it is not significantly higher than the *sensitivity* for the two models above (85.1%).\n",
    "- ***GradientBoostingClassifier* with *SMOTE*** - Performs slightly better than the *RandomForestClassifier* model in terms of *accuracy*, but with a higher degree of over-fit on the train data. Also, it has the lowest *sensitivity* among the four models (83.3%).\n",
    "\n",
    "So, from the above, the two models that performed the best in terms of *accuracy* are *RandomForestClassifier* and *GradientBoostingClassifier*. While *GradientBoostingClassifier* performed slightly better on the train data, *RandomForestClassifier* had a significantly lesser degree of over-fit, and so can be said to be generalizing better on unseen data. Furthermore, *RandomForestClassifier sensitivity* is quite high and while it is only slightly lower than *SVC*, it manages to mantain a significantly higher *accuracy* as well as *specificity*. It also has the highest *ROC-AUC* score among the four models.\n",
    "\n",
    "So, for the above stated reasons, **we chose *RandomForestClassifier* to be our best performing classifier**. We will now pair *RandomForestClassifier* with **three other balancing techniques - *ADASYN, ClusterCentroids* and using hyperparameter *class_weight='balanced'*** to further model and select the best performing combination of class balancing technique and classifier for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *RandomForestClassifier* with *ADASYN* balancing technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a similar approach as above, manual tweaking of hyperparameters was done after using *GridSearchCV*. As explained above, ***GridSearchCV* only optimizes the model using a single scoring parameter. However, in this context, we need to find a good balance between *accuracy* and *sensitivity* scores, and so a manual tuning of hyperparameters is required**.\n",
    "\n",
    "The final set of hyperparameters chosen after manual tuning of the model are as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pipeline object using imblearn.pipeline with ADASYN and RandomForestClassifier.\n",
    "\n",
    "rfc_adasyn_pipe5 = make_pipeline(ADASYN(random_state=42),\n",
    "                                 RandomForestClassifier(n_estimators=100,\n",
    "                                                        ccp_alpha=0,\n",
    "                                                        max_depth=5,\n",
    "                                                        min_samples_split=2,\n",
    "                                                        min_samples_leaf=3,\n",
    "                                                        random_state=42\n",
    "                                                       )\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('adasyn',\n",
       "                 ADASYN(n_jobs=None, n_neighbors=5, random_state=42,\n",
       "                        sampling_strategy='auto')),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=5, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=3, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=42,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fitting X_train_sc and y_train on the pipeline object defined above.\n",
    "\n",
    "rfc_adasyn_pipe5.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7707129094412332"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scoring the model on training dataset.\n",
    "# Training Accuracy\n",
    "\n",
    "train_acc5 = rfc_adasyn_pipe5.score(X_train_sc, y_train)\n",
    "train_acc5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7605955120643086"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Estimated Testing Accuracy\n",
    "\n",
    "est_test_acc5 = cross_val_score(rfc_adasyn_pipe5, X_train_sc, y_train, cv=5).mean()\n",
    "est_test_acc5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7615606936416185"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Actual Testing Accuracy\n",
    "\n",
    "test_acc5 = rfc_adasyn_pipe5.score(X_test_sc, y_test)\n",
    "test_acc5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating predictions on testing dataset using the model above.\n",
    "\n",
    "y_pred5 = rfc_adasyn_pipe5.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating prediction probabilities on testing dataset using the model above.\n",
    "\n",
    "y_pred_proba5 = rfc_adasyn_pipe5.predict_proba(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a confusion matrix.\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred5).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual WnvPresent=1</th>\n",
       "      <th>Actual WnvPresent=0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted WnvPresent=1</th>\n",
       "      <td>96 (True Pos)</td>\n",
       "      <td>477 (False Pos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted WnvPresent=0</th>\n",
       "      <td>18 (False Neg)</td>\n",
       "      <td>1485 (True Neg)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Actual WnvPresent=1 Actual WnvPresent=0\n",
       "Predicted WnvPresent=1       96 (True Pos)     477 (False Pos)\n",
       "Predicted WnvPresent=0      18 (False Neg)     1485 (True Neg)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mat5 = pd.DataFrame(columns=['Actual WnvPresent=1', 'Actual WnvPresent=0'], \n",
    "                         index=['Predicted WnvPresent=1', 'Predicted WnvPresent=0'],\n",
    "                         data=[[f'{tp} (True Pos)', f'{fp} (False Pos)'], [f'{fn} (False Neg)', f'{tn} (True Neg)']]\n",
    "                        )\n",
    "conf_mat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8421052631578947"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sensitivity5 = tp/(tp+fn)\n",
    "sensitivity5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7568807339449541"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "specificity5 = tn/(tn+fp)\n",
    "specificity5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16753926701570682"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision5 = tp/(tp+fp)\n",
    "precision5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8715573975714005"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc5 = roc_auc_score(y_test, y_pred_proba5[:, 1])\n",
    "roc_auc5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating prediction probabilities on actual testing dataset using the model above (for kaggle submission).\n",
    "\n",
    "submission_pred_proba5 = rfc_adasyn_pipe5.predict_proba(act_test_X_sc)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting the above predicted probabilities into a dataframe and exporting it as a csv file for submission to kaggle.\n",
    "\n",
    "sub5 = pd.DataFrame({'Id' : test['Id'].values, 'WnvPresent' : submission_pred_proba5})\n",
    "sub5.to_csv('../kaggle_submissions/submission_5_rfc_adasyn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Class Balancing Technique</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Est. Test Accuracy (cv=5)</th>\n",
       "      <th>Actual Test Accuracy</th>\n",
       "      <th>Overfit / Underfit</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>Kaggle ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.712</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Classifier Class Balancing Technique  Train Accuracy  \\\n",
       "1          LogisticRegression                     SMOTE           0.707   \n",
       "2      RandomForestClassifier                     SMOTE           0.778   \n",
       "3                         SVC                     SMOTE           0.703   \n",
       "4  GradientBoostingClassifier                     SMOTE           0.780   \n",
       "5      RandomForestClassifier                    ADASYN           0.771   \n",
       "\n",
       "   Est. Test Accuracy (cv=5)  Actual Test Accuracy  Overfit / Underfit  \\\n",
       "1                      0.698                 0.712              -0.004   \n",
       "2                      0.768                 0.775               0.003   \n",
       "3                      0.693                 0.694               0.010   \n",
       "4                      0.778                 0.765               0.015   \n",
       "5                      0.761                 0.762               0.009   \n",
       "\n",
       "   Sensitivity  Specificity  Precision  ROC-AUC  Kaggle ROC-AUC  \n",
       "1        0.851        0.704      0.143    0.858           0.661  \n",
       "2        0.851        0.771      0.177    0.872           0.706  \n",
       "3        0.860        0.684      0.136    0.844           0.675  \n",
       "4        0.833        0.761      0.168    0.871           0.705  \n",
       "5        0.842        0.757      0.168    0.872           0.713  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_df.loc[5] = [\"RandomForestClassifier\",\n",
    "                     \"ADASYN\",\n",
    "                     round(train_acc5, 3),\n",
    "                     round(est_test_acc5, 3),\n",
    "                     round(test_acc5, 3),\n",
    "                     round(train_acc5-test_acc5, 3),\n",
    "                     round(sensitivity5, 3),\n",
    "                     round(specificity5, 3),\n",
    "                     round(precision5, 3),\n",
    "                     round(roc_auc5, 3),\n",
    "                     0.713\n",
    "                    ]\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *RandomForestClassifier* with *ClusterCentroids* balancing technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a similar approach as above, manual tweaking of hyperparameters was done after using *GridSearchCV*. As explained above, ***GridSearchCV* only optimizes the model using a single scoring parameter. However, in this context, we need to find a good balance between *accuracy* and *sensitivity* scores, and so a manual tuning of hyperparameters is required**.\n",
    "\n",
    "The final set of hyperparameters chosen after manual tuning of the model are as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pipeline object using imblearn.pipeline with ClusterCentroids and RandomForestClassifier.\n",
    "\n",
    "rfc_clustercentroids_pipe6 = make_pipeline(ClusterCentroids(random_state=42),\n",
    "                                           RandomForestClassifier(n_estimators=100,\n",
    "                                                                  ccp_alpha=0,\n",
    "                                                                  max_depth=5,\n",
    "                                                                  min_samples_split=2,\n",
    "                                                                  min_samples_leaf=3,\n",
    "                                                                  random_state=42\n",
    "                                                                 )\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('clustercentroids',\n",
       "                 ClusterCentroids(estimator=None, n_jobs=None, random_state=42,\n",
       "                                  sampling_strategy='auto', voting='auto')),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=5, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=3, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=42,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fitting X_train_sc and y_train on the pipeline object defined above.\n",
    "\n",
    "rfc_clustercentroids_pipe6.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6274887604367373"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scoring the model on training dataset.\n",
    "# Training Accuracy\n",
    "\n",
    "train_acc6 = rfc_clustercentroids_pipe6.score(X_train_sc, y_train)\n",
    "train_acc6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6178545320930592"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Estimated Testing Accuracy\n",
    "\n",
    "est_test_acc6 = cross_val_score(rfc_clustercentroids_pipe6, X_train_sc, y_train, cv=5).mean()\n",
    "est_test_acc6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6242774566473989"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Actual Testing Accuracy\n",
    "\n",
    "test_acc6 = rfc_clustercentroids_pipe6.score(X_test_sc, y_test)\n",
    "test_acc6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating predictions on testing dataset using the model above.\n",
    "\n",
    "y_pred6 = rfc_clustercentroids_pipe6.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating prediction probabilities on testing dataset using the model above.\n",
    "\n",
    "y_pred_proba6 = rfc_clustercentroids_pipe6.predict_proba(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a confusion matrix.\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred6).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual WnvPresent=1</th>\n",
       "      <th>Actual WnvPresent=0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted WnvPresent=1</th>\n",
       "      <td>105 (True Pos)</td>\n",
       "      <td>771 (False Pos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted WnvPresent=0</th>\n",
       "      <td>9 (False Neg)</td>\n",
       "      <td>1191 (True Neg)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Actual WnvPresent=1 Actual WnvPresent=0\n",
       "Predicted WnvPresent=1      105 (True Pos)     771 (False Pos)\n",
       "Predicted WnvPresent=0       9 (False Neg)     1191 (True Neg)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mat6 = pd.DataFrame(columns=['Actual WnvPresent=1', 'Actual WnvPresent=0'], \n",
    "                         index=['Predicted WnvPresent=1', 'Predicted WnvPresent=0'],\n",
    "                         data=[[f'{tp} (True Pos)', f'{fp} (False Pos)'], [f'{fn} (False Neg)', f'{tn} (True Neg)']]\n",
    "                        )\n",
    "conf_mat6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9210526315789473"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sensitivity6 = tp/(tp+fn)\n",
    "sensitivity6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6070336391437309"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "specificity6 = tn/(tn+fp)\n",
    "specificity6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11986301369863013"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision6 = tp/(tp+fp)\n",
    "precision6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8479465100059017"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc6 = roc_auc_score(y_test, y_pred_proba6[:, 1])\n",
    "roc_auc6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating prediction probabilities on actual testing dataset using the model above (for kaggle submission).\n",
    "\n",
    "submission_pred_proba6 = rfc_clustercentroids_pipe6.predict_proba(act_test_X_sc)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting the above predicted probabilities into a dataframe and exporting it as a csv file for submission to kaggle.\n",
    "\n",
    "sub6 = pd.DataFrame({'Id' : test['Id'].values, 'WnvPresent' : submission_pred_proba6})\n",
    "sub6.to_csv('../kaggle_submissions/submission_6_rfc_clustercentroids.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Class Balancing Technique</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Est. Test Accuracy (cv=5)</th>\n",
       "      <th>Actual Test Accuracy</th>\n",
       "      <th>Overfit / Underfit</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>Kaggle ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.712</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>ClusterCentroids</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Classifier Class Balancing Technique  Train Accuracy  \\\n",
       "1          LogisticRegression                     SMOTE           0.707   \n",
       "2      RandomForestClassifier                     SMOTE           0.778   \n",
       "3                         SVC                     SMOTE           0.703   \n",
       "4  GradientBoostingClassifier                     SMOTE           0.780   \n",
       "5      RandomForestClassifier                    ADASYN           0.771   \n",
       "6      RandomForestClassifier          ClusterCentroids           0.627   \n",
       "\n",
       "   Est. Test Accuracy (cv=5)  Actual Test Accuracy  Overfit / Underfit  \\\n",
       "1                      0.698                 0.712              -0.004   \n",
       "2                      0.768                 0.775               0.003   \n",
       "3                      0.693                 0.694               0.010   \n",
       "4                      0.778                 0.765               0.015   \n",
       "5                      0.761                 0.762               0.009   \n",
       "6                      0.618                 0.624               0.003   \n",
       "\n",
       "   Sensitivity  Specificity  Precision  ROC-AUC  Kaggle ROC-AUC  \n",
       "1        0.851        0.704      0.143    0.858           0.661  \n",
       "2        0.851        0.771      0.177    0.872           0.706  \n",
       "3        0.860        0.684      0.136    0.844           0.675  \n",
       "4        0.833        0.761      0.168    0.871           0.705  \n",
       "5        0.842        0.757      0.168    0.872           0.713  \n",
       "6        0.921        0.607      0.120    0.848           0.707  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_df.loc[6] = [\"RandomForestClassifier\",\n",
    "                     \"ClusterCentroids\",\n",
    "                     round(train_acc6, 3),\n",
    "                     round(est_test_acc6, 3),\n",
    "                     round(test_acc6, 3),\n",
    "                     round(train_acc6-test_acc6, 3),\n",
    "                     round(sensitivity6, 3),\n",
    "                     round(specificity6, 3),\n",
    "                     round(precision6, 3),\n",
    "                     round(roc_auc6, 3),\n",
    "                     0.707\n",
    "                    ]\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *RandomForestClassifier* with hyperparameter *class_weight='balanced_subsample'*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a similar approach as above, manual tweaking of hyperparameters was done after using *GridSearchCV*. As explained above, ***GridSearchCV* only optimizes the model using a single scoring parameter. However, in this context, we need to find a good balance between *accuracy* and *sensitivity* scores, and so a manual tuning of hyperparameters is required**.\n",
    "\n",
    "The final set of hyperparameters chosen after manual tuning of the model are as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a RandomForestClassifier object.\n",
    "\n",
    "rfc7 = RandomForestClassifier(class_weight='balanced_subsample', \n",
    "                              n_estimators=200,\n",
    "                              ccp_alpha=0,\n",
    "                              max_depth=5,\n",
    "                              min_samples_split=2,\n",
    "                              min_samples_leaf=1,\n",
    "                              random_state=42\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0,\n",
       "                       class_weight='balanced_subsample', criterion='gini',\n",
       "                       max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "                       max_samples=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=200, n_jobs=None, oob_score=False,\n",
       "                       random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fitting X_train_sc and y_train on RandomForestClassifier object defined above.\n",
    "\n",
    "rfc7.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7408477842003853"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scoring the model on training dataset.\n",
    "# Training Accuracy\n",
    "\n",
    "train_acc7 = rfc7.score(X_train_sc, y_train)\n",
    "train_acc7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7430972042262147"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Estimated Testing Accuracy\n",
    "\n",
    "est_test_acc7 = cross_val_score(rfc7, X_train_sc, y_train, cv=5).mean()\n",
    "est_test_acc7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7345857418111753"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Actual Testing Accuracy\n",
    "\n",
    "test_acc7 = rfc7.score(X_test_sc, y_test)\n",
    "test_acc7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating predictions on testing dataset using the model above.\n",
    "\n",
    "y_pred7 = rfc7.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating prediction probabilities on testing dataset using the model above.\n",
    "\n",
    "y_pred_proba7 = rfc7.predict_proba(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a confusion matrix.\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred7).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual WnvPresent=1</th>\n",
       "      <th>Actual WnvPresent=0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted WnvPresent=1</th>\n",
       "      <td>104 (True Pos)</td>\n",
       "      <td>541 (False Pos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted WnvPresent=0</th>\n",
       "      <td>10 (False Neg)</td>\n",
       "      <td>1421 (True Neg)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Actual WnvPresent=1 Actual WnvPresent=0\n",
       "Predicted WnvPresent=1      104 (True Pos)     541 (False Pos)\n",
       "Predicted WnvPresent=0      10 (False Neg)     1421 (True Neg)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mat7 = pd.DataFrame(columns=['Actual WnvPresent=1', 'Actual WnvPresent=0'], \n",
    "                         index=['Predicted WnvPresent=1', 'Predicted WnvPresent=0'],\n",
    "                         data=[[f'{tp} (True Pos)', f'{fp} (False Pos)'], [f'{fn} (False Neg)', f'{tn} (True Neg)']]\n",
    "                        )\n",
    "conf_mat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9122807017543859"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sensitivity7 = tp/(tp+fn)\n",
    "sensitivity7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7242609582059123"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "specificity7 = tn/(tn+fp)\n",
    "specificity7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16124031007751938"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision7 = tp/(tp+fp)\n",
    "precision7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8820372158735269"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc7 = roc_auc_score(y_test, y_pred_proba7[:, 1])\n",
    "roc_auc7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating prediction probabilities on actual testing dataset using the model above (for kaggle submission).\n",
    "\n",
    "submission_pred_proba7 = rfc7.predict_proba(act_test_X_sc)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting the above predicted probabilities into a dataframe and exporting it as a csv file for submission to kaggle.\n",
    "\n",
    "sub7 = pd.DataFrame({'Id' : test['Id'].values, 'WnvPresent' : submission_pred_proba7})\n",
    "sub7.to_csv('../kaggle_submissions/submission_7_rfc_class_weight_bal.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the fitted model as a pickle file for deployment.\n",
    "\n",
    "filename= 'final_rfc_model.pkl'\n",
    "pickle.dump(rfc7, open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Class Balancing Technique</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Est. Test Accuracy (cv=5)</th>\n",
       "      <th>Actual Test Accuracy</th>\n",
       "      <th>Overfit / Underfit</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>Kaggle ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.712</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>ADASYN</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>ClusterCentroids</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>class_weight='balanced_subsample'</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Classifier          Class Balancing Technique  \\\n",
       "1          LogisticRegression                              SMOTE   \n",
       "2      RandomForestClassifier                              SMOTE   \n",
       "3                         SVC                              SMOTE   \n",
       "4  GradientBoostingClassifier                              SMOTE   \n",
       "5      RandomForestClassifier                             ADASYN   \n",
       "6      RandomForestClassifier                   ClusterCentroids   \n",
       "7      RandomForestClassifier  class_weight='balanced_subsample'   \n",
       "\n",
       "   Train Accuracy  Est. Test Accuracy (cv=5)  Actual Test Accuracy  \\\n",
       "1           0.707                      0.698                 0.712   \n",
       "2           0.778                      0.768                 0.775   \n",
       "3           0.703                      0.693                 0.694   \n",
       "4           0.780                      0.778                 0.765   \n",
       "5           0.771                      0.761                 0.762   \n",
       "6           0.627                      0.618                 0.624   \n",
       "7           0.741                      0.743                 0.735   \n",
       "\n",
       "   Overfit / Underfit  Sensitivity  Specificity  Precision  ROC-AUC  \\\n",
       "1              -0.004        0.851        0.704      0.143    0.858   \n",
       "2               0.003        0.851        0.771      0.177    0.872   \n",
       "3               0.010        0.860        0.684      0.136    0.844   \n",
       "4               0.015        0.833        0.761      0.168    0.871   \n",
       "5               0.009        0.842        0.757      0.168    0.872   \n",
       "6               0.003        0.921        0.607      0.120    0.848   \n",
       "7               0.006        0.912        0.724      0.161    0.882   \n",
       "\n",
       "   Kaggle ROC-AUC  \n",
       "1           0.661  \n",
       "2           0.706  \n",
       "3           0.675  \n",
       "4           0.705  \n",
       "5           0.713  \n",
       "6           0.707  \n",
       "7           0.717  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_df.loc[7] = [\"RandomForestClassifier\",\n",
    "                     \"class_weight='balanced_subsample'\",\n",
    "                     round(train_acc7, 3),\n",
    "                     round(est_test_acc7, 3),\n",
    "                     round(test_acc7, 3),\n",
    "                     round(train_acc7-test_acc7, 3),\n",
    "                     round(sensitivity7, 3),\n",
    "                     round(specificity7, 3),\n",
    "                     round(precision7, 3),\n",
    "                     round(roc_auc7, 3),\n",
    "                     0.717\n",
    "                    ]\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "006be043bc5636bd4f043fb67299334f749b935cdb979ce371419345f6e1f02a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
